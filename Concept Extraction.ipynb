{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not re-inventing the wheel.\n",
    "# Copied from edison project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Take something like:\n",
    "\n",
    "1. Learn Computer Science With JavaScript: Part 4, Functions\n",
    "1. Create Interactive Charts Using Plotly.js, Part 1: Getting Started\n",
    "\n",
    "And come out with keywords:\n",
    "\n",
    "1. Computer Science\n",
    "1. JavaScript\n",
    "1. Functions\n",
    "1. Interactive Charts\n",
    "1. Plotly.js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceptance Criteria\n",
    "\n",
    "It is okay for the extractor to extract things that are not exactly concepts. For example, in the case above, it might also come up with:\n",
    "\n",
    "1. Getting Started\n",
    "\n",
    "Another classifier can use Word2Vec to exclude generic terms, but it's not in the scope of this extractor, because we're only looking at the grammatical structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core idea\n",
    "\n",
    "Encode every token inside a title as:\n",
    "\n",
    "1. The tag of the parent\n",
    "1. The dependency to the parent\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kavitakanojiya/anaconda2/envs/levelling36/lib/python3.6/runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/kavitakanojiya/anaconda2/envs/levelling36/lib/python3.6/runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1625\" height=\"487.0\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Create</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Interactive</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NNP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Charts</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NNS</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Using</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VBG</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Plotly.js,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NNP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Part</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NNP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">1:</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">CD</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Getting</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">VBG</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">Started</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VBN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M70,352.0 C70,177.0 390.0,177.0 390.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,354.0 L398.0,342.0 382.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M560.0,354.0 L568.0,342.0 552.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M735.0,354.0 L743.0,342.0 727.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M420,352.0 C420,89.5 920.0,89.5 920.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,354.0 L928.0,342.0 912.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp('Create Interactive Charts Using Plotly.js, Part 1: Getting Started')\n",
    "displacy.render(doc, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_features(token):\n",
    "    print(\"Token:\", token)\n",
    "    print(\"Token tag:\", token.tag_)\n",
    "    print(\"Token parent dep:\", token.dep_)\n",
    "    print(\"Token parent tag:\", token.head.tag_)\n",
    "    print(\"Children:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Interactive\n",
      "Token tag: NNP\n",
      "Token parent dep: compound\n",
      "Token parent tag: NNS\n",
      "Children:\n"
     ]
    }
   ],
   "source": [
    "test_features(doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Charts\n",
      "Token tag: NNS\n",
      "Token parent dep: dobj\n",
      "Token parent tag: VB\n",
      "Children:\n"
     ]
    }
   ],
   "source": [
    "test_features(doc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ---------------- Here, it ends the concept extraction login ---------------- ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following is the logic to extract concepts from all the html files ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive Charts dobj Create\n",
      "Plotly.js dobj Using\n",
      "Part appos Charts\n"
     ]
    }
   ],
   "source": [
    "# Playing with #noun_chunks\n",
    "for np in doc.noun_chunks:\n",
    "    print(np.text, np.root.dep_, np.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of HTML tags\n",
    "def clean_me(html):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    for s in soup(['script', 'style']):\n",
    "        s.decompose()\n",
    "    return ' '.join(soup.stripped_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Read all HTML files from Machine Learning Mastery articles folder.\n",
    "html_files = os.listdir(\"Machine Learning Mastery articles\")\n",
    "\n",
    "# Initialise a list to capture all keywords\n",
    "keywords = dict()\n",
    "\n",
    "for html_file in html_files:\n",
    "    try:\n",
    "        with open(\"Machine Learning Mastery articles/\" + html_file) as f:\n",
    "            html = f.read()\n",
    "            scrubbed_content = clean_me(html)\n",
    "            current_doc = nlp(scrubbed_content)\n",
    "\n",
    "            for np in current_doc.noun_chunks:\n",
    "                if np.root.dep_ in ['pobj', 'nsubj','compound'] and np.root.tag_ == 'NNP' and np.root.pos_ == 'PROPN':\n",
    "                    if np.text in keywords:\n",
    "                        keywords[np.text] += 1\n",
    "                    else:\n",
    "                        keywords[np.text] = 0\n",
    "\n",
    "                    # Handling words differently\n",
    "            #         if np.root.dep_ == 'nsubj' and np.root.tag_ == 'NNP' and np.root.pos_ == 'PROPN':\n",
    "            #             keywords.append(np.text)\n",
    "            #         if np.root.dep_ == 'compound' and np.root.tag_ == 'NNP' and np.root.pos_ == 'PROPN':\n",
    "            #             keywords.append(np.text)\n",
    "            #         if np.root.dep_ == 'dobj' and np.root.tag_ == 'NN' and np.root.pos_ == 'NOUN':\n",
    "            #             keywords.append(np.text)\n",
    "            #         print(np.text + \" dep: \" + np.root.dep_ + \" with tag: \" + np.root.tag_ + \" root.head.text: \" + np.root.head.text + \" POS: \" + np.root.pos_)\n",
    "    except:\n",
    "        print(html_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the Python Deep Learning Library TensorFlow - Machine Learning Mastery Navigation Machine Learning Mastery': 0,\n",
       " 'Blog Books': 514,\n",
       " 'Contact': 497,\n",
       " 'Deep Learning': 500,\n",
       " 'Content Introduction': 4,\n",
       " 'the Python Deep Learning Library TensorFlow': 2,\n",
       " 'Jason Brownlee': 1207,\n",
       " 'May': 108,\n",
       " 'Deep Learning Share': 46,\n",
       " 'Twitter Tweet Share': 1093,\n",
       " 'Google Plus Share TensorFlow': 0,\n",
       " 'Google': 36,\n",
       " 'TensorFlow': 46,\n",
       " 'the Python Deep Learning Library TensorFlow Photo': 0,\n",
       " 'Nicolas Raymond': 1,\n",
       " 'Theano': 68,\n",
       " 'Install TensorFlow Installation': 0,\n",
       " 'Python': 4391,\n",
       " 'Installation': 0,\n",
       " 'the Download': 0,\n",
       " 'the GPU': 10,\n",
       " 'TensorFlow Computation': 0,\n",
       " 'tf': 5,\n",
       " 'np': 10,\n",
       " 'NumPy': 20,\n",
       " 'W': 1,\n",
       " 'Tensorflow': 22,\n",
       " 'xrange(201': 0,\n",
       " 'xrange': 0,\n",
       " 'Udacity TensorFlow': 0,\n",
       " 'Your Progress': 84,\n",
       " 'Minutes': 109,\n",
       " 'Python Discover': 63,\n",
       " 'my new Ebook': 395,\n",
       " 'Google Plus Share': 768,\n",
       " 'Jason Brownlee Dr. Jason Brownlee': 543,\n",
       " 'Machine Learning Developers Introduction': 0,\n",
       " 'Machine Learning': 1224,\n",
       " 'Introduction': 4,\n",
       " 'Reply Jason Brownlee': 5356,\n",
       " 'Reply Amit Kumar': 0,\n",
       " 'Python3': 2,\n",
       " 'Reply Walid Ahmed': 7,\n",
       " 'Reply': 451,\n",
       " 'Machine Learning Mastery': 551,\n",
       " 'Deep Learning Sick': 46,\n",
       " 'Python Today': 161,\n",
       " 'Python Step': 554,\n",
       " 'Step': 554,\n",
       " 'Keras': 3640,\n",
       " 'LSTMs': 856,\n",
       " 'Anaconda': 590,\n",
       " 'the Long Short-Term Memory Network': 555,\n",
       " 'Python April': 546,\n",
       " 'the Keras Deep Learning Library': 1104,\n",
       " 'Keras - Machine Learning Mastery Navigation Machine Learning Mastery': 35,\n",
       " 'Content': 318,\n",
       " 'October': 56,\n",
       " 'Long Short-Term Memory Networks Share': 56,\n",
       " 'the Long Short-Term Memory': 1,\n",
       " 'the Keras API': 7,\n",
       " 'Keras Photo': 32,\n",
       " 'Adrian Curt Dannemann': 0,\n",
       " 'The Long Short-Term Memory': 1,\n",
       " 'import Model': 14,\n",
       " 'import Input': 7,\n",
       " 'Long Short-Term Memory Networks': 40,\n",
       " 'Python Return States': 0,\n",
       " 'Keras Long Short-Term Memory': 1,\n",
       " 'Keras Summary': 3,\n",
       " ': Long Short-Term Memory Networks': 56,\n",
       " 'Document Classification': 8,\n",
       " 'Index': 5,\n",
       " 'Keras Nikeita': 0,\n",
       " 'https://stats.stackexchange.com/a/181544/37863 Reply Jason Brownlee': 0,\n",
       " 'Reply Thabet Ali': 1,\n",
       " 'Thabet Reply Jason Brownlee': 0,\n",
       " 'set_state': 0,\n",
       " 'Reply Eldar': 0,\n",
       " 'https://arxiv.org/pdf/1703.01253.pdf': 0,\n",
       " 'GRU': 4,\n",
       " 'keras': 1,\n",
       " 'Alex Reply Jason Brownlee': 1,\n",
       " '# Hi Jason': 43,\n",
       " 'Reply MT November': 0,\n",
       " 'raise_exception_on_not_ok_status': 0,\n",
       " 'keras.models import Sequential': 34,\n",
       " 'Output self.model.add(Dense(1,activation=”sigmoid”,name=”output_layer': 0,\n",
       " 'a GRU': 0,\n",
       " 'Reply Kaushal Shetty': 1,\n",
       " 'a LSTM': 0,\n",
       " 'the LSTM': 115,\n",
       " 'Nathan D.': 0,\n",
       " '*lstm1': 0,\n",
       " 'Sequence Prediction Cut': 56,\n",
       " 'August': 60,\n",
       " 'damon jah': 0,\n",
       " 'a Final LSTM Model': 0,\n",
       " 'Sequence Prediction': 69,\n",
       " 'Your Final Model Keras': 0,\n",
       " 'import Sequential': 69,\n",
       " 'import LSTM': 10,\n",
       " 'New Data': 4,\n",
       " 'the Keras FAQ': 0,\n",
       " 'Generative Long Short-Term Memory Networks': 2,\n",
       " 'X': 49,\n",
       " 'Data Leakage': 6,\n",
       " 'Machine Learning - Machine Learning Mastery Navigation Machine Learning Mastery': 46,\n",
       " 'Content Data Leakage': 0,\n",
       " 'Machine Learning Process Share': 57,\n",
       " 'Machine Learning Photo': 37,\n",
       " 'DaveBleasdale': 0,\n",
       " 'Predictive Modeling': 5,\n",
       " 'Cross Validation Folds': 0,\n",
       " 'the Frontline': 7,\n",
       " 'Cross Validated': 1,\n",
       " 'R': 124,\n",
       " 'Dikran Marsupial': 3,\n",
       " 'Combat Data Leakage Temporal Cutoff': 0,\n",
       " 'Data Mining': 20,\n",
       " 'the Kaggle Wiki': 0,\n",
       " 'the ICML 2013 Whale Challenge Summary': 0,\n",
       " 'Tune Machine Learning Algorithms': 6,\n",
       " 'Weka': 600,\n",
       " 'Machine Learning Calvin': 0,\n",
       " 'H2O': 3,\n",
       " 'Reply Seo young jae': 1,\n",
       " 'Content Weka Machine Learning': 0,\n",
       " 'Weka Machine Learning Share': 36,\n",
       " 'Weka Mini-Course Photo': 0,\n",
       " 'Leon Yaakov': 0,\n",
       " 'Your Data': 18,\n",
       " 'Algorithms': 36,\n",
       " 'Java': 51,\n",
       " 'Windows': 38,\n",
       " 'the Weka Explorer': 17,\n",
       " 'Start Weka': 0,\n",
       " 'the “Visualize': 0,\n",
       " 'Machine Learning Algorithms': 121,\n",
       " 'Tour': 4,\n",
       " 'Classification Algorithms Weka': 0,\n",
       " 'Ensemble Algorithms Weka': 0,\n",
       " 'Algorithms Weka': 1,\n",
       " 'The\\xa0Weka Experiment Environment': 0,\n",
       " 'IBK': 0,\n",
       " 'ZeroR': 14,\n",
       " 'the “Analyse': 0,\n",
       " 'The Weka Experiment Environment': 4,\n",
       " 'KNN': 34,\n",
       " '“Plain Text': 0,\n",
       " 'The Code': 37,\n",
       " 'the Weka Machine Learning Workbench': 8,\n",
       " 'Weka Machine Learning Mini-Course Raman': 0,\n",
       " 'Information Systems': 0,\n",
       " 'University': 10,\n",
       " 'Weka GUI': 1,\n",
       " 'Applied ML': 0,\n",
       " 'the ML': 2,\n",
       " 'ML': 170,\n",
       " 'Sreedev': 0,\n",
       " 'Lesson': 2,\n",
       " 'Dominik Reply Jason Brownlee': 1,\n",
       " '# Awesome Jason': 0,\n",
       " 'Germany': 0,\n",
       " 'Reply Upasana Tiwari': 0,\n",
       " 'CorrelationAttributeEval': 1,\n",
       " 'the UCI Machine Learning Repository': 75,\n",
       " 'Reply Dada Gbenga': 0,\n",
       " 'Weka Machine Learning': 36,\n",
       " 'Non-Linear Classification': 2,\n",
       " 'R - Machine Learning Mastery Navigation Machine Learning Mastery': 14,\n",
       " 'R Machine Learning Share': 37,\n",
       " 'R.': 111,\n",
       " 'dottieg2007': 1,\n",
       " 'Mixture Discriminant Analysis': 0,\n",
       " 'Quadratic Discriminant Analysis QDA': 0,\n",
       " 'Quadratic Discriminant Analysis': 0,\n",
       " 'Regularized Discriminant Analysis': 1,\n",
       " 'Neural Network A Neural Network': 1,\n",
       " 'Neural Network': 6,\n",
       " 'Flexible Discriminant Analysis': 0,\n",
       " 'SVM': 75,\n",
       " 'Support Vector Machine': 2,\n",
       " 'Naive Bayes Naive Bayes': 2,\n",
       " 'Naive Bayes': 52,\n",
       " 'R Machine Learning': 79,\n",
       " 'Jason Brownlee → Linear Classification': 0,\n",
       " 'Machine': 9,\n",
       " 'R Daniel Nee': 0,\n",
       " 'Tom Mitchell': 4,\n",
       " 'Content Biggest Mistake': 0,\n",
       " 'March': 55,\n",
       " 'C4.5': 9,\n",
       " 'a GUI': 1,\n",
       " 'Weka Explorer Interface': 4,\n",
       " 'Weka Feature Selection': 0,\n",
       " 'Biggest Mistake': 0,\n",
       " 'a Kaggle Master': 5,\n",
       " 'Diogo Ferreira - Machine Learning Mastery Navigation Machine Learning Mastery': 0,\n",
       " 'Diogo Ferreira': 2,\n",
       " 'Start Machine Learning Share': 67,\n",
       " 'Diogo': 3,\n",
       " 'the\\xa0Technical University': 0,\n",
       " 'Lisbon': 1,\n",
       " 'BPM': 0,\n",
       " 'Process Mining': 0,\n",
       " 'Business Intelligence': 0,\n",
       " 'the Process Mining Manifesto': 0,\n",
       " 'Puzzles': 0,\n",
       " 'Jason': 62,\n",
       " 'Chess Rating Competition White': 0,\n",
       " 'Black Photo': 0,\n",
       " 'Gideon': 0,\n",
       " 'Your Specific\\xa0Solution': 0,\n",
       " 'the reference player Z': 0,\n",
       " 'Convergence': 2,\n",
       " 'TrueSkill': 0,\n",
       " 'Jeff Sonas': 0,\n",
       " 'Jeff': 1,\n",
       " 'the Chess Rating Competition': 0,\n",
       " 'PhDs': 0,\n",
       " 'the Rest': 0,\n",
       " 'the World': 1,\n",
       " 'Historical Data': 0,\n",
       " 'the Technical University': 0,\n",
       " 'Machine Learning Algorithms An Introduction': 0,\n",
       " 'Diogo Ferreira Hui': 0,\n",
       " 'Thanks Hui Reply': 0,\n",
       " 'A Problem': 5,\n",
       " 'A Data Scientist - Machine Learning Mastery': 0,\n",
       " 'December': 78,\n",
       " 'Hilary Mason': 2,\n",
       " 'A Taxonomy': 0,\n",
       " 'Data Science': 23,\n",
       " 'the Command Line': 3,\n",
       " 'Jeroen Janssens': 1,\n",
       " 'O’Reilly': 2,\n",
       " 'A Data Scientist Photo': 0,\n",
       " 'U.S. Army RDECOM': 0,\n",
       " 'OSEMN Process OSEMN': 0,\n",
       " 'Obtain': 1,\n",
       " 'JSON': 5,\n",
       " 'the Data Preparation Process': 0,\n",
       " 'Pairwise Histograms': 0,\n",
       " 'Exploratory Data Analysis': 0,\n",
       " 'OSEMN': 1,\n",
       " 'Knowledge Discovery': 13,\n",
       " 'Databases': 8,\n",
       " 'Content Spot': 0,\n",
       " 'February': 42,\n",
       " 'Spot Check Machine Learning Algorithms': 1,\n",
       " 'R Photo': 8,\n",
       " 'Nuclear Regulatory Commission': 0,\n",
       " 'Spot Check': 0,\n",
       " 'y': 78,\n",
       " 'CART': 25,\n",
       " 'David Samson': 0,\n",
       " 'dbs Reply Jason Brownlee': 0,\n",
       " 'Mustafa Reply Jason Brownlee': 1,\n",
       " 'January': 72,\n",
       " 'Photo': 8,\n",
       " 'Phil Sexton': 0,\n",
       " 'Regrads': 0,\n",
       " 'Update Sept/2017': 0,\n",
       " '3V': 0,\n",
       " 'the KerasClassifier': 2,\n",
       " 'grid.fit': 0,\n",
       " 'Epochs': 4,\n",
       " 'Dense': 30,\n",
       " 'the Training Optimization Algorithm Keras': 0,\n",
       " 'KerasClassifier': 5,\n",
       " 'Tune Learning Rate': 3,\n",
       " 'keras.wrappers.scikit_learn import KerasClassifier': 18,\n",
       " 'relatively SGD': 0,\n",
       " \"KerasClassifier\\ndef create_model(activation='relu\": 0,\n",
       " 'Tune Dropout Regularization': 0,\n",
       " 'sklearn.model_selection import GridSearchCV': 3,\n",
       " 'keras.layers import Dropout': 9,\n",
       " 'the Hidden Layer': 0,\n",
       " 'KerasClassifier\\ndef create_model(neurons=1': 0,\n",
       " 'Hyperparameter': 0,\n",
       " 'Your Dataset': 0,\n",
       " 'a Binary Classification Project': 4,\n",
       " 'Weka Step': 8,\n",
       " 'a Regression Machine Learning Project': 4,\n",
       " 'Keras Yanbo': 0,\n",
       " 'a large CNN': 0,\n",
       " 'LSTM': 157,\n",
       " 'Bilstm cnnlstm Reply Jason Brownlee': 0,\n",
       " 'Reply Satheesh': 0,\n",
       " 'Keras Classifier': 0,\n",
       " 'the NN': 4,\n",
       " 'Reply L Fenu': 0,\n",
       " 'as json_file: json_file.write(model2json) best_model.save_weights(best_model_file_path+’.h5′': 0,\n",
       " 'StackOverflow': 11,\n",
       " 'Jan Reply Jason Brownlee': 0,\n",
       " 'Reply Jan de Lange': 0,\n",
       " 'Stackoverflow': 0,\n",
       " 'Reply Anthony Ohazulike': 0,\n",
       " 'Reply Thomas Maier': 0,\n",
       " 'Thomas Reply Jason Brownlee': 1,\n",
       " 'the cuff Jimi': 0,\n",
       " 'Reply DeepLearning': 1,\n",
       " 'the UCI ML Repo': 2,\n",
       " 'Reply Rajneesh January': 0,\n",
       " 'Reply Jing': 0,\n",
       " 'the ‘model.compile()’method': 0,\n",
       " 'Reply Dan March': 5,\n",
       " 'GridsearchCV': 2,\n",
       " 'KERAS': 3,\n",
       " 'Reply Maycown Miranda April': 0,\n",
       " 'check_params(self=': 0,\n",
       " 'Reply Chandra Sutrisno Tjhong': 0,\n",
       " 'Reply Usman May': 0,\n",
       " 'SGD': 23,\n",
       " 'Reply Pradanuari': 0,\n",
       " 'fit(self=': 0,\n",
       " ') AttributeError': 1,\n",
       " 'Ibrahim Reply Jason Brownlee': 0,\n",
       " 'Ibrahim El-Fayoumi': 0,\n",
       " 'Linux': 17,\n",
       " 'Reply Edward': 0,\n",
       " 'Adamax': 1,\n",
       " 'both Adamax': 0,\n",
       " 'Reply Yang May': 0,\n",
       " 'Input1': 0,\n",
       " 'a 1,000 *3 matrix Input2': 0,\n",
       " 'the GridsearchCV': 1,\n",
       " 'import SGD': 2,\n",
       " 'Reply Rahul May': 0,\n",
       " 'Reply Ian Worthington': 0,\n",
       " 'https://arxiv.org/abs/1206.5533 Reply Ian Worthington': 0,\n",
       " 'Reply Mario': 1,\n",
       " 'GridSearch': 1,\n",
       " '# GridSearch': 0,\n",
       " 'the “CV': 0,\n",
       " 'cv': 6,\n",
       " 'CV': 25,\n",
       " 'Abhijith Darshan Ravindra': 0,\n",
       " 'Spyder IDE': 0,\n",
       " 'Reply DY': 0,\n",
       " 'MLPRegressor': 1,\n",
       " 'I’ll': 1,\n",
       " 'Reply Josep': 0,\n",
       " 'Hi Josep': 0,\n",
       " 'Reply Michael August': 0,\n",
       " 'Reply Shubham Kumar': 6,\n",
       " 'GridSearchCV': 1,\n",
       " 'MLP_Regressor': 0,\n",
       " 'Andrew Ng': 12,\n",
       " 'MB': 0,\n",
       " 'Reply TMN': 0,\n",
       " '‘relu’} Jason Brownlee': 1,\n",
       " 'Thanks Jason Brownlee': 1,\n",
       " 'a Pipeline': 0,\n",
       " '5-repeated 10-fold CV': 0,\n",
       " 'Pipeline': 5,\n",
       " 'Reply Buz Fifer': 2,\n",
       " '#  ————': 0,\n",
       " '# ————': 0,\n",
       " 'a CNN': 22,\n",
       " 'nb_conv': 0,\n",
       " 'https://keras.io/layers/convolutional/ Reply': 0,\n",
       " 'Reply Bgie': 0,\n",
       " 'my CNN': 0,\n",
       " 'ImageDataGenerator': 4,\n",
       " 'https://machinelearningmastery.com/evaluate-skill-deep-learning-models/ Reply Shubham Kumar': 0,\n",
       " 'Reply Mustafa Murat ARAT': 2,\n",
       " '{‘neurons’': 0,\n",
       " 'dataset[:,4': 0,\n",
       " 'Wassim Reply Jason Brownlee': 0,\n",
       " 'train_on_batch': 0,\n",
       " 'Estelle Reply Jason Brownlee': 1,\n",
       " 'Reply Estelle December': 0,\n",
       " 'Daniel Pamplona': 0,\n",
       " 'Reply Sean December': 2,\n",
       " 'Hi Jason': 11,\n",
       " 'ValueError': 28,\n",
       " 'Reply Olivier Blais': 1,\n",
       " 'Parallel': 0,\n",
       " 'their val_loss': 0,\n",
       " 'Justin Reply Jason Brownlee': 0,\n",
       " 'Content Logistic Regression': 0,\n",
       " 'April': 42,\n",
       " 'Machine Learning Algorithms Share': 43,\n",
       " 'Learning Algorithm': 0,\n",
       " 'Logistic Regression Photo': 0,\n",
       " 'Michael Vadon': 0,\n",
       " 'Representation': 0,\n",
       " 'Free': 41,\n",
       " 'Logistic Regression': 31,\n",
       " 'Statistical Learning': 57,\n",
       " 'An Introduction': 2,\n",
       " 'Machine Learning Math': 43,\n",
       " 'Jason Brownlee → Linear Regression Tutorial': 0,\n",
       " 'Machine Learning Logistic Regression Tutorial': 0,\n",
       " 'Machine Learning Ahmaf': 0,\n",
       " 'training data Reply Jason Brownlee': 0,\n",
       " 'p(class=0': 1,\n",
       " 'Reply Rishu': 0,\n",
       " 'Nov’15-Oct’16': 0,\n",
       " 'July’16': 0,\n",
       " 'Jan-June’16': 0,\n",
       " 'Aug’16': 0,\n",
       " 'Rishabh Reply Jason Brownlee': 1,\n",
       " 'x. Reply Jason Brownlee': 0,\n",
       " '“An Introduction': 0,\n",
       " 'Reply Marjorie Escanan': 0,\n",
       " 'Reply vinay kumar': 0,\n",
       " 'Reply John Serpano': 0,\n",
       " 'Image Augmentation': 2,\n",
       " 'Content Image Augmentation': 0,\n",
       " 'June': 56,\n",
       " 'Comparison': 1,\n",
       " 'load_data': 1,\n",
       " \"K\\nK.set_image_dim_ordering('th\": 10,\n",
       " 'K K': 10,\n",
       " 'PCA': 22,\n",
       " 'the MNIST': 3,\n",
       " 'MNIST Images': 0,\n",
       " 'the width_shift_range': 0,\n",
       " '# Random Shifts': 0,\n",
       " 'MNIST': 21,\n",
       " '# Random Flips': 0,\n",
       " 'PNG': 1,\n",
       " 'pyplot.subplot(330': 0,\n",
       " '18 datagen.flow(X_train, y_train': 0,\n",
       " 'random_transform fill_mode': 0,\n",
       " 'X.': 3,\n",
       " 'segmentation Reply Sudesh': 0,\n",
       " 'datagen.flow(imgs_train': 0,\n",
       " 'Reply Addie': 0,\n",
       " 'this ImageGenerator': 0,\n",
       " 'Reply Lucas': 1,\n",
       " 'RGBXYZ': 0,\n",
       " 'RGB': 2,\n",
       " 'PCL(Point Cloud Library': 0,\n",
       " 'Reply Brian April': 0,\n",
       " '# Thanks Jason': 6,\n",
       " 'ImageGenerator': 0,\n",
       " 'November': 59,\n",
       " 'Reply Matthew Hancock': 1,\n",
       " 'the Image Data Generator': 0,\n",
       " 'the “Point': 0,\n",
       " 'Alice': 9,\n",
       " '1 7 Reply Jason Brownlee': 0,\n",
       " 'Reply john Landler': 0,\n",
       " 'i.e. Feature Standardization': 0,\n",
       " '‘th’': 0,\n",
       " 'C:\\\\ProgramData\\\\Anaconda3': 0,\n",
       " 'Example Feature Standardization': 0,\n",
       " 'https://keras.io/preprocessing/image/ Reply': 0,\n",
       " 'the Keras': 1,\n",
       " 'Xiaojie': 0,\n",
       " 'model.fit_generator': 6,\n",
       " 'Transfer Learning': 2,\n",
       " 'Reply Momo': 0,\n",
       " 'the val_acc': 0,\n",
       " 'keras.preprocessing.image.ImageDataGenerator': 0,\n",
       " 'evaluate_generator': 0,\n",
       " 'Machine Learning Algorithms - Machine Learning Mastery Navigation Machine Learning Mastery': 2,\n",
       " 'Home Empty Menu Return': 95,\n",
       " 'Machine Learning Algorithms Photo': 1,\n",
       " 'Joel Montes de Oca': 0,\n",
       " 'So Many Algorithms': 0,\n",
       " 'wikipedia': 1,\n",
       " 'DataTau': 0,\n",
       " 'Machine Learning Algorithms Ming Huang': 0,\n",
       " 'Reply Chris P': 0,\n",
       " 'July': 50,\n",
       " 'Martin Abegglen': 0,\n",
       " 'enumerate(alphabet': 24,\n",
       " 'One-Char Mapping': 5,\n",
       " 'dataX': 11,\n",
       " '# Naive LSTM': 3,\n",
       " 'Naive LSTM': 1,\n",
       " 'a Three-Char Feature Window': 0,\n",
       " 'a Three-Char Time Step Window': 0,\n",
       " 'your LSTM': 1,\n",
       " 'A Batch': 2,\n",
       " 'range(0,20': 0,\n",
       " '62 # Naive LSTM': 0,\n",
       " 'a\\xa0One-Char': 0,\n",
       " '# Stateful LSTM': 1,\n",
       " '“K': 0,\n",
       " '“J': 0,\n",
       " 'Variable-Length Input': 0,\n",
       " 'the Keras “stateful” LSTM': 0,\n",
       " 'alphabet[end': 1,\n",
       " 'theano.tensor.shared_randomstreams import RandomStreams': 0,\n",
       " 'numpy.random.seed(7': 4,\n",
       " '= \"ABCDEFGHIJKLMNOPQRSTUVWXYZ': 0,\n",
       " 'Keras Mark': 0,\n",
       " 'Reply Kilian': 0,\n",
       " 'Wikipedia': 49,\n",
       " 'GitHub': 28,\n",
       " 'https://github.com/batzner/tensorlm Reply Jason Brownlee': 0,\n",
       " 'Reply David Petit': 0,\n",
       " 'Shanbe': 0,\n",
       " 'the “LSTM State': 0,\n",
       " 'LSM': 0,\n",
       " 'a One-Char': 1,\n",
       " 'Reply Rodrigo Pinto': 0,\n",
       " 'Reply Wes March': 1,\n",
       " 'a Generative Adversarial Network': 0,\n",
       " 'a stateful LSTM': 6,\n",
       " 'Variable Length Input': 1,\n",
       " 'N-Char-Output': 0,\n",
       " 'enumerate(chars': 11,\n",
       " 'Reply Riccardo Folloni': 0,\n",
       " 'keras.preprocessing.sequence import pad_sequences Reply Jason Brownlee': 0,\n",
       " '#Learning Sine': 0,\n",
       " '= theano.shared(np.random.uniform(size=(n, nout': 0,\n",
       " 'W_in – lr': 0,\n",
       " 'training’': 0,\n",
       " 'range(len(testX': 1,\n",
       " 'Reply Louis Abraham': 0,\n",
       " 'this LSTM': 0,\n",
       " 'choice Fernando': 0,\n",
       " 'Reply leila': 0,\n",
       " 'Reply Melih May': 0,\n",
       " 'RNN': 40,\n",
       " 'Reply Reihaneh': 2,\n",
       " 'Reply Reihaneh Amini': 0,\n",
       " 'ABC -> BCD': 0,\n",
       " 'ABC-': 0,\n",
       " 'LSTM/RNN': 1,\n",
       " 'Orthogonal': 0,\n",
       " 'AAARS': 0,\n",
       " 'range(len(dataX': 1,\n",
       " 'Reply Dan DeDora': 0,\n",
       " 'the ‘Accuracy’': 1,\n",
       " 'an LSTM': 11,\n",
       " 'Philippe Remy': 0,\n",
       " 'Hochreiter': 3,\n",
       " 'The LSTM': 13,\n",
       " 'The stateful LSTM': 0,\n",
       " 'Reply Shirin Shadman': 0,\n",
       " 'Stateful LSTM': 7,\n",
       " 'One-Char': 0,\n",
       " 'BPTT': 20,\n",
       " 'Gradient Boosting': 13,\n",
       " 'XGBoost': 223,\n",
       " 'Python - Machine Learning Mastery Navigation Machine Learning Mastery': 79,\n",
       " 'Content Tune Learning Rate': 0,\n",
       " 'September': 60,\n",
       " 'XGBoost Share': 16,\n",
       " 'Python Photo': 66,\n",
       " 'Robert Hertel': 0,\n",
       " 'Slow Learning': 0,\n",
       " 'Gradient': 11,\n",
       " 'a Learning Rate Gradient': 0,\n",
       " 'Kaggle': 72,\n",
       " 'xgboost import XGBClassifier': 27,\n",
       " 'Log Loss': 13,\n",
       " 'XGBoost Next': 0,\n",
       " 'Trees': 7,\n",
       " 'enumerate(learning_rate': 0,\n",
       " 'learning_rate=0.1': 0,\n",
       " 'n_estimators': 0,\n",
       " 'Learning Rate=0.1': 0,\n",
       " 'XGBoost Summary': 1,\n",
       " 'Python Juan Agustin': 0,\n",
       " 'Reply Juan Agustin February': 0,\n",
       " 'Python Machine Learning': 84,\n",
       " 'Python Machine Learning Share': 40,\n",
       " 'Mac OS X. Python': 0,\n",
       " 'Install XCode XCode': 0,\n",
       " 'OS X. Installation': 0,\n",
       " 'XCode': 2,\n",
       " 'Install Macports Macports': 0,\n",
       " 'OS X.': 2,\n",
       " 'OS X': 1,\n",
       " 'Sierra': 0,\n",
       " 'Install SciPy': 0,\n",
       " '# pandas': 6,\n",
       " 'the filename versions.py': 0,\n",
       " 'Your First Machine Learning Project': 6,\n",
       " 'Keras Step': 5,\n",
       " 'Macports': 0,\n",
       " 'my Mac': 1,\n",
       " 'PyCharm': 3,\n",
       " 'which python Reply Phil Salm March': 0,\n",
       " 'Reply Phil Salm March': 0,\n",
       " 'Reply Nidhi Sharma April': 0,\n",
       " 'Reply PJ May': 0,\n",
       " 'ImportError': 5,\n",
       " 'THE TERMINAL': 0,\n",
       " 'A LIBEDIT / PYTHON INTERACTION ISSUE': 0,\n",
       " 'macholib==1.9 Markdown==2.6.11': 0,\n",
       " 'a Beginner': 3,\n",
       " 'Kaggle - Machine Learning Mastery Navigation Machine Learning Mastery': 1,\n",
       " 'Gareth James et al': 0,\n",
       " '“Data Science': 0,\n",
       " 'Data Analysis': 5,\n",
       " 'Excel': 9,\n",
       " 'Software Development': 0,\n",
       " 'an Excel Background': 0,\n",
       " 'RStudio': 3,\n",
       " 'Pandas': 59,\n",
       " 'R. R': 1,\n",
       " 'Q.': 1,\n",
       " 'Octave/Matlab': 0,\n",
       " 'the Small Projects Methodology': 0,\n",
       " 'Machine Learning Practitioner': 7,\n",
       " 'Brian Thomas': 2,\n",
       " 'ernest': 0,\n",
       " 'macOS - Machine Learning Mastery Navigation Machine Learning Mastery': 0,\n",
       " 'Install XGBoost': 0,\n",
       " 'macOS': 5,\n",
       " 'Google Plus Share XGBoost': 3,\n",
       " 'Install MacPorts': 0,\n",
       " 'macOS High Sierra': 0,\n",
       " 'GCC': 0,\n",
       " 'cli_main.o': 1,\n",
       " 'objective.o': 1,\n",
       " 'xgboost==0.6': 0,\n",
       " 'scikit-learn A Standard Multivariate': 0,\n",
       " 'How to Install XGBoost': 0,\n",
       " 'windows OS': 0,\n",
       " 'Reply Juliano Petronetto': 0,\n",
       " 'Docker': 1,\n",
       " 'https://github.com/petronetto/machine-learning-alpine Reply Jason Brownlee': 0,\n",
       " 'Reply Gabriel Kreplak': 0,\n",
       " 'Clever Application': 1,\n",
       " 'A Predictive Model - Machine Learning Mastery Navigation Machine Learning Mastery': 0,\n",
       " 'A Predictive Model': 2,\n",
       " 'Applied Predictive Modeling': 9,\n",
       " 'Official U.S. Navy Page': 0,\n",
       " 'Concrete Mixtures': 0,\n",
       " 'Fine': 0,\n",
       " 'the RMSE': 12,\n",
       " 'RSM': 0,\n",
       " 'Iterate': 0,\n",
       " 'Surrogate Modelling': 0,\n",
       " 'Data Pre-Processing Linear Classification': 0,\n",
       " 'Google Books': 0,\n",
       " 'HackerNews': 2,\n",
       " 'Beginning Machine Learning': 2,\n",
       " 'Reply Martin': 2,\n",
       " 'Reply Jamieson Pryor': 0,\n",
       " 'Reply Anthony FJ Garner': 0,\n",
       " 'ASM': 1,\n",
       " '# Python': 1,\n",
       " 'Content Self-Study Guide': 0,\n",
       " 'Scikit-Learn': 23,\n",
       " 'Reddit': 1,\n",
       " 'Self-Study Guide': 0,\n",
       " 'Mathematics': 16,\n",
       " 'R and Machine Learning': 0,\n",
       " 'Sr': 0,\n",
       " 'Reply Asif Ameer': 0,\n",
       " 'the caret homepage Estimating Model Accuracy': 0,\n",
       " 'Data': 48,\n",
       " 'k-fold Cross Validation': 3,\n",
       " 'Data Bootstrap': 0,\n",
       " 'Out Cross Validation': 2,\n",
       " 'fold cross validation Reply Jason Brownlee': 0,\n",
       " 'simplified Reply Jason Brownlee': 0,\n",
       " 'Repeated k-fold Cross Validation': 0,\n",
       " 'Cheers Tobias Reply Dev': 0,\n",
       " 'Reply Jim Callahan': 0,\n",
       " 'TPR': 2,\n",
       " 'TN': 0,\n",
       " '10-fold CV': 4,\n",
       " 'set.seed(123': 0,\n",
       " '# Caret Train': 0,\n",
       " 'lib.loc=”~/R': 0,\n",
       " 'number=10': 1,\n",
       " 'Estimating Model Accuracy’': 0,\n",
       " 'NaiveBayes.default(X': 0,\n",
       " 'Reply Hans May': 9,\n",
       " 'Y': 47,\n",
       " '# Repeated CV': 0,\n",
       " 'Reply Yones': 0,\n",
       " 'Cubist': 0,\n",
       " 'Reply Cesar Yona': 0,\n",
       " 'Reply Sanskriti': 0,\n",
       " 'a LOOCV': 0,\n",
       " 'Duncan Reply Jason Brownlee': 0,\n",
       " 'Mansur Reply': 0,\n",
       " 'Time Series Forecasting - Machine Learning Mastery Navigation Machine Learning Mastery': 13,\n",
       " 'Time Series Forecasting': 268,\n",
       " 'L1': 2,\n",
       " 'Time Series Forecasting Photo': 12,\n",
       " 'Julian Fong': 0,\n",
       " 'Results Environment': 5,\n",
       " 'either the TensorFlow': 27,\n",
       " 'Anaconda Next': 1,\n",
       " 'Makridakis': 21,\n",
       " 'a Pandas Series': 37,\n",
       " 'Baseline LSTM Model': 1,\n",
       " 'sklearn.metrics import mean_squared_error': 33,\n",
       " 'import L1L2': 0,\n",
       " 'range(interval': 37,\n",
       " 'range(n_repeats': 17,\n",
       " '= test_scaled[:,0:-1': 11,\n",
       " 'range(len(output': 16,\n",
       " 'regularizers import L1L2': 0,\n",
       " 'Baseline Performance': 3,\n",
       " 'the L1': 0,\n",
       " 'Regularizers': 0,\n",
       " 'Bias Weight Regularization Performance': 0,\n",
       " 'the Shampoo Sales Dataset Input Weight Regularization': 0,\n",
       " 'the test RMSE': 4,\n",
       " 'Input Weight Regularization Performance': 0,\n",
       " 'the Shampoo Sales Dataset Recurrent Weight Regularization': 0,\n",
       " 'Recurrent Weight Regularization Performance': 0,\n",
       " 'a Supervised Learning Problem': 13,\n",
       " 'Time Series Forecasting Alex': 0,\n",
       " 'Reply Alex May': 3,\n",
       " 'True) data[‘returns’]=np.log(data/data.shift(1': 0,\n",
       " 'DNNClassifier(feature_columns=fc': 0,\n",
       " '] training_data[‘prediction’]=np.where(pred>0,1,-1) training_data[‘strategy’]=training_data[‘prediction’]*training_data[‘returns’': 0,\n",
       " 'Reply Birkey': 1,\n",
       " '4 (n_batch=4': 0,\n",
       " 'Reply jinhua zhang': 0,\n",
       " 'the IDE': 1,\n",
       " 'Konstantin Slisenko - Machine Learning Mastery Navigation Machine Learning Mastery': 0,\n",
       " 'Content Project': 2,\n",
       " 'Konstantin Slisenko': 1,\n",
       " 'Belarus': 0,\n",
       " 'the Belarusian State University': 0,\n",
       " 'Informatics': 0,\n",
       " 'Apache Hadoop': 1,\n",
       " 'Apache Mahout': 0,\n",
       " 'Frank Scholten': 0,\n",
       " 'Mahout': 3,\n",
       " 'Action': 8,\n",
       " 'Stackexchange': 0,\n",
       " 'Stack Exchange Clustering': 0,\n",
       " 'GitHub Konstantin': 0,\n",
       " 'Konstantin': 1,\n",
       " 'Association Rule Learning': 1,\n",
       " 'Konstantin Slisenko Konstantin Slisenko March': 0,\n",
       " 'LSTMs - Machine Learning Mastery Navigation Machine Learning Mastery': 0,\n",
       " 'Google Plus Share Keras': 10,\n",
       " 'Batch Size Sequence Prediction Problem Description LSTM Model': 0,\n",
       " 'range(n_epoch': 9,\n",
       " 'testX': 5,\n",
       " 'Tensor': 1,\n",
       " \"(9, 1, 1)' 1 ValueError\": 0,\n",
       " 'Expected=0.3': 3,\n",
       " 'Expected=0.0, Predicted=0.0': 4,\n",
       " 'range(len(y': 1,\n",
       " 'a Long Short-Term Memory Network': 5,\n",
       " 'LSTMs Sam Taha': 0,\n",
       " 'Reply Logan May': 3,\n",
       " 'Reply Jason Ho May': 0,\n",
       " 'Reply Kim Miller': 9,\n",
       " 'DRL': 0,\n",
       " 'Reply Dimitar': 0,\n",
       " 'Hello Dr. Brownlee': 1,\n",
       " '= j Reply Jason Brownlee': 0,\n",
       " 'stateful LSTM': 1,\n",
       " 'stateless LSTM': 0,\n",
       " 'stateful LSTMs': 0,\n",
       " 'Reply Michael Dipperstein': 0,\n",
       " 'https://machinelearningmastery.com/evaluate-skill-deep-learning-models/ Reply Michael Dipperstein': 0,\n",
       " 'Reply Alex Loosley': 0,\n",
       " 'Reply Anton': 1,\n",
       " 'Content Linear Discriminant Analysis': 0,\n",
       " 'Linear Discriminant Analysis': 7,\n",
       " 'LDA': 30,\n",
       " 'Jamie McCaffrey': 0,\n",
       " 'LDA Models': 0,\n",
       " 'the multivariate Gaussian': 0,\n",
       " 'Learning LDA Models LDA': 0,\n",
       " 'muk': 0,\n",
       " 'K': 11,\n",
       " 'LDA LDA': 0,\n",
       " 'Bayes’ Theorem': 2,\n",
       " 'The f(x': 4,\n",
       " 'f(x': 0,\n",
       " 'LDA Linear Discriminant Analysis': 0,\n",
       " 'Multiple Discriminant Analysis': 0,\n",
       " 'Machine Learning Deep Learning': 1,\n",
       " 'Machine Learning Shaksham Kapoor': 0,\n",
       " 'PII': 0,\n",
       " 'Reply Pia Laine': 3,\n",
       " 'fk(x': 0,\n",
       " 'P(X': 1,\n",
       " 'Madeleine Reply Jason Brownlee': 0,\n",
       " 'The Python conference PyCon2014': 0,\n",
       " 'Melanie Warrick': 1,\n",
       " 'Melanie': 2,\n",
       " 'Arthur Samuel': 0,\n",
       " 'She': 0,\n",
       " 'Artificial Intelligence': 18,\n",
       " 'contracting Python': 0,\n",
       " 'Python Federico Pascual': 0,\n",
       " 'Reply Federico Pascual': 0,\n",
       " 'Mitchell’s Machine Learning Tom Mitchell': 0,\n",
       " 'T': 4,\n",
       " 'Pattern Recognition Bishop': 0,\n",
       " 'Bishop': 0,\n",
       " 'An Algorithmic Perspective Marsland': 0,\n",
       " 'Venn Diagram': 0,\n",
       " 'Drew Conway': 3,\n",
       " 'Creative Commons': 0,\n",
       " 'Marsland': 2,\n",
       " 'Mitchell': 3,\n",
       " 'Hastie': 0,\n",
       " 'Bishop Machine Learning': 0,\n",
       " 'Hackers Question': 0,\n",
       " 'Quora': 17,\n",
       " 'Stack Overflow': 1,\n",
       " 'Machine Learning –': 0,\n",
       " 'Qual': 0,\n",
       " 'Reply Lucas Lopes': 1,\n",
       " 'Mas': 0,\n",
       " 'Reply Idrees': 0,\n",
       " 'Reply Jim Kitzmiller': 3,\n",
       " 'Reply Bolanle': 0,\n",
       " 'Health': 0,\n",
       " 'Reply Phillip': 0,\n",
       " 'Reply Jesús December': 0,\n",
       " 'Microsoft Azure - Machine Learning Mastery Navigation Machine Learning Mastery': 0,\n",
       " 'Content Choosing Machine Learning Algorithms': 0,\n",
       " 'Microsoft Azure': 3,\n",
       " 'Google Plus Share Microsoft': 0,\n",
       " 'USDA': 0,\n",
       " 'Machine Learning Algorithm Cheatsheet Microsoft': 0,\n",
       " 'Azure': 1,\n",
       " 'the Background': 5,\n",
       " 'Mathematics Understand Machine Learning Algorithms': 0,\n",
       " 'Scratch': 117,\n",
       " 'Reply Déborah Mesquita': 0,\n",
       " 'ML world Reply Jason Brownlee': 0,\n",
       " 'Scratch Share': 18,\n",
       " 'Amanda B': 0,\n",
       " 'RFC': 0,\n",
       " 'Floats': 1,\n",
       " 'Integers': 1,\n",
       " 'range(len(dataset[0': 31,\n",
       " 'range(4': 6,\n",
       " 'Iris-setosa': 0,\n",
       " 'Code Algorithms': 18,\n",
       " 'Math': 19,\n",
       " 'Your\\xa0First Algorithm': 18,\n",
       " 'Linear Regression': 35,\n",
       " 'The Machine Learning Mastery': 1,\n",
       " 'Python SalemAmeen': 0,\n",
       " 'a CSV': 9,\n",
       " 'your Deep Learning': 0,\n",
       " 'Pima D.S.': 0,\n",
       " 'Reply Ray T April': 0,\n",
       " 'Python 3.5 Reply Jason Brownlee': 0,\n",
       " 'RATNA NITIN PATIL July': 0,\n",
       " 'Reply Milan Modak December': 0,\n",
       " 'Pedro Ribeiro Simões': 0,\n",
       " 'Ensembles': 4,\n",
       " 'the classic Neural Net FAQ': 0,\n",
       " 'Invent': 0,\n",
       " 'a skewed Gaussian': 0,\n",
       " 'Feature Selection Feature Selection': 1,\n",
       " 'Improve Performance': 2,\n",
       " 'the short list Spot-Check Algorithms': 0,\n",
       " 'Literature': 2,\n",
       " 'LVQ, MLP, CNN': 0,\n",
       " 'your Machine Learning Problems Spot-Check Classification Machine Learning Algorithms': 0,\n",
       " 'Model Accuracy': 2,\n",
       " 'Keras Overfitting': 0,\n",
       " 'Regularization Regularization': 0,\n",
       " 'Dropout': 11,\n",
       " 'Weight Decay': 0,\n",
       " 'Stochastic Gradient Descent': 26,\n",
       " 'the more traditional (Levenberg-Marquardt': 0,\n",
       " 'Xu Lu': 0,\n",
       " 'Reply Nitin': 0,\n",
       " 'Reply Daisuke': 0,\n",
       " 'Semantic Segmentation': 0,\n",
       " 'Reply Max S.': 0,\n",
       " 'Reply KERKENI L. March': 0,\n",
       " 'Matlab': 11,\n",
       " 'Linear SVM': 0,\n",
       " 'Nunu Reply Jason Brownlee': 4,\n",
       " 'RMSE': 38,\n",
       " 'Reply Danny': 1,\n",
       " 'Reply K.D.': 0,\n",
       " 'Rescale Your Data': 0,\n",
       " 'Reply Amina': 1,\n",
       " 'Alan Reply Jason Brownlee': 1,\n",
       " 'Pavs December': 0,\n",
       " 'Reply Fredrik January': 0,\n",
       " 'Reply Tony January': 0,\n",
       " 'brendan-c': 0,\n",
       " 'Steve Pavlina': 0,\n",
       " 'Self-Study Machine Learning': 2,\n",
       " 'Jason Reply Jason Brownlee': 11,\n",
       " 'Reply Roberto May': 0,\n",
       " 'Reply Rex May': 0,\n",
       " 'Reply Kleyn Guerreiro': 2,\n",
       " 'Coursera': 16,\n",
       " 'Reply Maanav': 0,\n",
       " 'India': 2,\n",
       " 'Maanav': 0,\n",
       " 'UG': 0,\n",
       " 'Reply Jessica': 1,\n",
       " 'Bayesian Network': 0,\n",
       " '# Machine Learning': 0,\n",
       " 'PG': 1,\n",
       " 'Data Analytics': 1,\n",
       " 'Maths/Stats': 0,\n",
       " 'Ecuador Reply': 0,\n",
       " 'thanks Reply Jason Brownlee': 0,\n",
       " 'Mr Jason Brownlee Reply Jason Brownlee': 0,\n",
       " 'Reply T.D.Nuwan Chathuranga': 0,\n",
       " 'Learning ML': 0,\n",
       " 'US': 1,\n",
       " 'Reply Satya Prakash Sharma': 0,\n",
       " 'Android Developing': 0,\n",
       " 'All Password Manage': 0,\n",
       " 'Even quora': 0,\n",
       " 'Prof. Reply Jason Brownlee': 0,\n",
       " 'Reply Shridhar October': 0,\n",
       " 'Reply Laeeq Khan': 0,\n",
       " 'John Bates': 0,\n",
       " 'CS': 1,\n",
       " 'Reply Rohit Kumar': 0,\n",
       " '“Parth': 0,\n",
       " 'MahaBharat': 0,\n",
       " 'Basic ML': 0,\n",
       " 'Emmanuel Gunti': 0,\n",
       " 'Computer Hardware': 1,\n",
       " 'Content Computer Hardware': 0,\n",
       " 'a Data Center': 0,\n",
       " 'Machine Learning Mark': 0,\n",
       " 'decent GPU': 0,\n",
       " 'Reply Rohan': 0,\n",
       " 'AMD': 0,\n",
       " 'https://machinelearningmastery.com/crash-course-statistics-machine-learning/ Reply': 0,\n",
       " 'Sentiment Analysis - Machine Learning Mastery Navigation Machine Learning Mastery': 1,\n",
       " 'Text': 65,\n",
       " 'Sentiment Analysis': 3,\n",
       " 'Natural Language Processing Share': 46,\n",
       " 'Sentiment Analysis Photo': 1,\n",
       " 'Ed Dunens': 2,\n",
       " 'Dataset Data Preparation': 0,\n",
       " 'Text Data': 45,\n",
       " 'Movie Review Dataset The Movie Review Data': 1,\n",
       " 'Bo Pang': 4,\n",
       " 'Minimum Cuts': 10,\n",
       " 'listdir(directory': 35,\n",
       " 'a directory def process_docs': 21,\n",
       " 'wb': 3,\n",
       " 'The function max_length': 0,\n",
       " 'the prepared Tokenizer': 0,\n",
       " 'Yoon Kim': 1,\n",
       " 'Sentence Classification': 12,\n",
       " 'Kim': 3,\n",
       " 'keras.preprocessing.text import Tokenizer': 14,\n",
       " 'the Multichannel Convolutional Neural Network': 0,\n",
       " 'load_model': 0,\n",
       " 'Text Data Today': 46,\n",
       " 'Natural Language Processing': 138,\n",
       " '-Words': 46,\n",
       " 'Sentiment Analysis Hitkul': 0,\n",
       " 'Reply Adnan ÖNCEVARLIK': 0,\n",
       " 'Reply Sébastien January': 0,\n",
       " 'Model': 4,\n",
       " 'Rui January': 0,\n",
       " 'Reply Dev January': 0,\n",
       " 'Text Data Cut': 46,\n",
       " 'NLP': 109,\n",
       " 'Content Building': 0,\n",
       " 'Google Plus': 2,\n",
       " 'Share Midwest.io': 0,\n",
       " 'Kansas City': 0,\n",
       " 'Josh Wills': 2,\n",
       " 'Cloudera': 4,\n",
       " 'Data Science Josh': 0,\n",
       " 'Industrial Machine Learning Josh': 0,\n",
       " 'Josh': 5,\n",
       " 'Oryx': 0,\n",
       " 'Airbnb': 0,\n",
       " 'Hadoop': 10,\n",
       " 'Feature Engineering Josh': 0,\n",
       " 'Supernova Schema': 0,\n",
       " 'Josh Wills’': 1,\n",
       " 'Midwest.io': 0,\n",
       " 'Linkedin': 0,\n",
       " 'Reply José Pedro Almeida': 0,\n",
       " 'industrial ML Reply': 0,\n",
       " '? - Machine Learning Mastery Navigation Machine Learning Mastery': 0,\n",
       " 'Google Plus Share Machine Learning': 2,\n",
       " 'Progenitors Algorithms': 0,\n",
       " 'Computational Intelligence': 2,\n",
       " 'Andries Engelbrecht': 0,\n",
       " 'Machine Learning Data': 13,\n",
       " 'Matt May': 0,\n",
       " 'Matt Reply': 0,\n",
       " 'Cognitive Computing': 0,\n",
       " 'Reply Carlos Lee March': 0,\n",
       " 'Reply Howard Schneider': 1,\n",
       " 'Kevin Markham': 0,\n",
       " 'Video Series Overview Kevin Markham': 0,\n",
       " 'General Assembly': 0,\n",
       " 'Kevin': 0,\n",
       " 'Mark': 11,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing to file!!!\n"
     ]
    }
   ],
   "source": [
    "### Step 8: Write JSON data in text format in `scrubbed_machine_learning_mastery.json` ###\n",
    "\n",
    "# write scrubbed JSON to `scrubbed_machine_learning_mastery.json`\n",
    "import json\n",
    "with open('extract_keywords.json', 'w') as outfile:\n",
    "     json.dump(keywords, outfile, sort_keys = True, indent = 4,\n",
    "               ensure_ascii = False)\n",
    "print('Done writing to file!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------ Below are the experimentations with textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textacy\n",
    "\n",
    "# !pip uninstall -y textacy[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "### Step 1: Import necessary packages here ###\n",
    "\n",
    "import csv\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# feedparser helps to xml to hash\n",
    "# Install: conda install feedparser\n",
    "import feedparser\n",
    "\n",
    "# BeautifulSoup helps to grab text out of html\n",
    "# Install: conda install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import json\n",
    "import urllib3\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import newspaper\n",
    "from newspaper import Article\n",
    "from pandas import read_csv\n",
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "import textacy\n",
    "import textacy.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 4,\n",
       " 'apparent symmetry': 1,\n",
       " 'baryon numb': 1,\n",
       " 'electric charge': 1,\n",
       " 'fractional electric': 1,\n",
       " 'fundamental relationship': 1,\n",
       " 'hypothetical color': 1,\n",
       " 'lepton family': 1,\n",
       " 'model theory': 1,\n",
       " 'standard model': 2,\n",
       " 'the apparent': 1,\n",
       " 'triplet boson': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = '''\n",
    "     The apparent symmetry between the quark and lepton families of\n",
    "     the Standard Model (SM) are, at the very least, suggestive of\n",
    "     a more fundamental relationship between them. In some Beyond the\n",
    "     Standard Model theories, such interactions are mediated by\n",
    "     leptoquarks (LQs): hypothetical color-triplet bosons with both\n",
    "     lepton and baryon number and fractional electric charge.'''\n",
    "metadata = {\n",
    "     'title': 'A Search for 2nd-generation Leptoquarks at √s = 7 TeV',\n",
    "     'author': 'Burton DeWilde',\n",
    "     'pub_date': '2012-08-01'}\n",
    "doc = textacy.Doc(content)\n",
    "# print(doc)\n",
    "\n",
    "doc.to_bag_of_terms(ngrams=2, named_entities=True,lemmatize=True, as_strings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 35,\n",
       " '# create 100': 2,\n",
       " '+ 0.3': 4,\n",
       " '+ b': 5,\n",
       " '-PRON- be': 1,\n",
       " '-PRON- could': 1,\n",
       " '-PRON- cover': 1,\n",
       " '-PRON- first': 3,\n",
       " '-PRON- first neural network': 1,\n",
       " '-PRON- free': 1,\n",
       " '-PRON- goal': 1,\n",
       " '-PRON- intend': 1,\n",
       " '-PRON- know': 2,\n",
       " '-PRON- learn': 1,\n",
       " '-PRON- own': 1,\n",
       " '-PRON- progress': 1,\n",
       " '-PRON- show': 1,\n",
       " '-PRON- tensorflow': 1,\n",
       " '-PRON- think': 2,\n",
       " '0': 3,\n",
       " '0.1': 8,\n",
       " '0.1 +': 4,\n",
       " '0.1000006': 2,\n",
       " '0.10000207': 2,\n",
       " '0.10000713': 2,\n",
       " '0.10002445': 2,\n",
       " '0.10008363': 2,\n",
       " '0.10028629': 2,\n",
       " '0.1009799': 2,\n",
       " '0.10335406': 2,\n",
       " '0.11148042': 2,\n",
       " '0.13929555': 2,\n",
       " '0.2629351': 2,\n",
       " '0.27992988': 2,\n",
       " '0.28697217': 2,\n",
       " '0.2941364': 2,\n",
       " '0.29828694': 2,\n",
       " '0.29995731': 2,\n",
       " '0.29999638': 2,\n",
       " '0.29999897': 2,\n",
       " '0.29999971': 2,\n",
       " '0.3': 4,\n",
       " '0.3 x_data': 1,\n",
       " '0.5': 1,\n",
       " '1': 4,\n",
       " '1 /usr': 1,\n",
       " '1 2': 3,\n",
       " '1 2 3 4 5': 1,\n",
       " '1 42': 1,\n",
       " '1 python': 1,\n",
       " '1.0': 2,\n",
       " '10': 2,\n",
       " '10 11': 2,\n",
       " '10 response': 1,\n",
       " '100': 3,\n",
       " '100 phony': 2,\n",
       " '11 12': 1,\n",
       " '12 13': 1,\n",
       " '120': 2,\n",
       " '12:00 pm': 1,\n",
       " '13': 1,\n",
       " '13 14': 1,\n",
       " '14 15': 1,\n",
       " '140': 2,\n",
       " '15 16': 1,\n",
       " '16': 1,\n",
       " '16 17': 1,\n",
       " '160': 2,\n",
       " '17': 1,\n",
       " '17 18': 1,\n",
       " '18 19': 1,\n",
       " '180': 2,\n",
       " '19': 1,\n",
       " '19 20': 1,\n",
       " '1:18': 1,\n",
       " '2 3': 3,\n",
       " '2-week': 1,\n",
       " '2-week email': 1,\n",
       " '2.0 open': 1,\n",
       " '2.7': 2,\n",
       " '20': 5,\n",
       " '20 21': 1,\n",
       " '20 =': 2,\n",
       " '200': 2,\n",
       " '201': 1,\n",
       " '2015': 1,\n",
       " '2016 how': 2,\n",
       " '2016 multivariate': 1,\n",
       " '2016 regression': 1,\n",
       " '2016 time': 2,\n",
       " '2016 ©': 1,\n",
       " '2017 develop': 1,\n",
       " '2017 multi': 1,\n",
       " '2017 sequence': 1,\n",
       " '2018': 1,\n",
       " '2018 machine': 1,\n",
       " '21 22': 1,\n",
       " '22 23': 1,\n",
       " '23 24': 1,\n",
       " '24': 1,\n",
       " '24 25': 1,\n",
       " '25': 1,\n",
       " '25 26': 1,\n",
       " '26': 1,\n",
       " '26 27': 1,\n",
       " '27': 1,\n",
       " '27 28': 1,\n",
       " '28 29': 1,\n",
       " '29 30': 1,\n",
       " '3 4': 3,\n",
       " '3.3 +': 1,\n",
       " '30 31': 1,\n",
       " '31 32': 1,\n",
       " '32': 1,\n",
       " '32 33': 1,\n",
       " '33 import': 1,\n",
       " '4 5': 3,\n",
       " '40': 2,\n",
       " '42': 1,\n",
       " '42 1': 1,\n",
       " '42 linear': 1,\n",
       " '5 6': 2,\n",
       " '5 import': 1,\n",
       " '5:49 pm': 1,\n",
       " '6 7': 2,\n",
       " '60': 2,\n",
       " '6:19 pm': 1,\n",
       " '6:38': 1,\n",
       " '7 8': 2,\n",
       " '7:33 pm': 1,\n",
       " '7:55': 1,\n",
       " '8 9': 2,\n",
       " '80': 2,\n",
       " '8:33': 1,\n",
       " '9': 1,\n",
       " '9 10': 2,\n",
       " '9:35': 1,\n",
       " '9:58 pm': 1,\n",
       " '= 0': 2,\n",
       " '= =': 2,\n",
       " '= float32': 44,\n",
       " '= np': 1,\n",
       " '= np.random.rand(100).astype(np.float32': 1,\n",
       " '= optimizer': 1,\n",
       " '= optimizer.minimize(loss': 1,\n",
       " '= tf': 13,\n",
       " '= tf.constant(10': 1,\n",
       " '= tf.constant(32': 1,\n",
       " '= tf.initialize_all_variables': 1,\n",
       " '= tf.reduce_mean(tf.square(y': 1,\n",
       " '= tf.train.gradientdescentoptimizer(0.5': 1,\n",
       " '= w': 4,\n",
       " '= x': 2,\n",
       " '= x_data': 2,\n",
       " 'a network': 1,\n",
       " 'about contact': 1,\n",
       " 'about jason': 1,\n",
       " 'abstract computation': 1,\n",
       " 'academic researcher': 1,\n",
       " 'academics': 1,\n",
       " 'ahmed august': 1,\n",
       " 'ale september': 1,\n",
       " 'all rights': 1,\n",
       " 'also check': 1,\n",
       " 'amit': 1,\n",
       " 'amit kumar': 1,\n",
       " 'an operation': 1,\n",
       " 'anaconda': 1,\n",
       " 'anaconda march': 1,\n",
       " 'apache': 1,\n",
       " 'apache 2.0': 1,\n",
       " 'api': 1,\n",
       " 'apply machine': 2,\n",
       " 'april 20': 1,\n",
       " 'april 20 , 2017': 1,\n",
       " 'april 21': 1,\n",
       " 'april 21 , 2017': 1,\n",
       " 'april 7': 1,\n",
       " 'asesh april': 1,\n",
       " 'attention mechanism': 1,\n",
       " 'august 14': 1,\n",
       " 'august 14 , 2017': 1,\n",
       " 'august 9': 3,\n",
       " 'august 9 , 2016': 1,\n",
       " 'august 9 , 2017': 2,\n",
       " 'b 0.3': 2,\n",
       " 'b =': 4,\n",
       " 'basic usage': 1,\n",
       " 'batch skip': 1,\n",
       " 'be dr.': 1,\n",
       " 'be not': 1,\n",
       " 'before start': 2,\n",
       " 'blog book': 1,\n",
       " 'book about': 1,\n",
       " 'bracket valid': 1,\n",
       " 'bring deep': 1,\n",
       " 'brownlee april': 1,\n",
       " 'brownlee august': 1,\n",
       " 'brownlee dr.': 1,\n",
       " 'brownlee february': 1,\n",
       " 'brownlee november': 1,\n",
       " 'brownlee september': 1,\n",
       " 'brownlee →': 1,\n",
       " 'by jason': 1,\n",
       " 'c++': 1,\n",
       " 'c++ api': 1,\n",
       " 'cancel reply': 1,\n",
       " 'cifar-10': 1,\n",
       " 'cifar-10 network': 1,\n",
       " 'class classification': 1,\n",
       " 'classification tutorial': 1,\n",
       " 'close bracket': 1,\n",
       " 'cnn': 1,\n",
       " 'code work': 1,\n",
       " 'comment name': 1,\n",
       " 'compute create': 1,\n",
       " 'compute y_data': 2,\n",
       " 'contact need': 1,\n",
       " 'contact |': 1,\n",
       " 'content introduction': 1,\n",
       " 'convolutional mnist': 1,\n",
       " 'convolutional nets': 1,\n",
       " 'convolutional nets and recurrent neural nets': 1,\n",
       " 'could develop': 1,\n",
       " 'course home': 1,\n",
       " 'course now': 1,\n",
       " 'cover self': 1,\n",
       " 'cpu system': 1,\n",
       " 'crash course': 1,\n",
       " 'create 100': 2,\n",
       " 'create deep': 1,\n",
       " 'cuda': 1,\n",
       " 'cuda toolkit': 3,\n",
       " 'datum flow': 1,\n",
       " 'datum point': 2,\n",
       " 'deep learn': 3,\n",
       " 'deep learning': 21,\n",
       " 'deep learning in python': 1,\n",
       " 'deep learning like theano': 1,\n",
       " 'deep learning share on': 1,\n",
       " 'deep learning with python': 1,\n",
       " 'deepdream': 1,\n",
       " 'deepdream project': 1,\n",
       " 'define constant': 1,\n",
       " 'define variable': 1,\n",
       " 'develop -PRON-': 1,\n",
       " 'develop a': 1,\n",
       " 'developer awesome': 1,\n",
       " 'developers introduction': 1,\n",
       " 'different dataset': 1,\n",
       " 'different network': 1,\n",
       " 'different way': 1,\n",
       " 'dimensional array': 1,\n",
       " 'direct graph': 1,\n",
       " 'discover mlp': 1,\n",
       " 'distribute system': 1,\n",
       " 'distributed systems': 1,\n",
       " 'docker image': 1,\n",
       " 'download': 2,\n",
       " 'dr. jason': 2,\n",
       " 'dtype =': 44,\n",
       " 'e.g. w': 1,\n",
       " 'ebook': 2,\n",
       " 'ebook version': 1,\n",
       " 'email course': 1,\n",
       " 'empty menu': 1,\n",
       " 'end project': 2,\n",
       " 'example come': 1,\n",
       " 'example directory': 1,\n",
       " 'example display': 1,\n",
       " 'example print': 1,\n",
       " 'example show': 1,\n",
       " 'example wait': 1,\n",
       " 'excellent list': 1,\n",
       " 'facebook share': 2,\n",
       " 'facebook share share': 1,\n",
       " 'fancy math': 1,\n",
       " 'fast numerical': 3,\n",
       " 'february 7': 1,\n",
       " 'february 7 , 2017': 1,\n",
       " 'february 8': 1,\n",
       " 'february 8 , 2017': 1,\n",
       " 'finally bring': 1,\n",
       " 'finally get': 1,\n",
       " 'find value': 2,\n",
       " 'first': 1,\n",
       " 'first machine': 1,\n",
       " 'first neural': 1,\n",
       " 'firstly': 1,\n",
       " 'fit': 2,\n",
       " 'follow output': 1,\n",
       " 'follow python': 1,\n",
       " 'for example': 3,\n",
       " 'foundation library': 1,\n",
       " 'free 2-week': 1,\n",
       " 'free mini': 2,\n",
       " 'free mini - course home empty menu return to content introduction to the python deep learning library tensorflow': 1,\n",
       " 'free pdf': 1,\n",
       " 'frustrate with': 1,\n",
       " 'fun deepdream': 1,\n",
       " 'get start': 2,\n",
       " 'github tensorflow': 1,\n",
       " 'google': 3,\n",
       " 'google plus': 2,\n",
       " 'google plus share': 1,\n",
       " 'google plus share tensorflow': 1,\n",
       " 'google search': 1,\n",
       " 'gpu': 2,\n",
       " 'gram model': 2,\n",
       " 'graph define': 1,\n",
       " 'great help': 1,\n",
       " 'grid search': 1,\n",
       " 'grid search hyperparameters': 1,\n",
       " 'help developer': 1,\n",
       " 'here blog': 1,\n",
       " 'heterogeneous distributed': 1,\n",
       " 'heterogeneous distributed systems': 1,\n",
       " 'hi jason': 2,\n",
       " 'home empty': 1,\n",
       " 'homepage tensforflow': 1,\n",
       " 'hundred': 1,\n",
       " 'if -PRON-': 1,\n",
       " 'import inspect': 2,\n",
       " 'import numpy': 2,\n",
       " 'import os': 2,\n",
       " 'import tensorflow': 6,\n",
       " 'in deep': 1,\n",
       " 'init =': 2,\n",
       " 'input attribute': 1,\n",
       " 'install tensorflow': 1,\n",
       " 'installation come': 1,\n",
       " 'jason': 2,\n",
       " 'jason -PRON-': 1,\n",
       " 'jason brownlee': 10,\n",
       " 'jason in': 1,\n",
       " 'jatin': 1,\n",
       " 'jatin november': 1,\n",
       " 'july 21': 1,\n",
       " 'july 21 , 2016': 1,\n",
       " 'july 26': 1,\n",
       " 'july 26 , 2016': 1,\n",
       " 'june 10': 1,\n",
       " 'june 10 , 2016': 1,\n",
       " 'june 2': 1,\n",
       " 'june 9': 1,\n",
       " 'keras': 3,\n",
       " 'keras august': 2,\n",
       " 'keras deep': 2,\n",
       " 'keras deep learning library': 1,\n",
       " 'keras deep learning library june 2 , 2016': 1,\n",
       " 'keras july': 2,\n",
       " 'keras step': 1,\n",
       " 'keras step - by - step': 1,\n",
       " 'kumar february': 1,\n",
       " 'large deep': 1,\n",
       " 'large scale': 1,\n",
       " 'launch': 2,\n",
       " 'learn 10': 1,\n",
       " 'learn model': 2,\n",
       " 'learn practitioner': 1,\n",
       " 'learn start': 1,\n",
       " 'learning developers': 1,\n",
       " 'learning library': 6,\n",
       " 'learning like': 1,\n",
       " 'learning mastery': 4,\n",
       " 'learning model': 2,\n",
       " 'learning models': 2,\n",
       " 'learning project': 1,\n",
       " 'learning share': 1,\n",
       " 'learning sick': 1,\n",
       " 'learning to': 1,\n",
       " 'learning with': 1,\n",
       " 'learns': 2,\n",
       " 'learns well': 2,\n",
       " 'lenet-5-like convolutional': 1,\n",
       " 'let -PRON-': 1,\n",
       " 'library intend': 1,\n",
       " 'library june': 1,\n",
       " 'library tensorflow': 4,\n",
       " 'like comment': 1,\n",
       " 'like theano': 1,\n",
       " 'like you': 1,\n",
       " 'linear regression': 1,\n",
       " 'linkedin share': 2,\n",
       " 'linkedin share share': 2,\n",
       " 'linux': 3,\n",
       " 'long short': 1,\n",
       " 'long short - term memory network': 1,\n",
       " 'loss =': 2,\n",
       " 'lstm recurrent': 2,\n",
       " 'lstm recurrent neural networks': 1,\n",
       " 'lstms': 1,\n",
       " 'mac os': 1,\n",
       " 'machine learn': 4,\n",
       " 'machine learning': 9,\n",
       " 'machine learning developers introduction to machine learning': 1,\n",
       " 'machine learning mastery': 1,\n",
       " 'machine learning mastery hi': 1,\n",
       " 'main tensorflow': 1,\n",
       " 'make developer': 1,\n",
       " 'march 13': 1,\n",
       " 'march 13 , 2017': 1,\n",
       " 'mastery hi': 1,\n",
       " 'mastery make': 1,\n",
       " 'mastery navigation': 1,\n",
       " 'may 24': 1,\n",
       " 'may 24 , 2016': 1,\n",
       " 'may 5': 1,\n",
       " 'may 5 , 2016': 1,\n",
       " 'mean square': 2,\n",
       " 'memory network': 1,\n",
       " 'menu return': 1,\n",
       " 'minimize': 2,\n",
       " 'mnist': 2,\n",
       " 'mnist dataset': 1,\n",
       " 'mnist model': 1,\n",
       " 'mobile device': 1,\n",
       " 'model directly': 1,\n",
       " 'model example': 1,\n",
       " 'model folder': 1,\n",
       " 'model subdirectory': 1,\n",
       " 'models -PRON-': 1,\n",
       " 'modify version': 1,\n",
       " 'more deep': 1,\n",
       " 'more finally': 1,\n",
       " 'more resources': 1,\n",
       " 'multi - class classification tutorial': 1,\n",
       " 'multilayer perceptrons': 1,\n",
       " 'multiply operation': 1,\n",
       " 'multivariate time': 1,\n",
       " 'multivariate time series forecasting with': 1,\n",
       " 'name': 1,\n",
       " 'name abstract': 1,\n",
       " 'navigation machine': 1,\n",
       " 'need help': 2,\n",
       " 'network': 1,\n",
       " 'network right': 1,\n",
       " 'network type': 1,\n",
       " 'neural nets': 1,\n",
       " 'neural network': 1,\n",
       " 'neural networks': 2,\n",
       " 'new ebook': 1,\n",
       " 'nicolas raymond': 1,\n",
       " 'node perform': 1,\n",
       " 'november 29': 1,\n",
       " 'november 29 , 2016': 1,\n",
       " 'november 30': 1,\n",
       " 'november 30 , 2016': 1,\n",
       " 'np.random.rand(100).astype(np.float32': 1,\n",
       " 'numerical computation': 1,\n",
       " 'numerical compute': 2,\n",
       " 'numerical library': 1,\n",
       " 'numpy': 2,\n",
       " 'official homepage': 1,\n",
       " 'open source': 2,\n",
       " 'optimizer =': 2,\n",
       " 'os x': 1,\n",
       " 'output attribute': 1,\n",
       " 'own projects': 1,\n",
       " 'pdf ebook': 1,\n",
       " 'perform computation': 2,\n",
       " 'phony x': 2,\n",
       " 'pip command': 1,\n",
       " 'plus share': 2,\n",
       " 'popular -PRON-': 1,\n",
       " 'practitioner like': 1,\n",
       " 'print sess.run(a+b': 1,\n",
       " 'print statement': 1,\n",
       " 'print(os.path.dirname(inspect.getfile(tensorflow': 2,\n",
       " 'privacy |': 1,\n",
       " 'probably simple': 1,\n",
       " 'process build': 1,\n",
       " 'produce output': 1,\n",
       " 'production system': 1,\n",
       " 'professional developer': 1,\n",
       " 'programme language': 1,\n",
       " 'progress in': 1,\n",
       " 'projects skip': 1,\n",
       " 'proud father': 1,\n",
       " 'python -PRON-': 1,\n",
       " 'python -c': 2,\n",
       " 'python 2.7': 2,\n",
       " 'python 3.3': 1,\n",
       " 'python april': 1,\n",
       " 'python april 7 , 2017': 1,\n",
       " 'python deep': 4,\n",
       " 'python discover': 1,\n",
       " 'python environment': 1,\n",
       " 'python june': 1,\n",
       " 'python june 9 , 2016': 1,\n",
       " 'python library': 2,\n",
       " 'python programme': 1,\n",
       " 'python scipy': 1,\n",
       " 'python script': 1,\n",
       " 'python step': 1,\n",
       " 'python today': 1,\n",
       " 'python with': 2,\n",
       " 'python3': 1,\n",
       " 'read more': 1,\n",
       " 'real value': 1,\n",
       " 'recent release': 1,\n",
       " 'recurrent neural': 3,\n",
       " 'reduce_mean': 1,\n",
       " 'regression tutorial': 1,\n",
       " 'reply ale': 1,\n",
       " 'reply amit': 1,\n",
       " 'reply amit kumar': 1,\n",
       " 'reply asesh': 1,\n",
       " 'reply click': 1,\n",
       " 'reply jason': 5,\n",
       " 'reply jason brownlee': 2,\n",
       " 'reply leave': 1,\n",
       " 'reply leave a reply click': 1,\n",
       " 'reply walid': 1,\n",
       " 'reply walid ahmed': 1,\n",
       " 'resources tensorflow': 2,\n",
       " 'response to introduction to the python deep learning library': 1,\n",
       " 'right reserve': 1,\n",
       " 'rights reserve': 1,\n",
       " 'sample code': 1,\n",
       " 'scale distribute': 1,\n",
       " 'scale machine': 1,\n",
       " 'scipy': 1,\n",
       " 'scipy environment': 1,\n",
       " 'search hyperparameters': 1,\n",
       " 'september 11': 1,\n",
       " 'september 11 , 2017': 1,\n",
       " 'september 9': 1,\n",
       " 'september 9 , 2017': 1,\n",
       " 'sequence classification': 1,\n",
       " 'sequence classification with lstm recurrent neural networks': 1,\n",
       " 'sequence model': 1,\n",
       " 'series forecasting': 2,\n",
       " 'series prediction': 1,\n",
       " 'sess =': 4,\n",
       " 'sess.run(a+b': 1,\n",
       " 'sess.run(w': 1,\n",
       " 'session': 1,\n",
       " 'setup instruction': 1,\n",
       " 'setup webpage': 1,\n",
       " 'share about': 1,\n",
       " 'share share': 4,\n",
       " 'share tensorflow': 1,\n",
       " 'single cpu': 1,\n",
       " 'small network': 1,\n",
       " 'source library': 1,\n",
       " 'source license': 1,\n",
       " 'special edge': 1,\n",
       " 'specific instruction': 1,\n",
       " 'specifically design': 1,\n",
       " 'square error': 2,\n",
       " 'start -PRON-': 1,\n",
       " 'start here': 1,\n",
       " 'start with': 2,\n",
       " 'step june': 1,\n",
       " 'step may': 1,\n",
       " 'step tutorial': 1,\n",
       " 'study tutorial': 1,\n",
       " 'summary': 1,\n",
       " 'summary in': 1,\n",
       " 'super computer': 1,\n",
       " 'synchronize behavior': 1,\n",
       " 'syntactically incorrect': 1,\n",
       " 'tensforflow project': 1,\n",
       " 'tensorflow': 22,\n",
       " 'tensorflow 1': 1,\n",
       " 'tensorflow by': 1,\n",
       " 'tensorflow change': 1,\n",
       " 'tensorflow computation': 1,\n",
       " 'tensorflow course': 1,\n",
       " 'tensorflow installation': 3,\n",
       " 'tensorflow jatin': 1,\n",
       " 'tensorflow library': 1,\n",
       " 'tensorflow official': 1,\n",
       " 'tensorflow photo': 1,\n",
       " 'tensorflow playground': 1,\n",
       " 'tensorflow python': 1,\n",
       " 'tensorflow resources': 1,\n",
       " 'tensorflow resources tensorflow official homepage tensforflow project on github tensorflow tutorial more resources tensorflow course on udacity tensorflow': 1,\n",
       " 'tensorflow separate': 1,\n",
       " 'tensorflow this': 2,\n",
       " 'tensorflow tutorial': 2,\n",
       " 'tensorflow website': 3,\n",
       " 'tensorflow work': 1,\n",
       " 'term memory': 1,\n",
       " 'tf import': 1,\n",
       " 'tf sess': 1,\n",
       " 'tf.constant(10': 1,\n",
       " 'tf.train.gradientdescentoptimizer(0.5': 1,\n",
       " 'thank amit': 1,\n",
       " 'thank jatin': 1,\n",
       " 'the api': 1,\n",
       " 'the bracket': 1,\n",
       " 'the cifar-10': 1,\n",
       " 'the graph': 1,\n",
       " 'this example': 1,\n",
       " 'thread word2vec': 2,\n",
       " 'time series': 3,\n",
       " 'to -PRON-': 1,\n",
       " 'today': 1,\n",
       " 'topic like': 1,\n",
       " 'train =': 2,\n",
       " 'tutorial more': 1,\n",
       " 'tweet share': 2,\n",
       " 'twitter tweet': 2,\n",
       " 'twitter tweet share': 2,\n",
       " 'udacity tensorflow': 1,\n",
       " 'unbatched skip': 1,\n",
       " 'underlie c++': 1,\n",
       " 'usage guide': 1,\n",
       " 'use different': 1,\n",
       " 'w': 2,\n",
       " 'w =': 2,\n",
       " 'walid ahmed': 1,\n",
       " 'want end': 1,\n",
       " 'web browser': 1,\n",
       " 'website welcome': 1,\n",
       " 'website welcome to': 1,\n",
       " 'well fit': 2,\n",
       " 'what if': 1,\n",
       " 'windows': 1,\n",
       " 'with -PRON-': 1,\n",
       " 'with deep': 2,\n",
       " 'with keras': 2,\n",
       " 'with python': 1,\n",
       " 'word2vec mini': 1,\n",
       " 'word2vec unbatched': 1,\n",
       " 'wrapper library': 1,\n",
       " 'x platform': 1,\n",
       " 'x_data +': 4,\n",
       " 'x_data =': 2,\n",
       " 'y =': 4,\n",
       " 'y datum': 2,\n",
       " 'y_data =': 4,\n",
       " 'you awesome': 1,\n",
       " 'zero': 2,\n",
       " '| about': 1,\n",
       " '| contact': 1,\n",
       " '© 2018': 1,\n",
       " '’ python': 1,\n",
       " '’ write': 1,\n",
       " '→ crash': 1,\n",
       " '\\ufeff1': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### with textacy:\n",
    "\n",
    "\n",
    "html_files = os.listdir(\"Machine Learning Mastery articles\")\n",
    "html_file  = html_files[0]\n",
    "\n",
    "html_file\n",
    "\n",
    "keywords = list()\n",
    "\n",
    "with open(\"Machine Learning Mastery articles/\" + html_file) as f:\n",
    "    html = f.read()\n",
    "\n",
    "scrubbed_content = clean_me(html)\n",
    "current_doc = textacy.Doc(scrubbed_content)\n",
    "current_doc.to_bag_of_terms(ngrams=2, named_entities=True,lemmatize=True, as_strings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
