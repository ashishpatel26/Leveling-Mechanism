<html lang="en-US" prefix="og: http://ogp.me/ns#">
<head>
<meta charset="utf-8"/>
<title>A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size - Machine Learning Mastery</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<link href="https://machinelearningmastery.com/xmlrpc.php" rel="pingback"/>
<!--  Mobile viewport scale -->
<meta content="initial-scale=1.0, maximum-scale=1.0, user-scalable=yes" name="viewport"/>
<!-- This site is optimized with the Yoast SEO plugin v6.1.1 - https://yoa.st/1yg?utm_content=6.1.1 -->
<link href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/" rel="canonical"/>
<link href="https://plus.google.com/u/0/b/117073416089354242117/+MachinelearningmasteryHome/" rel="publisher"/>
<meta content="en_US" property="og:locale"/>
<meta content="article" property="og:type"/>
<meta content="A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size - Machine Learning Mastery" property="og:title"/>
<meta content="Stochastic gradient descent is the dominant method used to train deep learning models. There are three main variants of gradient descent and it can be confusing which one to use. In this post, you will discover the one type of gradient descent you should use in general and how to configure it. After completing this …" property="og:description"/>
<meta content="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/" property="og:url"/>
<meta content="Machine Learning Mastery" property="og:site_name"/>
<meta content="https://www.facebook.com/Machine-Learning-Mastery-1429846323896563/" property="article:publisher"/>
<meta content="Deep Learning" property="article:section"/>
<meta content="2017-07-21T05:00:58+11:00" property="article:published_time"/>
<meta content="2017-12-28T05:27:10+11:00" property="article:modified_time"/>
<meta content="2017-12-28T05:27:10+11:00" property="og:updated_time"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/A-Gentle-Introduction-to-Mini-Batch-Gradient-Descent-and-How-to-Configure-Batch-Size.jpg" property="og:image"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/A-Gentle-Introduction-to-Mini-Batch-Gradient-Descent-and-How-to-Configure-Batch-Size.jpg" property="og:image:secure_url"/>
<meta content="640" property="og:image:width"/>
<meta content="427" property="og:image:height"/>
<script type="application/ld+json">{"@context":"http:\/\/schema.org","@type":"WebSite","@id":"#website","url":"https:\/\/machinelearningmastery.com\/","name":"Machine Learning Mastery","potentialAction":{"@type":"SearchAction","target":"https:\/\/machinelearningmastery.com\/?s={search_term_string}","query-input":"required name=search_term_string"}}</script>
<script type="application/ld+json">{"@context":"http:\/\/schema.org","@type":"Organization","url":"https:\/\/machinelearningmastery.com\/gentle-introduction-mini-batch-gradient-descent-configure-batch-size\/","sameAs":["https:\/\/www.facebook.com\/Machine-Learning-Mastery-1429846323896563\/","https:\/\/www.linkedin.com\/in\/jasonbrownlee","https:\/\/plus.google.com\/u\/0\/b\/117073416089354242117\/+MachinelearningmasteryHome\/","https:\/\/twitter.com\/TeachTheMachine"],"@id":"#organization","name":"Machine Learning Mastery","logo":"https:\/\/machinelearningmastery.com\/wp-content\/uploads\/2016\/09\/cropped-icon.png"}</script>
<!-- / Yoast SEO plugin. -->
<link href="//cdnjs.cloudflare.com" rel="dns-prefetch"/>
<link href="//fonts.googleapis.com" rel="dns-prefetch"/>
<link href="//s.w.org" rel="dns-prefetch"/>
<link href="https://feeds.feedburner.com/MachineLearningMastery" rel="alternate" title="Machine Learning Mastery » Feed" type="application/rss+xml"/>
<link href="https://machinelearningmastery.com/comments/feed/" rel="alternate" title="Machine Learning Mastery » Comments Feed" type="application/rss+xml"/>
<link href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/feed/" rel="alternate" title="Machine Learning Mastery » A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size Comments Feed" type="application/rss+xml"/>
<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.3\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.3\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/machinelearningmastery.com\/wp-includes\/js\/wp-emoji-release.min.js?ver=4.9.2"}};
			!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline="top",l.font="600 32px Arial",a){case"flag":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case"emoji":return b=d([55358,56794,8205,9794,65039],[55358,56794,8203,9794,65039]),!b}return!1}function f(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var g,h,i,j,k=b.createElement("canvas"),l=k.getContext&&k.getContext("2d");for(j=Array("flag","emoji"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],"flag"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",h,!1),a.addEventListener("load",h,!1)):(a.attachEvent("onload",h),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/css/min/crayon.min.css?ver=_2.7.2_beta" id="crayon-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/themes/classic/classic.css?ver=_2.7.2_beta" id="crayon-theme-classic-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/fonts/monaco.css?ver=_2.7.2_beta" id="crayon-font-monaco-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/contact-form-7/includes/css/styles.css?ver=4.9.2" id="contact-form-7-css" media="all" rel="stylesheet" type="text/css"/>
<link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.4.0/css/font-awesome.min.css?ver=4.2.2.0.iis7_supports_permalinks" id="apss-font-awesome-css" media="all" rel="stylesheet" type="text/css"/>
<link href="//fonts.googleapis.com/css?family=Open+Sans&amp;ver=4.9.2" id="apss-font-opensans-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/seo-optimized-share-buttons/css/frontend.css?ver=4.2.2.0.iis7_supports_permalinks" id="apss-frontend-css-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/integrations/testimonials/css/testimonials.css?ver=4.9.2" id="woo-testimonials-css-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/style.css?ver=5.9.21" id="theme-stylesheet-css" media="all" rel="stylesheet" type="text/css"/>
<!--[if lt IE 9]>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/css/non-responsive.css" rel="stylesheet" type="text/css" />
<style type="text/css">.col-full, #wrapper { width: 960px; max-width: 960px; } #inner-wrapper { padding: 0; } body.full-width #header, #nav-container, body.full-width #content, body.full-width #footer-widgets, body.full-width #footer { padding-left: 0; padding-right: 0; } body.fixed-mobile #top, body.fixed-mobile #header-container, body.fixed-mobile #footer-container, body.fixed-mobile #nav-container, body.fixed-mobile #footer-widgets-container { min-width: 960px; padding: 0 1em; } body.full-width #content { width: auto; padding: 0 1em;}</style>
<![endif]-->
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/jquery/jquery.js?ver=1.12.4" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.4.1" type="text/javascript"></script>
<script type="text/javascript">
/* <![CDATA[ */
var CrayonSyntaxSettings = {"version":"_2.7.2_beta","is_admin":"0","ajaxurl":"https:\/\/machinelearningmastery.com\/wp-admin\/admin-ajax.php","prefix":"crayon-","setting":"crayon-setting","selected":"crayon-setting-selected","changed":"crayon-setting-changed","special":"crayon-setting-special","orig_value":"data-orig-value","debug":""};
var CrayonSyntaxStrings = {"copy":"Press %s to Copy, %s to Paste","minimize":"Click To Expand Code"};
/* ]]> */
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/js/min/crayon.min.js?ver=_2.7.2_beta" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/third-party.min.js?ver=4.9.2" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/modernizr.min.js?ver=2.6.2" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/general.min.js?ver=4.9.2" type="text/javascript"></script>
<link href="https://machinelearningmastery.com/wp-json/" rel="https://api.w.org/"/>
<link href="https://machinelearningmastery.com/xmlrpc.php?rsd" rel="EditURI" title="RSD" type="application/rsd+xml"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/wlwmanifest.xml" rel="wlwmanifest" type="application/wlwmanifest+xml"/>
<link href="https://machinelearningmastery.com/?p=4147" rel="shortlink"/>
<link href="https://machinelearningmastery.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fmachinelearningmastery.com%2Fgentle-introduction-mini-batch-gradient-descent-configure-batch-size%2F" rel="alternate" type="application/json+oembed"/>
<link href="https://machinelearningmastery.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fmachinelearningmastery.com%2Fgentle-introduction-mini-batch-gradient-descent-configure-batch-size%2F&amp;format=xml" rel="alternate" type="text/xml+oembed"/>
<!-- Start Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44039733-3', 'auto');
  ga('send', 'pageview');

</script>
<!-- End Google Analytics -->
<!-- Facebook Pixel Code -->
<script>
!function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function(){n.callMethod?
n.callMethod.apply(n,arguments):n.queue.push(arguments)};if(!f._fbq)f._fbq=n;
n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;
t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,
document,'script','https://connect.facebook.net/en_US/fbevents.js');

fbq('init', '296263687421164');
fbq('track', "PageView");</script>
<noscript><img height="1" src="https://www.facebook.com/tr?id=296263687421164&amp;ev=PageView&amp;noscript=1" style="display:none" width="1"/></noscript>
<!-- End Facebook Pixel Code -->
<!-- Custom CSS Styling -->
<style type="text/css">
#logo .site-title, #logo .site-description { display:none; }
body {background-repeat:no-repeat;background-position:top left;background-attachment:scroll;border-top:0px solid #000000;}
#header {background-repeat:no-repeat;background-position:left top;margin-top:0px;margin-bottom:0px;padding-top:10px;padding-bottom:10px;border:0px solid ;}
#logo .site-title a {font:bold 40px/1em Helvetica Neue, Helvetica, sans-serif;color:#222222;}
#logo .site-description {font:300 13px/1em Helvetica Neue, Helvetica, sans-serif;color:#999999;}
body, p { font:300 14px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#555555; }
h1 { font:bold 28px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h2 { font:bold 24px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h3 { font:bold 20px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h4 { font:bold 16px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h5 { font:bold 14px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h6 { font:bold 12px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }
.page-title, .post .title, .page .title {font:bold 28px/1.1em "Helvetica Neue", Helvetica, sans-serif;color:#222222;}
.post .title a:link, .post .title a:visited, .page .title a:link, .page .title a:visited {color:#222222}
.post-meta { font:300 12px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#999999; }
.entry, .entry p{ font:300 15px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#555555; }
.post-more {font:300 13px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:;border-top:0px solid #e6e6e6;border-bottom:0px solid #e6e6e6;}
#post-author, #connect {border-top:1px solid #e6e6e6;border-bottom:1px solid #e6e6e6;border-left:1px solid #e6e6e6;border-right:1px solid #e6e6e6;border-radius:5px;-moz-border-radius:5px;-webkit-border-radius:5px;background-color:#fafafa}
.nav-entries a, .woo-pagination { font:300 13px/1em "Helvetica Neue", Helvetica, sans-serif;color:#888; }
.woo-pagination a, .woo-pagination a:hover {color:#888!important}
.widget h3 {font:bold 14px/1.2em &quot;Helvetica Neue&quot;, Helvetica, sans-serif;color:#555555;border-bottom:1px solid #e6e6e6;}
.widget_recent_comments li, #twitter li { border-color: #e6e6e6;}
.widget p, .widget .textwidget { font:300 13px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#555555; }
.widget {font:300 13px/1.5em &quot;Helvetica Neue&quot;, Helvetica, sans-serif;color:#555555;border-radius:0px;-moz-border-radius:0px;-webkit-border-radius:0px;}
#tabs .inside li a, .widget_woodojo_tabs .tabbable .tab-pane li a { font:bold 12px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#555555; }
#tabs .inside li span.meta, .widget_woodojo_tabs .tabbable .tab-pane li span.meta { font:300 11px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#999999; }
#tabs ul.wooTabs li a, .widget_woodojo_tabs .tabbable .nav-tabs li a { font:300 11px/2em Helvetica Neue, Helvetica, sans-serif;color:#999999; }
@media only screen and (min-width:768px) {
ul.nav li a, #navigation ul.rss a, #navigation ul.cart a.cart-contents, #navigation .cart-contents #navigation ul.rss, #navigation ul.nav-search, #navigation ul.nav-search a { font:300 14px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#666666; } #navigation ul.rss li a:before, #navigation ul.nav-search a.search-contents:before { color:#666666;}
#navigation ul.nav li ul, #navigation ul.cart > li > ul > div  { border: 0px solid #dbdbdb; }
#navigation ul.nav > li:hover > ul  { left: 0; }
#navigation ul.nav > li  { border-right: 0px solid #dbdbdb; }#navigation ul.nav > li:hover > ul  { left: 0; }
#navigation { box-shadow: none; -moz-box-shadow: none; -webkit-box-shadow: none; }#navigation ul li:first-child, #navigation ul li:first-child a { border-radius:0px 0 0 0px; -moz-border-radius:0px 0 0 0px; -webkit-border-radius:0px 0 0 0px; }
#navigation {border-top:0px solid #dbdbdb;border-bottom:0px solid #dbdbdb;border-left:0px solid #dbdbdb;border-right:0px solid #dbdbdb;border-radius:0px; -moz-border-radius:0px; -webkit-border-radius:0px;}
#top ul.nav li a { font:300 12px/1.6em Helvetica Neue, Helvetica, sans-serif;color:#ddd; }
}
#footer, #footer p { font:300 13px/1.4em Helvetica Neue, Helvetica, sans-serif;color:#999999; }
#footer {border-top:1px solid #dbdbdb;border-bottom:0px solid ;border-left:0px solid ;border-right:0px solid ;border-radius:0px; -moz-border-radius:0px; -webkit-border-radius:0px;}
.magazine #loopedSlider .content h2.title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-magazine .slide-title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.magazine #loopedSlider .content .excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-magazine .slide-content p, .wooslider-theme-magazine .slide-excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.magazine .block .post .title a {font:bold 18px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }
#loopedSlider.business-slider .content h2 { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
#loopedSlider.business-slider .content h2.title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-business .has-featured-image .slide-title { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-business .has-featured-image .slide-title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
#wrapper #loopedSlider.business-slider .content p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-business .has-featured-image .slide-content p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-business .has-featured-image .slide-excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.archive_header { font:bold 18px/1em Arial, sans-serif;color:#222222; }
.archive_header {border-bottom:1px solid #e6e6e6;}
.archive_header .catrss { display:none; }
</style>
<!-- Woo Shortcodes CSS -->
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/functions/css/shortcodes.css" rel="stylesheet" type="text/css"/>
<!-- Custom Stylesheet -->
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/custom.css" rel="stylesheet" type="text/css"/>
<!-- Theme version -->
<meta content="Canvas 5.9.21" name="generator"/>
<meta content="WooFramework 6.2.9" name="generator"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-32x32.png" rel="icon" sizes="32x32"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-192x192.png" rel="icon" sizes="192x192"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-180x180.png" rel="apple-touch-icon-precomposed"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-270x270.png" name="msapplication-TileImage"/>
</head>
<body class="post-template-default single single-post postid-4147 single-format-standard chrome alt-style-default two-col-left width-960 two-col-left-960">
<div id="wrapper">
<div id="inner-wrapper">
<h3 class="nav-toggle icon"><a href="#navigation">Navigation</a></h3>
<header class="col-full" id="header">
<div id="logo">
<a href="https://machinelearningmastery.com/" title="Making developers awesome at machine learning"><img alt="Machine Learning Mastery" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/MachineLearningMastery.png"/></a>
<span class="site-title"><a href="https://machinelearningmastery.com/">Machine Learning Mastery</a></span>
<span class="site-description">Making developers awesome at machine learning</span>
</div>
<div class="header-widget">
<div class="widget widget_text" id="text-3"> <div class="textwidget"><br/>
<div style="font-size:12pt;">
<a href="/start-here"><strong>Start Here</strong></a>
     
<a href="/blog">Blog</a>
     
<a href="/products">Books</a>
     
<a href="/about">About</a>
     
<a href="/contact">Contact</a>
</div></div>
</div><div class="widget widget_search" id="search-3"><div class="search_main">
<form action="https://machinelearningmastery.com/" class="searchform" method="get">
<input class="field s" name="s" onblur="if (this.value == '') {this.value = 'Search...';}" onfocus="if (this.value == 'Search...') {this.value = '';}" type="text" value="Search..."/>
<button class="fa fa-search submit" name="submit" type="submit" value="Search"></button>
</form>
<div class="fix"></div>
</div></div><div class="widget widget_text" id="text-32"> <div class="textwidget"><p>Need help with Deep Learning? <a href="https://machinelearningmastery.lpages.co/deep-learning-with-python-mini-course/">Take the FREE Mini-Course</a></p>
</div>
</div> </div>
</header>
<nav class="col-full" id="navigation" role="navigation">
<section class="menus">
<a class="nav-home" href="https://machinelearningmastery.com"><span>Home</span></a>
<h3>Empty Menu</h3> <div class="side-nav">
</div><!-- /#side-nav -->
</section><!-- /.menus -->
<a class="nav-close" href="#top"><span>Return to Content</span></a>
</nav>
<!-- #content Starts -->
<div class="col-full" id="content">
<div id="main-sidebar-container">
<!-- #main Starts -->
<section id="main">
<article class="post-4147 post type-post status-publish format-standard has-post-thumbnail hentry category-deep-learning">
<header>
<h1 class="title entry-title">A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size</h1> </header>
<div class="post-meta"><span class="small">By</span> <span class="author vcard"><span class="fn"><a href="https://machinelearningmastery.com/author/jasonb/" rel="author" title="Posts by Jason Brownlee">Jason Brownlee</a></span></span> <span class="small">on</span> <abbr class="date time published updated" title="2017-07-21T05:00:58+1100">July 21, 2017</abbr> <span class="small">in</span> <span class="categories"><a href="https://machinelearningmastery.com/category/deep-learning/" title="View all items in Deep Learning">Deep Learning</a></span> </div>
<section class="entry">
<div class="apss-social-share apss-theme-4 clearfix">
<div class="apss-twitter apss-single-icon">
<a href="javascript:void(0);" onclick="apss_open_in_popup_window(event, 'https://twitter.com/intent/tweet?text=A%20Gentle%20Introduction%20to%20Mini-Batch%20Gradient%20Descent%20and%20How%20to%20Configure%20Batch%20Size&amp;url=https%3A%2F%2Fmachinelearningmastery.com%2Fgentle-introduction-mini-batch-gradient-descent-configure-batch-size%2F&amp;');" rel="nofollow" target="" title="Share on Twitter">
<div class="apss-icon-block clearfix">
<i class="fa fa-twitter"></i>
<span class="apss-social-text">Share on Twitter</span><span class="apss-share">Tweet</span>
</div>
</a>
</div>
<div class="apss-facebook apss-single-icon">
<a href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/" onclick="apss_open_in_popup_window(event, 'https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/');" rel="nofollow" target="" title="Share on Facebook">
<div class="apss-icon-block clearfix">
<i class="fa fa-facebook"></i>
<span class="apss-social-text">Share on Facebook</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-linkedin apss-single-icon">
<a href="http://www.linkedin.com/shareArticle?mini=true&amp;title=A%20Gentle%20Introduction%20to%20Mini-Batch%20Gradient%20Descent%20and%20How%20to%20Configure%20Batch%20Size&amp;url=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/&amp;summary=Stochastic+gradient+descent+is+the+dominant+method+used+to+train+deep+learning+models.%0D%0A%0D%0AThere+are+..." onclick="apss_open_in_popup_window(event, 'http://www.linkedin.com/shareArticle?mini=true&amp;title=A%20Gentle%20Introduction%20to%20Mini-Batch%20Gradient%20Descent%20and%20How%20to%20Configure%20Batch%20Size&amp;url=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/&amp;summary=Stochastic+gradient+descent+is+the+dominant+method+used+to+train+deep+learning+models.%0D%0A%0D%0AThere+are+...');" rel="nofollow" target="" title="Share on LinkedIn">
<div class="apss-icon-block clearfix"><i class="fa fa-linkedin"></i>
<span class="apss-social-text">Share on LinkedIn</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-google-plus apss-single-icon">
<a href="https://plus.google.com/share?url=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/" onclick="apss_open_in_popup_window(event, 'https://plus.google.com/share?url=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/');" rel="nofollow" target="" title="Share on Google Plus">
<div class="apss-icon-block clearfix">
<i class="fa fa-google-plus"></i>
<span class="apss-social-text">Share on Google Plus</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
</div><p>Stochastic gradient descent is the dominant method used to train deep learning models.</p>
<p>There are three main variants of gradient descent and it can be confusing which one to use.</p>
<p>In this post, you will discover the one type of gradient descent you should use in general and how to configure it.</p>
<p>After completing this post, you will know:</p>
<ul>
<li>What gradient descent is and how it works from a high level.</li>
<li>What batch, stochastic, and mini-batch gradient descent are and the benefits and limitations of each method.</li>
<li>That mini-batch gradient descent is the go-to method and how to configure it on your applications.</li>
</ul>
<p>Let’s get started.</p>
<div class="wp-caption aligncenter" id="attachment_4148" style="max-width: 650px"><img alt="A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size" class="size-full wp-image-4148" height="427" sizes="(max-width: 640px) 100vw, 640px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/A-Gentle-Introduction-to-Mini-Batch-Gradient-Descent-and-How-to-Configure-Batch-Size.jpg" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/A-Gentle-Introduction-to-Mini-Batch-Gradient-Descent-and-How-to-Configure-Batch-Size.jpg 640w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/07/A-Gentle-Introduction-to-Mini-Batch-Gradient-Descent-and-How-to-Configure-Batch-Size-300x200.jpg 300w" width="640"/><p class="wp-caption-text">A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size<br/>Photo by <a href="https://www.flickr.com/photos/smithser/6269720226/">Brian Smithson</a>, some rights reserved.</p></div>
<h2>Tutorial Overview</h2>
<p>This tutorial is divided into 3 parts; they are:</p>
<ol>
<li>What is Gradient Descent?</li>
<li>Contrasting the 3 Types of Gradient Descent</li>
<li>How to Configure Mini-Batch Gradient Descent</li>
</ol>
<h2>What is Gradient Descent?</h2>
<p>Gradient descent is an optimization algorithm often used for finding the weights or coefficients of machine learning algorithms, such as artificial neural networks and logistic regression.</p>
<p>It works by having the model make predictions on training data and using the error on the predictions to update the model in such a way as to reduce the error.</p>
<p>The goal of the algorithm is to find model parameters (e.g. coefficients or weights) that minimize the error of the model on the training dataset. It does this by making changes to the model that move it along a gradient or slope of errors down toward a minimum error value. This gives the algorithm its name of “gradient descent.”</p>
<p>The pseudocode sketch below summarizes the gradient descent algorithm:</p><!-- Crayon Syntax Highlighter v_2.7.2_beta -->
<div class="crayon-syntax crayon-theme-classic crayon-font-monaco crayon-os-pc print-yes notranslate" data-settings=" minimize scroll-mouseover" id="crayon-5a658f78e4c59035540103" style=" margin-top: 12px; margin-bottom: 12px; font-size: 12px !important; line-height: 15px !important;">
<div class="crayon-toolbar" data-settings=" mouseover overlay hide delay" style="font-size: 12px !important;height: 18px !important; line-height: 18px !important;"><span class="crayon-title"></span>
<div class="crayon-tools" style="font-size: 12px !important;height: 18px !important; line-height: 18px !important;"><div class="crayon-button crayon-nums-button" title="Toggle Line Numbers"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-plain-button" title="Toggle Plain Code"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-wrap-button" title="Toggle Line Wrap"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-expand-button" title="Expand Code"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-copy-button" title="Copy"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-popup-button" title="Open Code In New Window"><div class="crayon-button-icon"></div></div></div></div>
<div class="crayon-info" style="min-height: 16.8px !important; line-height: 16.8px !important;"></div>
<div class="crayon-plain-wrap"><textarea class="crayon-plain print-no" data-settings="dblclick" readonly="" style="-moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4; font-size: 12px !important; line-height: 15px !important;" wrap="soft">
model = initialization(...)
n_epochs = ...
train_data = ...
for i in n_epochs:
	train_data = shuffle(train_data)
	X, y = split(train_data)
	predictions = predict(X, model)
	error = calculate_error(y, predictions)
	model = update_model(model, error)</textarea></div>
<div class="crayon-main" style="">
<table class="crayon-table">
<tr class="crayon-row">
<td class="crayon-nums " data-settings="show">
<div class="crayon-nums-content" style="font-size: 12px !important; line-height: 15px !important;"><div class="crayon-num" data-line="crayon-5a658f78e4c59035540103-1">1</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a658f78e4c59035540103-2">2</div><div class="crayon-num" data-line="crayon-5a658f78e4c59035540103-3">3</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a658f78e4c59035540103-4">4</div><div class="crayon-num" data-line="crayon-5a658f78e4c59035540103-5">5</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a658f78e4c59035540103-6">6</div><div class="crayon-num" data-line="crayon-5a658f78e4c59035540103-7">7</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a658f78e4c59035540103-8">8</div><div class="crayon-num" data-line="crayon-5a658f78e4c59035540103-9">9</div></div>
</td>
<td class="crayon-code"><div class="crayon-pre" style="font-size: 12px !important; line-height: 15px !important; -moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4;"><div class="crayon-line" id="crayon-5a658f78e4c59035540103-1">model = initialization(...)</div><div class="crayon-line crayon-striped-line" id="crayon-5a658f78e4c59035540103-2">n_epochs = ...</div><div class="crayon-line" id="crayon-5a658f78e4c59035540103-3">train_data = ...</div><div class="crayon-line crayon-striped-line" id="crayon-5a658f78e4c59035540103-4">for i in n_epochs:</div><div class="crayon-line" id="crayon-5a658f78e4c59035540103-5">	train_data = shuffle(train_data)</div><div class="crayon-line crayon-striped-line" id="crayon-5a658f78e4c59035540103-6">	X, y = split(train_data)</div><div class="crayon-line" id="crayon-5a658f78e4c59035540103-7">	predictions = predict(X, model)</div><div class="crayon-line crayon-striped-line" id="crayon-5a658f78e4c59035540103-8">	error = calculate_error(y, predictions)</div><div class="crayon-line" id="crayon-5a658f78e4c59035540103-9">	model = update_model(model, error)</div></div></td>
</tr>
</table>
</div>
</div>
<!-- [Format Time: 0.0003 seconds] -->
<p>For more information see the posts:</p>
<ul>
<li><a href="http://machinelearningmastery.com/gradient-descent-for-machine-learning/">Gradient Descent For Machine Learning</a></li>
<li><a href="http://machinelearningmastery.com/implement-linear-regression-stochastic-gradient-descent-scratch-python/">How to Implement Linear Regression with Stochastic Gradient Descent from Scratch with Python</a></li>
</ul>
<h2>Contrasting the 3 Types of Gradient Descent</h2>
<p>Gradient descent can vary in terms of the number of training patterns used to calculate error; that is in turn used to update the model.</p>
<p>The number of patterns used to calculate the error includes how stable the gradient is that is used to update the model. We will see that there is a tension in gradient descent configurations of computational efficiency and the fidelity of the error gradient.</p>
<p>The three main flavors of gradient descent are batch, stochastic, and mini-batch.</p>
<p>Let’s take a closer look at each.</p>
<h3>What is Stochastic Gradient Descent?</h3>
<p>Stochastic gradient descent, often abbreviated SGD, is a variation of the gradient descent algorithm that calculates the error and updates the model for each example in the training dataset.</p>
<p>The update of the model for each training example means that stochastic gradient descent is often called an <a href="https://en.wikipedia.org/wiki/Online_machine_learning">online machine learning algorithm</a>.</p>
<h4>Upsides</h4>
<ul>
<li>The frequent updates immediately give an insight into the performance of the model and the rate of improvement.</li>
<li>This variant of gradient descent may be the simplest to understand and implement, especially for beginners.</li>
<li>The increased model update frequency can result in faster learning on some problems.</li>
<li>The noisy update process can allow the model to avoid local minima (e.g. premature convergence).</li>
</ul>
<h4>Downsides</h4>
<ul>
<li>Updating the model so frequently is more computationally expensive than other configurations of gradient descent, taking significantly longer to train models on large datasets.</li>
<li>The frequent updates can result in a noisy gradient signal, which may cause the model parameters and in turn the model error to jump around (have a higher variance over training epochs).</li>
<li>The noisy learning process down the error gradient can also make it hard for the algorithm to settle on an error minimum for the model.</li>
</ul>
<h3>What is Batch Gradient Descent?</h3>
<p>Batch gradient descent is a variation of the gradient descent algorithm that calculates the error for each example in the training dataset, but only updates the model after all training examples have been evaluated.</p>
<p>One cycle through the entire training dataset is called a training epoch. Therefore, it is often said that batch gradient descent performs model updates at the end of each training epoch.</p>
<h4>Upsides</h4>
<ul>
<li>Fewer updates to the model means this variant of gradient descent is more computationally efficient than stochastic gradient descent.</li>
<li>The decreased update frequency results in a more stable error gradient and may result in a more stable convergence on some problems.</li>
<li>The separation of the calculation of prediction errors and the model update lends the algorithm to parallel processing based implementations.</li>
</ul>
<h4>Downsides</h4>
<ul>
<li>The more stable error gradient may result in premature convergence of the model to a less optimal set of parameters.</li>
<li>The updates at the end of the training epoch require the additional complexity of accumulating prediction errors across all training examples.</li>
<li>Commonly, batch gradient descent is implemented in such a way that it requires the entire training dataset in memory and available to the algorithm.</li>
<li>Model updates, and in turn training speed, may become very slow for large datasets.</li>
</ul>
<h3>What is Mini-Batch Gradient Descent?</h3>
<p>Mini-batch gradient descent is a variation of the gradient descent algorithm that splits the training dataset into small batches that are used to calculate model error and update model coefficients.</p>
<p>Implementations may choose to sum the gradient over the mini-batch or take the average of the gradient which further reduces the variance of the gradient.</p>
<p>Mini-batch gradient descent seeks to find a balance between the robustness of stochastic gradient descent and the efficiency of batch gradient descent. It is the most common implementation of gradient descent used in the field of deep learning.</p>
<h4>Upsides</h4>
<ul>
<li>The model update frequency is higher than batch gradient descent which allows for a more robust convergence, avoiding local minima.</li>
<li>The batched updates provide a computationally more efficient process than stochastic gradient descent.</li>
<li>The batching allows both the efficiency of not having all training data in memory and algorithm implementations.</li>
</ul>
<h4>Downsides</h4>
<ul>
<li>Mini-batch requires the configuration of an additional “mini-batch size” hyperparameter for the learning algorithm.</li>
<li>Error information must be accumulated across mini-batches of training examples like batch gradient descent.</li>
</ul>
<h2>How to Configure Mini-Batch Gradient Descent</h2>
<p>Mini-batch gradient descent is the recommended variant of gradient descent for most applications, especially in deep learning.</p>
<p>Mini-batch sizes, commonly called “batch sizes” for brevity, are often tuned to an aspect of the computational architecture on which the implementation is being executed. Such as a power of two that fits the memory requirements of the GPU or CPU hardware like 32, 64, 128, 256, and so on.</p>
<p>Batch size is a slider on the learning process.</p>
<ul>
<li>Small values give a learning process that converges quickly at the cost of noise in the training process.</li>
<li>Large values give a learning process that converges slowly with accurate estimates of the error gradient.</li>
</ul>
<p><strong>Tip 1: A good default for batch size might be 32.</strong></p>
<blockquote><p>… [batch size] is typically chosen between 1 and a few hundreds, e.g. [batch size] = 32 is a good default value, with values above 10 taking advantage of the speedup of matrix-matrix products over matrix-vector products.</p></blockquote>
<p>— <a href="https://arxiv.org/abs/1206.5533">Practical recommendations for gradient-based training of deep architectures</a>, 2012</p>
<p><strong>Tip 2: It is a good idea to review learning curves of model validation error against training time with different batch sizes when tuning the batch size.</strong></p>
<blockquote><p>… it can be optimized separately of the other hyperparameters, by comparing training curves (training and validation error vs amount of training time), after the other hyper-parameters (except learning rate) have been selected.</p></blockquote>
<p><strong>Tip 3: Tune batch size and learning rate after tuning all other hyperparameters.</strong></p>
<blockquote><p>… [batch size] and [learning rate] may slightly interact with other hyper-parameters so both should be re-optimized at the end. Once [batch size] is selected, it can generally be fixed while the other hyper-parameters can be further optimized (except for a momentum hyper-parameter, if one is used).</p></blockquote>
<h2>Further Reading</h2>
<p>This section provides more resources on the topic if you are looking go deeper.</p>
<h3>Related Posts</h3>
<ul>
<li><a href="http://machinelearningmastery.com/gradient-descent-for-machine-learning/">Gradient Descent for Machine Learning</a></li>
<li><a href="http://machinelearningmastery.com/implement-linear-regression-stochastic-gradient-descent-scratch-python/">How to Implement Linear Regression with Stochastic Gradient Descent from Scratch with Python</a></li>
</ul>
<h3>Additional Reading</h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent</a> on Wikipedia</li>
<li><a href="https://en.wikipedia.org/wiki/Online_machine_learning">Online machine learning</a> on Wikipedia</li>
<li><a href="http://sebastianruder.com/optimizing-gradient-descent/index.html">An overview of gradient descent optimization algorithms</a></li>
<li><a href="https://arxiv.org/abs/1206.5533">Practical recommendations for gradient-based training of deep architectures</a>, 2012</li>
<li><a href="http://www.cs.cmu.edu/~muli/file/minibatch_sgd.pdf">Efficient Mini-batch Training for Stochastic Optimization</a>, 2014</li>
<li><a href="https://www.quora.com/In-deep-learning-why-dont-we-use-the-whole-training-set-to-compute-the-gradient">In deep learning, why don’t we use the whole training set to compute the gradient?</a> on Quora</li>
<li><a href="https://arxiv.org/abs/1606.04838">Optimization Methods for Large-Scale Machine Learning</a>, 2016</li>
</ul>
<h2>Summary</h2>
<p>In this post, you discovered the gradient descent algorithm and the version that you should use in practice.</p>
<p>Specifically, you learned:</p>
<ul>
<li>What gradient descent is and how it works from a high level.</li>
<li>What batch, stochastic, and mini-batch gradient descent are and the benefits and limitations of each method.</li>
<li>That mini-batch gradient descent is the go-to method and how to configure it on your applications.</li>
</ul>
<p>Do you have any questions?<br/>
Ask your questions in the comments below and I will do my best to answer.</p>
<div class="awac-wrapper"><div class="awac widget text-35"> <div class="textwidget"><div class="woo-sc-hr"></div>
<h2 style="text-align: center;">Frustrated With Your Progress In Deep Learning?</h2>
<p><a href="/deep-learning-with-python/"><img align="left" alt="Deep Learning with Python" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/05/DeepLearningWithPython-220.png" style="border: 0;"/></a></p>
<h4 style="text-align: center;"> What If You Could Develop A Network in Minutes</h4>
<p style="text-align: center;">…with just a few lines of Python</p>
<p style="text-align: center;">Discover how in my new Ebook: <a href="https://machinelearningmastery.com/deep-learning-with-python/">Deep Learning With Python</a></p>
<p style="text-align: center;">It covers <strong>self-study tutorials</strong> and <strong>end-to-end projects</strong> on topics like:<br/>
<em>Multilayer Perceptrons</em>, <em>Convolutional Nets</em> and <em>Recurrent Neural Nets</em>, and more…</p>
<h4 style="text-align: center;">Finally Bring Deep Learning To<br/>
Your Own Projects</h4>
<p style="text-align: center;">Skip the Academics. Just Results.</p>
<p style="text-align: center;"><a href="https://machinelearningmastery.com/deep-learning-with-python/">Click to learn more</a>.</p>
<div class="woo-sc-hr"></div>
</div>
</div></div><div class="apss-social-share apss-theme-4 clearfix">
<div class="apss-twitter apss-single-icon">
<a href="javascript:void(0);" onclick="apss_open_in_popup_window(event, 'https://twitter.com/intent/tweet?text=A%20Gentle%20Introduction%20to%20Mini-Batch%20Gradient%20Descent%20and%20How%20to%20Configure%20Batch%20Size&amp;url=https%3A%2F%2Fmachinelearningmastery.com%2Fgentle-introduction-mini-batch-gradient-descent-configure-batch-size%2F&amp;');" rel="nofollow" target="" title="Share on Twitter">
<div class="apss-icon-block clearfix">
<i class="fa fa-twitter"></i>
<span class="apss-social-text">Share on Twitter</span><span class="apss-share">Tweet</span>
</div>
</a>
</div>
<div class="apss-facebook apss-single-icon">
<a href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/" onclick="apss_open_in_popup_window(event, 'https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/');" rel="nofollow" target="" title="Share on Facebook">
<div class="apss-icon-block clearfix">
<i class="fa fa-facebook"></i>
<span class="apss-social-text">Share on Facebook</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-linkedin apss-single-icon">
<a href="http://www.linkedin.com/shareArticle?mini=true&amp;title=A%20Gentle%20Introduction%20to%20Mini-Batch%20Gradient%20Descent%20and%20How%20to%20Configure%20Batch%20Size&amp;url=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/&amp;summary=Stochastic+gradient+descent+is+the+dominant+method+used+to+train+deep+learning+models.%0D%0A%0D%0AThere+are+..." onclick="apss_open_in_popup_window(event, 'http://www.linkedin.com/shareArticle?mini=true&amp;title=A%20Gentle%20Introduction%20to%20Mini-Batch%20Gradient%20Descent%20and%20How%20to%20Configure%20Batch%20Size&amp;url=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/&amp;summary=Stochastic+gradient+descent+is+the+dominant+method+used+to+train+deep+learning+models.%0D%0A%0D%0AThere+are+...');" rel="nofollow" target="" title="Share on LinkedIn">
<div class="apss-icon-block clearfix"><i class="fa fa-linkedin"></i>
<span class="apss-social-text">Share on LinkedIn</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-google-plus apss-single-icon">
<a href="https://plus.google.com/share?url=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/" onclick="apss_open_in_popup_window(event, 'https://plus.google.com/share?url=https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/');" rel="nofollow" target="" title="Share on Google Plus">
<div class="apss-icon-block clearfix">
<i class="fa fa-google-plus"></i>
<span class="apss-social-text">Share on Google Plus</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
</div> </section><!-- /.entry -->
<div class="fix"></div>
<aside id="post-author">
<div class="profile-image"><img alt="" class="avatar avatar-80 photo" height="80" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=160&amp;d=mm&amp;r=g 2x" width="80"/></div>
<div class="profile-content">
<h4>About Jason Brownlee</h4>
		Dr. Jason Brownlee is a husband, proud father, academic researcher, author, professional developer and a machine learning practitioner. He is dedicated to helping developers get started and get good at applied machine learning.
<a href="/about">Learn more</a>.				<div class="profile-link">
<a href="https://machinelearningmastery.com/author/jasonb/">
				View all posts by Jason Brownlee <span class="meta-nav">→</span> </a>
</div><!--#profile-link-->
</div>
<div class="fix"></div>
</aside>
<div class="post-utility"></div>
</article><!-- /.post -->
<div class="post-entries">
<div class="nav-prev fl"><a href="https://machinelearningmastery.com/sequence-prediction-problems-learning-lstm-recurrent-neural-networks/" rel="prev"><i class="fa fa-angle-left"></i> 5 Examples of Simple Sequence Prediction Problems for Learning LSTM Recurrent Neural Networks</a></div>
<div class="nav-next fr"><a href="https://machinelearningmastery.com/much-training-data-required-machine-learning/" rel="next">How Much Training Data is Required for Machine Learning? <i class="fa fa-angle-right"></i></a></div>
<div class="fix"></div>
</div>
<div id="comments"> <h3 id="comments-title">21 Responses to <em>A Gentle Introduction to Mini-Batch Gradient Descent and How to Configure Batch Size</em></h3>
<ol class="commentlist">
<li class="comment even thread-even depth-1" id="comment-407659">
<div class="comment-container" id="li-comment-407659">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/59f346ef4e414938b86f452c59b451e5?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/59f346ef4e414938b86f452c59b451e5?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Jie</span>
<span class="date">July 28, 2017 at 2:19 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-407659" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>In mini-batch part, “The model update frequency is lower than batch gradient descent which allows for a more robust convergence, avoiding local minima.”<br/>
I think this is lower than SGD, rather than BGD, am I wrong?</p>
<div class="reply">
<a aria-label="Reply to Jie" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=407659#respond" onclick='return addComment.moveForm( "comment-407659", "407659", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-407739">
<div class="comment-container" id="li-comment-407739">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">July 29, 2017 at 8:03 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-407739" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Typo, I meant “higher”. Fixed, thanks.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=407739#respond" onclick='return addComment.moveForm( "comment-407739", "407739", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment even thread-odd thread-alt depth-1" id="comment-407984">
<div class="comment-container" id="li-comment-407984">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/c8b59cf9856cfca6210dd4d2140f47c9?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/c8b59cf9856cfca6210dd4d2140f47c9?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Darlington</span>
<span class="date">July 31, 2017 at 12:29 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-407984" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Wait, so won’t that make Adam a mini-batch gradient descent algorithm, instead of stochastic gradient descent? (At least, in Keras’ implementation)<br/>
Since in Keras, when using Adam, you can still set batch size, rather than have it update weights per each data point</p>
<div class="reply">
<a aria-label="Reply to Darlington" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=407984#respond" onclick='return addComment.moveForm( "comment-407984", "407984", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-407999">
<div class="comment-container" id="li-comment-407999">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">July 31, 2017 at 3:50 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-407999" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>The idea of batches in SGD and the Adam optimizations of SGD are orthogonal.</p>
<p>You can use batches with or without Adam.</p>
<p>More on Adam here:<br/>
<a href="http://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" rel="nofollow">http://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/</a></p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=407999#respond" onclick='return addComment.moveForm( "comment-407999", "407999", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment even depth-3" id="comment-408055">
<div class="comment-container" id="li-comment-408055">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/c8b59cf9856cfca6210dd4d2140f47c9?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/c8b59cf9856cfca6210dd4d2140f47c9?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Darlington</span>
<span class="date">August 1, 2017 at 3:00 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-408055" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Oh ok, and also isn’t SGD called so because Gradient Descent is a greedy algorithm and searches for a minima along a slope which can lead to it getting stuck with local minima and to prevent that, Stochastic Gradient Descent uses various random iteration and then a proximates the global minima from all slopes, hence the “stochastic”?</p>
<div class="reply">
<a aria-label="Reply to Darlington" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=408055#respond" onclick='return addComment.moveForm( "comment-408055", "408055", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-4" id="comment-408093">
<div class="comment-container" id="li-comment-408093">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">August 1, 2017 at 8:04 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-408093" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Yes, right on, it adds noise to the process which allows the process to escape local optima in search of something better.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=408093#respond" onclick='return addComment.moveForm( "comment-408093", "408093", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment even thread-even depth-1" id="comment-410482">
<div class="comment-container" id="li-comment-410482">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/de683b611016bc221494aa857a6276c8?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/de683b611016bc221494aa857a6276c8?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Sabih</span>
<span class="date">August 22, 2017 at 3:33 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-410482" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Suppose my training data size is 1000 and batch size I selected is 128.<br/>
So, I would like to know how algorithm deals with last training set which is less than batch size?<br/>
In this case 7 weights update will be done till algorithm reach 896 training samples.</p>
<p>Now what happens for rest of 104 training samples.<br/>
Will it ignore the last training set or it will use 24 samples from next epoch?</p>
<div class="reply">
<a aria-label="Reply to Sabih" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=410482#respond" onclick='return addComment.moveForm( "comment-410482", "410482", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-410515">
<div class="comment-container" id="li-comment-410515">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">August 22, 2017 at 6:47 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-410515" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>It uses a smaller batch size for the last batch. The samples are still used.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=410515#respond" onclick='return addComment.moveForm( "comment-410515", "410515", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment even depth-3" id="comment-410524">
<div class="comment-container" id="li-comment-410524">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/de683b611016bc221494aa857a6276c8?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/de683b611016bc221494aa857a6276c8?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Sabih</span>
<span class="date">August 22, 2017 at 9:02 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-410524" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Thanks for the clarification.</p>
<div class="reply">
<a aria-label="Reply to Sabih" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=410524#respond" onclick='return addComment.moveForm( "comment-410524", "410524", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-419681">
<div class="comment-container" id="li-comment-419681">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/5e3e2e73741a3f85dd40976b0ec78126?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/5e3e2e73741a3f85dd40976b0ec78126?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Mark</span>
<span class="date">November 11, 2017 at 7:16 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-419681" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>These quotes are from this article and the linked articles.  They are subtly different, are they all true?</p>
<p>“Batch gradient descent is the most common form of gradient descent described in machine learning.”</p>
<p>“The most common optimization algorithm used in machine learning is stochastic gradient descent.”</p>
<p>“Mini-batch gradient descent is the recommended variant of gradient descent for most applications, especially in deep learning.”</p>
<div class="reply">
<a aria-label="Reply to Mark" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=419681#respond" onclick='return addComment.moveForm( "comment-419681", "419681", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-419707">
<div class="comment-container" id="li-comment-419707">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">November 11, 2017 at 9:29 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-419707" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Yes, batch/mini-batch are types of stochastic gradient descent.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=419707#respond" onclick='return addComment.moveForm( "comment-419707", "419707", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-even depth-1" id="comment-421418">
<div class="comment-container" id="li-comment-421418">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/de198a39aeed1eee9126650f1827c6ef?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/de198a39aeed1eee9126650f1827c6ef?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Yuqiong</span>
<span class="date">November 28, 2017 at 8:31 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-421418" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Thanks for the post! It’s a very elegant summry. </p>
<p>However, I don’t really understand this point for the benefits of stochastic gradient descent: </p>
<p>– The noisy update process can allow the model to avoid local minima (e.g. premature convergence).</p>
<p>Can I ask why is this the case?</p>
<div class="reply">
<a aria-label="Reply to Yuqiong" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=421418#respond" onclick='return addComment.moveForm( "comment-421418", "421418", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-421438">
<div class="comment-container" id="li-comment-421438">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">November 28, 2017 at 8:46 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-421438" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Wonderful question.</p>
<p>Because the weights will bounce around the solution space more and may bounce out of local minima given the larger variance in the updates to the weights.</p>
<p>Does that help?</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=421438#respond" onclick='return addComment.moveForm( "comment-421438", "421438", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-424461">
<div class="comment-container" id="li-comment-424461">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/6ad947313aecee6aae3ba26bbf7d6d29?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/6ad947313aecee6aae3ba26bbf7d6d29?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Andrew</span>
<span class="date">December 23, 2017 at 1:42 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-424461" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Great summary!  Concerning mini batch – you said “Implementations may choose to sum the gradient…”</p>
<p>Suppose there are 1000 training samples, and a mini batch size of 42.  So 23 mini batches of size 42, and 1 mini batch of size of 34.</p>
<p>if the weights are updated based only on the sum of the gradient, would that last mini batch with a different size cause problems since the number of summations isn’t the same as the other mini batches?</p>
<div class="reply">
<a aria-label="Reply to Andrew" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=424461#respond" onclick='return addComment.moveForm( "comment-424461", "424461", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-424491">
<div class="comment-container" id="li-comment-424491">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">December 23, 2017 at 5:21 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-424491" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Good question, in general it is better to have mini batches that have the same number of samples. In practice the difference does not seem to matter much.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=424491#respond" onclick='return addComment.moveForm( "comment-424491", "424491", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-even depth-1" id="comment-424998">
<div class="comment-container" id="li-comment-424998">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/0fad49c6aa6b527efa5cfd3e82082bf9?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/0fad49c6aa6b527efa5cfd3e82082bf9?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Shashi</span>
<span class="date">December 28, 2017 at 3:29 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-424998" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Shouldn’t <code>predict(X, train_data)</code> in your pseudocode be <code>predict(X, model)</code>?</p>
<div class="reply">
<a aria-label="Reply to Shashi" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=424998#respond" onclick='return addComment.moveForm( "comment-424998", "424998", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-425015">
<div class="comment-container" id="li-comment-425015">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">December 28, 2017 at 5:27 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-425015" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Yes, fixed. Thanks.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=425015#respond" onclick='return addComment.moveForm( "comment-425015", "425015", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-425489">
<div class="comment-container" id="li-comment-425489">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/86bc67a82a3466616a8d28002905c22f?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/86bc67a82a3466616a8d28002905c22f?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://www.devtechnologies.net/" rel="external nofollow">Igor Livshin</a></span>
<span class="date">January 3, 2018 at 5:50 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-425489" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Hi Jason,great post.<br/>
Could you please explain the meaning of “sum the gradient over the mini-batch or take the average of the gradient”. What we actually summing over the mini-batch? </p>
<p>When you say “take the average of the gradient” I presume you mean taking the average of the parameters calculated for all mini-batches.</p>
<p>Also, is this post is an excerpt from your book?</p>
<p>Thanks</p>
<div class="reply">
<a aria-label="Reply to Igor Livshin" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=425489#respond" onclick='return addComment.moveForm( "comment-425489", "425489", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-425508">
<div class="comment-container" id="li-comment-425508">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">January 3, 2018 at 3:42 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-425508" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>The estimate of the error gradient.</p>
<p>You can learn more about how the error gradient is calculated with a code example here:<br/>
<a href="https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/" rel="nofollow">https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/</a></p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=425508#respond" onclick='return addComment.moveForm( "comment-425508", "425508", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-even depth-1" id="comment-425496">
<div class="comment-container" id="li-comment-425496">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/86bc67a82a3466616a8d28002905c22f?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/86bc67a82a3466616a8d28002905c22f?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Igor Livshin</span>
<span class="date">January 3, 2018 at 10:01 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-425496" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Also, why in mini-batch gradient descent we simply use the output from one mini-batch processing as the input into the next mini-batch</p>
<div class="reply">
<a aria-label="Reply to Igor Livshin" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=425496#respond" onclick='return addComment.moveForm( "comment-425496", "425496", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-425509">
<div class="comment-container" id="li-comment-425509">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">January 3, 2018 at 3:43 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#comment-425509" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Sorry Igor, I don’t follow. Perhaps you can rephrase your question?</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/?replytocom=425509#respond" onclick='return addComment.moveForm( "comment-425509", "425509", "respond", "4147" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ol>
</div> <div class="comment-respond" id="respond">
<h3 class="comment-reply-title" id="reply-title">Leave a Reply <small><a href="/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/#respond" id="cancel-comment-reply-link" rel="nofollow" style="display:none;">Click here to cancel reply.</a></small></h3> <form action="https://machinelearningmastery.com/wp-comments-post.php?wpe-comment-post=mlmastery" class="comment-form" id="commentform" method="post">
<p class="comment-form-comment"><label class="hide" for="comment">Comment</label> <textarea aria-required="true" cols="50" id="comment" maxlength="65525" name="comment" required="required" rows="10" tabindex="4"></textarea></p><p class="comment-form-author"><input aria-required="true" class="txt" id="author" name="author" size="30" tabindex="1" type="text" value=""/><label for="author">Name <span class="required">(required)</span></label> </p>
<p class="comment-form-email"><input aria-required="true" class="txt" id="email" name="email" size="30" tabindex="2" type="text" value=""/><label for="email">Email (will not be published) <span class="required">(required)</span></label> </p>
<p class="comment-form-url"><input class="txt" id="url" name="url" size="30" tabindex="3" type="text" value=""/><label for="url">Website</label></p>
<p class="form-submit"><input class="submit" id="submit" name="submit" type="submit" value="Submit Comment"/> <input id="comment_post_ID" name="comment_post_ID" type="hidden" value="4147"/>
<input id="comment_parent" name="comment_parent" type="hidden" value="0"/>
</p><p style="display: none;"><input id="akismet_comment_nonce" name="akismet_comment_nonce" type="hidden" value="c0c9b79d0d"/></p><p style="display: none;"><input id="ak_js" name="ak_js" type="hidden" value="17"/></p> </form>
</div><!-- #respond -->
</section><!-- /#main -->
<aside id="sidebar">
<div class="widget widget_woo_blogauthorinfo" id="woo_blogauthorinfo-2"><h3>Welcome to Machine Learning Mastery</h3><span class="left"><img alt="" class="avatar avatar-100 photo" height="100" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=100&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=200&amp;d=mm&amp;r=g 2x" width="100"/></span>
<p>Hi, I'm Dr. Jason Brownlee.
<br/>
My goal is to make practitioners like YOU awesome at applied machine learning.</p>
<p><a href="/about">Read More</a></p>
<div class="fix"></div>
</div><div class="widget widget_text" id="text-6"> <div class="textwidget"><p></p><center>
<h3>Finally Get Started With Deep Learning</h3>
<p>Sick of the fancy math and need for super computers?<br/>
Looking for step-by-step tutorials?<br/>
Want end-to-end projects?</p>
<p><a href="https://machinelearningmastery.com/deep-learning-with-python/">Get Started With Deep Learning in Python Today!</a><br/>
<a href="https://machinelearningmastery.com/deep-learning-with-python/"><img src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/05/DeepLearningWithPython-220.png"/></a><br/>
</p></center>
</div>
</div>
<div class="widget widget_woo_tabs" id="woo_tabs-2"> <div id="tabs">
<ul class="wooTabs">
<li class="popular"><a href="#tab-pop">Popular</a></li> </ul>
<div class="clear"></div>
<div class="boxes box inside">
<ul class="list" id="tab-pop">
<li>
<a href="https://machinelearningmastery.com/machine-learning-in-python-step-by-step/" title="Your First Machine Learning Project in Python Step-By-Step"><img alt="Your First Machine Learning Project in Python Step-By-Step" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/Your-First-Machine-Learning-Project-in-Python-Step-By-Step-150x150.jpg" title="Your First Machine Learning Project in Python Step-By-Step" width="45"/></a> <a href="https://machinelearningmastery.com/machine-learning-in-python-step-by-step/" title="Your First Machine Learning Project in Python Step-By-Step">Your First Machine Learning Project in Python Step-By-Step</a>
<span class="meta">June 10, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/" title="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras"><img alt="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/07/Time-Series-Prediction-with-LSTM-Recurrent-Neural-Networks-in-Python-with-Keras-150x150.jpg" title="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras" width="45"/></a> <a href="https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/" title="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras">Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras</a>
<span class="meta">July 21, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/" title="Multivariate Time Series Forecasting with LSTMs in Keras"><img alt="Line Plots of Air Pollution Time Series" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/06/Line-Plots-of-Air-Pollution-Time-Series-150x150.png" title="Multivariate Time Series Forecasting with LSTMs in Keras" width="45"/></a> <a href="https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/" title="Multivariate Time Series Forecasting with LSTMs in Keras">Multivariate Time Series Forecasting with LSTMs in Keras</a>
<span class="meta">August 14, 2017</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/" title="Develop Your First Neural Network in Python With Keras Step-By-Step"><img alt="Tour of Deep Learning Algorithms" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/04/Tour-of-Deep-Learning-Algorithms-150x150.jpg" title="Develop Your First Neural Network in Python With Keras Step-By-Step" width="45"/></a> <a href="https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/" title="Develop Your First Neural Network in Python With Keras Step-By-Step">Develop Your First Neural Network in Python With Keras Step-By-Step</a>
<span class="meta">May 24, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/setup-python-environment-machine-learning-deep-learning-anaconda/" title="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda"><img alt="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/03/How-to-Setup-a-Python-Environment-for-Machine-Learning-and-Deep-Learning-with-Anaconda-150x150.png" title="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda" width="45"/></a> <a href="https://machinelearningmastery.com/setup-python-environment-machine-learning-deep-learning-anaconda/" title="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda">How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda</a>
<span class="meta">March 13, 2017</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/" title="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras"><img alt="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/07/Sequence-Classification-with-LSTM-Recurrent-Neural-Networks-in-Python-with-Keras-150x150.jpg" title="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras" width="45"/></a> <a href="https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/" title="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras">Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras</a>
<span class="meta">July 26, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/" title="Time Series Forecasting with the Long Short-Term Memory Network in Python"><img alt="Time Series Forecasting with the Long Short-Term Memory Network in Python" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/04/Time-Series-Forecasting-with-the-Long-Short-Term-Memory-Network-in-Python-150x150.jpg" title="Time Series Forecasting with the Long Short-Term Memory Network in Python" width="45"/></a> <a href="https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/" title="Time Series Forecasting with the Long Short-Term Memory Network in Python">Time Series Forecasting with the Long Short-Term Memory Network in Python</a>
<span class="meta">April 7, 2017</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/" title="Multi-Class Classification Tutorial with the Keras Deep Learning Library"><img alt="Multi-Class Classification Tutorial with the Keras Deep Learning Library" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/Multi-Class-Classification-Tutorial-with-the-Keras-Deep-Learning-Library-150x150.jpg" title="Multi-Class Classification Tutorial with the Keras Deep Learning Library" width="45"/></a> <a href="https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/" title="Multi-Class Classification Tutorial with the Keras Deep Learning Library">Multi-Class Classification Tutorial with the Keras Deep Learning Library</a>
<span class="meta">June 2, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/" title="Regression Tutorial with the Keras Deep Learning Library in Python"><img alt="Regression Tutorial with Keras Deep Learning Library in Python" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/Regression-Tutorial-with-Keras-Deep-Learning-Library-in-Python-150x150.jpg" title="Regression Tutorial with the Keras Deep Learning Library in Python" width="45"/></a> <a href="https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/" title="Regression Tutorial with the Keras Deep Learning Library in Python">Regression Tutorial with the Keras Deep Learning Library in Python</a>
<span class="meta">June 9, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/" title="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras"><img alt="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/08/How-to-Grid-Search-Hyperparameters-for-Deep-Learning-Models-in-Python-With-Keras-150x150.jpg" title="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras" width="45"/></a> <a href="https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/" title="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras">How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras</a>
<span class="meta">August 9, 2016</span>
<div class="fix"></div>
</li>
</ul>
</div><!-- /.boxes -->
</div><!-- /wooTabs -->
</div> </aside><!-- /#sidebar -->
</div><!-- /#main-sidebar-container -->
</div><!-- /#content -->
<footer class="col-full" id="footer">
<div class="col-left" id="copyright">
<p>© 2018 Machine Learning Mastery. All Rights Reserved. </p> </div>
<div class="col-right" id="credit">
<p></p><p>
<a href="/privacy/">Privacy</a> | 
<a href="/contact/">Contact</a> |
<a href="/about/">About</a>
</p> </div>
</footer>
</div><!-- /#inner-wrapper -->
</div><!-- /#wrapper -->
<div class="fix"></div><!--/.fix-->
<!-- Drip -->
<script type="text/javascript">
  var _dcq = _dcq || [];
  var _dcs = _dcs || {}; 
  _dcs.account = '9556588';
  
  (function() {
    var dc = document.createElement('script');
    dc.type = 'text/javascript'; dc.async = true; 
    dc.src = '//tag.getdrip.com/9556588.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(dc, s);
  })();
</script><!-- Woo Tabs Widget -->
<script type="text/javascript">
jQuery(document).ready(function(){
	// UL = .wooTabs
	// Tab contents = .inside

	var tag_cloud_class = '#tagcloud';

	//Fix for tag clouds - unexpected height before .hide()
	var tag_cloud_height = jQuery( '#tagcloud').height();

	jQuery( '.inside ul li:last-child').css( 'border-bottom','0px' ); // remove last border-bottom from list in tab content
	jQuery( '.wooTabs').each(function(){
		jQuery(this).children( 'li').children( 'a:first').addClass( 'selected' ); // Add .selected class to first tab on load
	});
	jQuery( '.inside > *').hide();
	jQuery( '.inside > *:first-child').show();

	jQuery( '.wooTabs li a').click(function(evt){ // Init Click funtion on Tabs

		var clicked_tab_ref = jQuery(this).attr( 'href' ); // Strore Href value

		jQuery(this).parent().parent().children( 'li').children( 'a').removeClass( 'selected' ); //Remove selected from all tabs
		jQuery(this).addClass( 'selected' );
		jQuery(this).parent().parent().parent().children( '.inside').children( '*').hide();

		jQuery( '.inside ' + clicked_tab_ref).fadeIn(500);

		 evt.preventDefault();

	})
})
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/comment-reply.min.js?ver=4.9.2" type="text/javascript"></script>
<script type="text/javascript">
/* <![CDATA[ */
var wpcf7 = {"apiSettings":{"root":"https:\/\/machinelearningmastery.com\/wp-json\/contact-form-7\/v1","namespace":"contact-form-7\/v1"},"recaptcha":{"messages":{"empty":"Please verify that you are not a robot."}},"cached":"1"};
/* ]]> */
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/contact-form-7/includes/js/scripts.js?ver=4.9.2" type="text/javascript"></script>
<script type="text/javascript">
/* <![CDATA[ */
var frontend_ajax_object = {"ajax_url":"https:\/\/machinelearningmastery.com\/wp-admin\/admin-ajax.php","ajax_nonce":"555b70787c"};
/* ]]> */
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/seo-optimized-share-buttons/js/frontend.js?ver=4.2.2.0.iis7_supports_permalinks" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/wp-embed.min.js?ver=4.9.2" type="text/javascript"></script>
<script async="async" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/akismet/_inc/form.js?ver=4.0.2" type="text/javascript"></script>
</body>
</html>