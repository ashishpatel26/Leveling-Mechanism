<html lang="en-US" prefix="og: http://ogp.me/ns#">
<head>
<meta charset="utf-8"/>
<title>Encoder-Decoder Models for Text Summarization in Keras - Machine Learning Mastery</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<link href="https://machinelearningmastery.com/xmlrpc.php" rel="pingback"/>
<!--  Mobile viewport scale -->
<meta content="initial-scale=1.0, maximum-scale=1.0, user-scalable=yes" name="viewport"/>
<!-- This site is optimized with the Yoast SEO plugin v6.1.1 - https://yoa.st/1yg?utm_content=6.1.1 -->
<link href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/" rel="canonical"/>
<link href="https://plus.google.com/u/0/b/117073416089354242117/+MachinelearningmasteryHome/" rel="publisher"/>
<meta content="en_US" property="og:locale"/>
<meta content="article" property="og:type"/>
<meta content="Encoder-Decoder Models for Text Summarization in Keras - Machine Learning Mastery" property="og:title"/>
<meta content="Text summarization is a problem in natural language processing of creating a short, accurate, and fluent summary of a source document. The Encoder-Decoder recurrent neural network architecture developed for machine translation has proven effective when applied to the problem of text summarization. It can be difficult to apply this architecture in the Keras deep learning …" property="og:description"/>
<meta content="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/" property="og:url"/>
<meta content="Machine Learning Mastery" property="og:site_name"/>
<meta content="https://www.facebook.com/Machine-Learning-Mastery-1429846323896563/" property="article:publisher"/>
<meta content="Natural Language Processing" property="article:section"/>
<meta content="2017-12-08T05:00:04+11:00" property="article:published_time"/>
<meta content="2017-11-21T11:07:52+11:00" property="article:modified_time"/>
<meta content="2017-11-21T11:07:52+11:00" property="og:updated_time"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/12/Encoder-Decoder-Models-for-Text-Summarization-in-Keras.jpg" property="og:image"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/12/Encoder-Decoder-Models-for-Text-Summarization-in-Keras.jpg" property="og:image:secure_url"/>
<meta content="640" property="og:image:width"/>
<meta content="427" property="og:image:height"/>
<script type="application/ld+json">{"@context":"http:\/\/schema.org","@type":"WebSite","@id":"#website","url":"https:\/\/machinelearningmastery.com\/","name":"Machine Learning Mastery","potentialAction":{"@type":"SearchAction","target":"https:\/\/machinelearningmastery.com\/?s={search_term_string}","query-input":"required name=search_term_string"}}</script>
<script type="application/ld+json">{"@context":"http:\/\/schema.org","@type":"Organization","url":"https:\/\/machinelearningmastery.com\/encoder-decoder-models-text-summarization-keras\/","sameAs":["https:\/\/www.facebook.com\/Machine-Learning-Mastery-1429846323896563\/","https:\/\/www.linkedin.com\/in\/jasonbrownlee","https:\/\/plus.google.com\/u\/0\/b\/117073416089354242117\/+MachinelearningmasteryHome\/","https:\/\/twitter.com\/TeachTheMachine"],"@id":"#organization","name":"Machine Learning Mastery","logo":"https:\/\/machinelearningmastery.com\/wp-content\/uploads\/2016\/09\/cropped-icon.png"}</script>
<!-- / Yoast SEO plugin. -->
<link href="//cdnjs.cloudflare.com" rel="dns-prefetch"/>
<link href="//fonts.googleapis.com" rel="dns-prefetch"/>
<link href="//s.w.org" rel="dns-prefetch"/>
<link href="https://feeds.feedburner.com/MachineLearningMastery" rel="alternate" title="Machine Learning Mastery » Feed" type="application/rss+xml"/>
<link href="https://machinelearningmastery.com/comments/feed/" rel="alternate" title="Machine Learning Mastery » Comments Feed" type="application/rss+xml"/>
<link href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/feed/" rel="alternate" title="Machine Learning Mastery » Encoder-Decoder Models for Text Summarization in Keras Comments Feed" type="application/rss+xml"/>
<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.3\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.3\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/machinelearningmastery.com\/wp-includes\/js\/wp-emoji-release.min.js?ver=4.9.2"}};
			!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline="top",l.font="600 32px Arial",a){case"flag":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case"emoji":return b=d([55358,56794,8205,9794,65039],[55358,56794,8203,9794,65039]),!b}return!1}function f(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var g,h,i,j,k=b.createElement("canvas"),l=k.getContext&&k.getContext("2d");for(j=Array("flag","emoji"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],"flag"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",h,!1),a.addEventListener("load",h,!1)):(a.attachEvent("onload",h),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/css/min/crayon.min.css?ver=_2.7.2_beta" id="crayon-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/themes/classic/classic.css?ver=_2.7.2_beta" id="crayon-theme-classic-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/fonts/monaco.css?ver=_2.7.2_beta" id="crayon-font-monaco-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/contact-form-7/includes/css/styles.css?ver=4.9.2" id="contact-form-7-css" media="all" rel="stylesheet" type="text/css"/>
<link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.4.0/css/font-awesome.min.css?ver=4.2.2.0.iis7_supports_permalinks" id="apss-font-awesome-css" media="all" rel="stylesheet" type="text/css"/>
<link href="//fonts.googleapis.com/css?family=Open+Sans&amp;ver=4.9.2" id="apss-font-opensans-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/seo-optimized-share-buttons/css/frontend.css?ver=4.2.2.0.iis7_supports_permalinks" id="apss-frontend-css-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/integrations/testimonials/css/testimonials.css?ver=4.9.2" id="woo-testimonials-css-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/style.css?ver=5.9.21" id="theme-stylesheet-css" media="all" rel="stylesheet" type="text/css"/>
<!--[if lt IE 9]>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/css/non-responsive.css" rel="stylesheet" type="text/css" />
<style type="text/css">.col-full, #wrapper { width: 960px; max-width: 960px; } #inner-wrapper { padding: 0; } body.full-width #header, #nav-container, body.full-width #content, body.full-width #footer-widgets, body.full-width #footer { padding-left: 0; padding-right: 0; } body.fixed-mobile #top, body.fixed-mobile #header-container, body.fixed-mobile #footer-container, body.fixed-mobile #nav-container, body.fixed-mobile #footer-widgets-container { min-width: 960px; padding: 0 1em; } body.full-width #content { width: auto; padding: 0 1em;}</style>
<![endif]-->
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/jquery/jquery.js?ver=1.12.4" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.4.1" type="text/javascript"></script>
<script type="text/javascript">
/* <![CDATA[ */
var CrayonSyntaxSettings = {"version":"_2.7.2_beta","is_admin":"0","ajaxurl":"https:\/\/machinelearningmastery.com\/wp-admin\/admin-ajax.php","prefix":"crayon-","setting":"crayon-setting","selected":"crayon-setting-selected","changed":"crayon-setting-changed","special":"crayon-setting-special","orig_value":"data-orig-value","debug":""};
var CrayonSyntaxStrings = {"copy":"Press %s to Copy, %s to Paste","minimize":"Click To Expand Code"};
/* ]]> */
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/js/min/crayon.min.js?ver=_2.7.2_beta" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/third-party.min.js?ver=4.9.2" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/modernizr.min.js?ver=2.6.2" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/general.min.js?ver=4.9.2" type="text/javascript"></script>
<link href="https://machinelearningmastery.com/wp-json/" rel="https://api.w.org/"/>
<link href="https://machinelearningmastery.com/xmlrpc.php?rsd" rel="EditURI" title="RSD" type="application/rsd+xml"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/wlwmanifest.xml" rel="wlwmanifest" type="application/wlwmanifest+xml"/>
<link href="https://machinelearningmastery.com/?p=4481" rel="shortlink"/>
<link href="https://machinelearningmastery.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fmachinelearningmastery.com%2Fencoder-decoder-models-text-summarization-keras%2F" rel="alternate" type="application/json+oembed"/>
<link href="https://machinelearningmastery.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fmachinelearningmastery.com%2Fencoder-decoder-models-text-summarization-keras%2F&amp;format=xml" rel="alternate" type="text/xml+oembed"/>
<!-- Start Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44039733-3', 'auto');
  ga('send', 'pageview');

</script>
<!-- End Google Analytics -->
<!-- Facebook Pixel Code -->
<script>
!function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function(){n.callMethod?
n.callMethod.apply(n,arguments):n.queue.push(arguments)};if(!f._fbq)f._fbq=n;
n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;
t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,
document,'script','https://connect.facebook.net/en_US/fbevents.js');

fbq('init', '296263687421164');
fbq('track', "PageView");</script>
<noscript><img height="1" src="https://www.facebook.com/tr?id=296263687421164&amp;ev=PageView&amp;noscript=1" style="display:none" width="1"/></noscript>
<!-- End Facebook Pixel Code -->
<!-- Custom CSS Styling -->
<style type="text/css">
#logo .site-title, #logo .site-description { display:none; }
body {background-repeat:no-repeat;background-position:top left;background-attachment:scroll;border-top:0px solid #000000;}
#header {background-repeat:no-repeat;background-position:left top;margin-top:0px;margin-bottom:0px;padding-top:10px;padding-bottom:10px;border:0px solid ;}
#logo .site-title a {font:bold 40px/1em Helvetica Neue, Helvetica, sans-serif;color:#222222;}
#logo .site-description {font:300 13px/1em Helvetica Neue, Helvetica, sans-serif;color:#999999;}
body, p { font:300 14px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#555555; }
h1 { font:bold 28px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h2 { font:bold 24px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h3 { font:bold 20px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h4 { font:bold 16px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h5 { font:bold 14px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h6 { font:bold 12px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }
.page-title, .post .title, .page .title {font:bold 28px/1.1em "Helvetica Neue", Helvetica, sans-serif;color:#222222;}
.post .title a:link, .post .title a:visited, .page .title a:link, .page .title a:visited {color:#222222}
.post-meta { font:300 12px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#999999; }
.entry, .entry p{ font:300 15px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#555555; }
.post-more {font:300 13px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:;border-top:0px solid #e6e6e6;border-bottom:0px solid #e6e6e6;}
#post-author, #connect {border-top:1px solid #e6e6e6;border-bottom:1px solid #e6e6e6;border-left:1px solid #e6e6e6;border-right:1px solid #e6e6e6;border-radius:5px;-moz-border-radius:5px;-webkit-border-radius:5px;background-color:#fafafa}
.nav-entries a, .woo-pagination { font:300 13px/1em "Helvetica Neue", Helvetica, sans-serif;color:#888; }
.woo-pagination a, .woo-pagination a:hover {color:#888!important}
.widget h3 {font:bold 14px/1.2em &quot;Helvetica Neue&quot;, Helvetica, sans-serif;color:#555555;border-bottom:1px solid #e6e6e6;}
.widget_recent_comments li, #twitter li { border-color: #e6e6e6;}
.widget p, .widget .textwidget { font:300 13px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#555555; }
.widget {font:300 13px/1.5em &quot;Helvetica Neue&quot;, Helvetica, sans-serif;color:#555555;border-radius:0px;-moz-border-radius:0px;-webkit-border-radius:0px;}
#tabs .inside li a, .widget_woodojo_tabs .tabbable .tab-pane li a { font:bold 12px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#555555; }
#tabs .inside li span.meta, .widget_woodojo_tabs .tabbable .tab-pane li span.meta { font:300 11px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#999999; }
#tabs ul.wooTabs li a, .widget_woodojo_tabs .tabbable .nav-tabs li a { font:300 11px/2em Helvetica Neue, Helvetica, sans-serif;color:#999999; }
@media only screen and (min-width:768px) {
ul.nav li a, #navigation ul.rss a, #navigation ul.cart a.cart-contents, #navigation .cart-contents #navigation ul.rss, #navigation ul.nav-search, #navigation ul.nav-search a { font:300 14px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#666666; } #navigation ul.rss li a:before, #navigation ul.nav-search a.search-contents:before { color:#666666;}
#navigation ul.nav li ul, #navigation ul.cart > li > ul > div  { border: 0px solid #dbdbdb; }
#navigation ul.nav > li:hover > ul  { left: 0; }
#navigation ul.nav > li  { border-right: 0px solid #dbdbdb; }#navigation ul.nav > li:hover > ul  { left: 0; }
#navigation { box-shadow: none; -moz-box-shadow: none; -webkit-box-shadow: none; }#navigation ul li:first-child, #navigation ul li:first-child a { border-radius:0px 0 0 0px; -moz-border-radius:0px 0 0 0px; -webkit-border-radius:0px 0 0 0px; }
#navigation {border-top:0px solid #dbdbdb;border-bottom:0px solid #dbdbdb;border-left:0px solid #dbdbdb;border-right:0px solid #dbdbdb;border-radius:0px; -moz-border-radius:0px; -webkit-border-radius:0px;}
#top ul.nav li a { font:300 12px/1.6em Helvetica Neue, Helvetica, sans-serif;color:#ddd; }
}
#footer, #footer p { font:300 13px/1.4em Helvetica Neue, Helvetica, sans-serif;color:#999999; }
#footer {border-top:1px solid #dbdbdb;border-bottom:0px solid ;border-left:0px solid ;border-right:0px solid ;border-radius:0px; -moz-border-radius:0px; -webkit-border-radius:0px;}
.magazine #loopedSlider .content h2.title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-magazine .slide-title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.magazine #loopedSlider .content .excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-magazine .slide-content p, .wooslider-theme-magazine .slide-excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.magazine .block .post .title a {font:bold 18px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }
#loopedSlider.business-slider .content h2 { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
#loopedSlider.business-slider .content h2.title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-business .has-featured-image .slide-title { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-business .has-featured-image .slide-title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
#wrapper #loopedSlider.business-slider .content p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-business .has-featured-image .slide-content p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-business .has-featured-image .slide-excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.archive_header { font:bold 18px/1em Arial, sans-serif;color:#222222; }
.archive_header {border-bottom:1px solid #e6e6e6;}
.archive_header .catrss { display:none; }
</style>
<!-- Woo Shortcodes CSS -->
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/functions/css/shortcodes.css" rel="stylesheet" type="text/css"/>
<!-- Custom Stylesheet -->
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/custom.css" rel="stylesheet" type="text/css"/>
<!-- Theme version -->
<meta content="Canvas 5.9.21" name="generator"/>
<meta content="WooFramework 6.2.9" name="generator"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-32x32.png" rel="icon" sizes="32x32"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-192x192.png" rel="icon" sizes="192x192"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-180x180.png" rel="apple-touch-icon-precomposed"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-270x270.png" name="msapplication-TileImage"/>
</head>
<body class="post-template-default single single-post postid-4481 single-format-standard safari alt-style-default two-col-left width-960 two-col-left-960">
<div id="wrapper">
<div id="inner-wrapper">
<h3 class="nav-toggle icon"><a href="#navigation">Navigation</a></h3>
<header class="col-full" id="header">
<div id="logo">
<a href="https://machinelearningmastery.com/" title="Making developers awesome at machine learning"><img alt="Machine Learning Mastery" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/MachineLearningMastery.png"/></a>
<span class="site-title"><a href="https://machinelearningmastery.com/">Machine Learning Mastery</a></span>
<span class="site-description">Making developers awesome at machine learning</span>
</div>
<div class="header-widget">
<div class="widget widget_text" id="text-3"> <div class="textwidget"><br/>
<div style="font-size:12pt;">
<a href="/start-here"><strong>Start Here</strong></a>
     
<a href="/blog">Blog</a>
     
<a href="/products">Books</a>
     
<a href="/about">About</a>
     
<a href="/contact">Contact</a>
</div></div>
</div><div class="widget widget_search" id="search-3"><div class="search_main">
<form action="https://machinelearningmastery.com/" class="searchform" method="get">
<input class="field s" name="s" onblur="if (this.value == '') {this.value = 'Search...';}" onfocus="if (this.value == 'Search...') {this.value = '';}" type="text" value="Search..."/>
<button class="fa fa-search submit" name="submit" type="submit" value="Search"></button>
</form>
<div class="fix"></div>
</div></div><div class="widget widget_text" id="text-44"> <div class="textwidget"><p>Need help with Deep Learning for Text? <a href="https://machinelearningmastery.lpages.co/dlfnlp-mini-course/">Take the FREE Mini-Course</a></p>
</div>
</div> </div>
</header>
<nav class="col-full" id="navigation" role="navigation">
<section class="menus">
<a class="nav-home" href="https://machinelearningmastery.com"><span>Home</span></a>
<h3>Empty Menu</h3> <div class="side-nav">
</div><!-- /#side-nav -->
</section><!-- /.menus -->
<a class="nav-close" href="#top"><span>Return to Content</span></a>
</nav>
<!-- #content Starts -->
<div class="col-full" id="content">
<div id="main-sidebar-container">
<!-- #main Starts -->
<section id="main">
<article class="post-4481 post type-post status-publish format-standard has-post-thumbnail hentry category-natural-language-processing">
<header>
<h1 class="title entry-title">Encoder-Decoder Models for Text Summarization in Keras</h1> </header>
<div class="post-meta"><span class="small">By</span> <span class="author vcard"><span class="fn"><a href="https://machinelearningmastery.com/author/jasonb/" rel="author" title="Posts by Jason Brownlee">Jason Brownlee</a></span></span> <span class="small">on</span> <abbr class="date time published updated" title="2017-12-08T05:00:04+1100">December 8, 2017</abbr> <span class="small">in</span> <span class="categories"><a href="https://machinelearningmastery.com/category/natural-language-processing/" title="View all items in Natural Language Processing">Natural Language Processing</a></span> </div>
<section class="entry">
<div class="apss-social-share apss-theme-4 clearfix">
<div class="apss-twitter apss-single-icon">
<a href="javascript:void(0);" onclick="apss_open_in_popup_window(event, 'https://twitter.com/intent/tweet?text=Encoder-Decoder%20Models%20for%20Text%20Summarization%20in%20Keras&amp;url=https%3A%2F%2Fmachinelearningmastery.com%2Fencoder-decoder-models-text-summarization-keras%2F&amp;');" rel="nofollow" target="" title="Share on Twitter">
<div class="apss-icon-block clearfix">
<i class="fa fa-twitter"></i>
<span class="apss-social-text">Share on Twitter</span><span class="apss-share">Tweet</span>
</div>
</a>
</div>
<div class="apss-facebook apss-single-icon">
<a href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/" onclick="apss_open_in_popup_window(event, 'https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/');" rel="nofollow" target="" title="Share on Facebook">
<div class="apss-icon-block clearfix">
<i class="fa fa-facebook"></i>
<span class="apss-social-text">Share on Facebook</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-linkedin apss-single-icon">
<a href="http://www.linkedin.com/shareArticle?mini=true&amp;title=Encoder-Decoder%20Models%20for%20Text%20Summarization%20in%20Keras&amp;url=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/&amp;summary=Text+summarization+is+a+problem+in+natural+language+processing+of+creating+a+short%2C+accurate%2C+and+fl..." onclick="apss_open_in_popup_window(event, 'http://www.linkedin.com/shareArticle?mini=true&amp;title=Encoder-Decoder%20Models%20for%20Text%20Summarization%20in%20Keras&amp;url=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/&amp;summary=Text+summarization+is+a+problem+in+natural+language+processing+of+creating+a+short%2C+accurate%2C+and+fl...');" rel="nofollow" target="" title="Share on LinkedIn">
<div class="apss-icon-block clearfix"><i class="fa fa-linkedin"></i>
<span class="apss-social-text">Share on LinkedIn</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-google-plus apss-single-icon">
<a href="https://plus.google.com/share?url=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/" onclick="apss_open_in_popup_window(event, 'https://plus.google.com/share?url=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/');" rel="nofollow" target="" title="Share on Google Plus">
<div class="apss-icon-block clearfix">
<i class="fa fa-google-plus"></i>
<span class="apss-social-text">Share on Google Plus</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
</div><p>Text summarization is a problem in natural language processing of creating a short, accurate, and fluent summary of a source document.</p>
<p>The Encoder-Decoder recurrent neural network architecture developed for machine translation has proven effective when applied to the problem of text summarization.</p>
<p>It can be difficult to apply this architecture in the Keras deep learning library, given some of the flexibility sacrificed to make the library clean, simple, and easy to use.</p>
<p>In this tutorial, you will discover how to implement the Encoder-Decoder architecture for text summarization in Keras.</p>
<p>After completing this tutorial, you will know:</p>
<ul>
<li>How text summarization can be addressed using the Encoder-Decoder recurrent neural network architecture.</li>
<li>How different encoders and decoders can be implemented for the problem.</li>
<li>Three models that you can use to implemented the architecture for text summarization in Keras.</li>
</ul>
<p>Let’s get started.</p>
<div class="wp-caption aligncenter" id="attachment_4487" style="max-width: 650px"><img alt="Encoder-Decoder Models for Text Summarization in Keras" class="wp-image-4487 size-full" height="427" sizes="(max-width: 640px) 100vw, 640px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/12/Encoder-Decoder-Models-for-Text-Summarization-in-Keras.jpg" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/12/Encoder-Decoder-Models-for-Text-Summarization-in-Keras.jpg 640w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/12/Encoder-Decoder-Models-for-Text-Summarization-in-Keras-300x200.jpg 300w" width="640"/><p class="wp-caption-text">Encoder-Decoder Models for Text Summarization in Keras<br/>Photo by <a href="https://www.flickr.com/photos/diogofreire/4766208168/">Diogo Freire</a>, some rights reserved.</p></div>
<h2>Tutorial Overview</h2>
<p>This tutorial is divided into 5 parts; they are:</p>
<ol>
<li>Encoder-Decoder Architecture</li>
<li>Text Summarization Encoders</li>
<li>Text Summarization Decoders</li>
<li>Reading Source Text</li>
<li>Implementation Models</li>
</ol>
<!-- Start shortcoder --><p></p><div class="woo-sc-hr"></div>
<center>
<h3>Need help with Deep Learning for Text Data?</h3>
<p>Take my free 7-day email crash course now (with sample code).</p>
<p>Click to sign-up and also get a free PDF Ebook version of the course.</p>
<p><a href="https://machinelearningmastery.lpages.co/leadbox/144855173f72a2%3A164f8be4f346dc/5655638436741120/" rel="noopener" style="background: #ffce0a; color: #ffffff; text-decoration: none; font-family: Helvetica, Arial, sans-serif; font-weight: bold; font-size: 16px; line-height: 20px; padding: 10px; display: inline-block; max-width: 300px; border-radius: 5px; text-shadow: rgba(0, 0, 0, 0.25) 0px -1px 1px; box-shadow: rgba(255, 255, 255, 0.5) 0px 1px 3px inset, rgba(0, 0, 0, 0.5) 0px 1px 3px;" target="_blank">Start Your FREE Crash-Course Now</a><script data-config="%7B%7D" data-leadbox="144855173f72a2:164f8be4f346dc" data-url="https://machinelearningmastery.lpages.co/leadbox/144855173f72a2%3A164f8be4f346dc/5655638436741120/" src="https://machinelearningmastery.lpages.co/leadbox-1509466860.js" type="text/javascript"></script></p>
</center>
<p></p><div class="woo-sc-hr"></div><!-- End shortcoder v4.1.5-->
<h2>Encoder-Decoder Architecture</h2>
<p>The Encoder-Decoder architecture is a way of organizing recurrent neural networks for sequence prediction problems that have a variable number of inputs, outputs, or both inputs and outputs.</p>
<p>The architecture involves two components: an encoder and a decoder.</p>
<ul>
<li><strong>Encoder</strong>: The encoder reads the entire input sequence and encodes it into an internal representation, often a fixed-length vector called the context vector.</li>
<li><strong>Decoder</strong>: The decoder reads the encoded input sequence from the encoder and generates the output sequence.</li>
</ul>
<p>For more about the Encoder-Decoder architecture, see the post:</p>
<ul>
<li><a href="https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/">Encoder-Decoder Long Short-Term Memory Networks</a></li>
</ul>
<p>Both the encoder and the decoder submodels are trained jointly, meaning at the same time.</p>
<p>This is quite a feat as traditionally, challenging natural language problems required the development of separate models that were later strung into a pipeline, allowing error to accumulate during the sequence generation process.</p>
<p>The entire encoded input is used as context for generating each step in the output. Although this works, the fixed-length encoding of the input limits the length of output sequences that can be generated.</p>
<p>An extension of the Encoder-Decoder architecture is to provide a more expressive form of the encoded input sequence and allow the decoder to learn where to pay attention to the encoded input when generating each step of the output sequence.</p>
<p>This extension of the architecture is called attention.</p>
<p>For more about Attention in the Encoder-Decoder architecture, see the post:</p>
<ul>
<li><a href="https://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/">Attention in Long Short-Term Memory Recurrent Neural Networks</a></li>
</ul>
<p>The Encoder-Decoder architecture with attention is popular for a suite of natural language processing problems that generate variable length output sequences, such as text summarization.</p>
<p>The application of architecture to text summarization is as follows:</p>
<ul>
<li><strong>Encoder</strong>: The encoder is responsible for reading the source document and encoding it to an internal representation.</li>
<li><strong>Decoder</strong>: The decoder is a language model responsible for generating each word in the output summary using the encoded representation of the source document.</li>
</ul>
<h2>Text Summarization Encoders</h2>
<p>The encoder is where the complexity of the model resides as it is responsible for capturing the meaning of the source document.</p>
<p>Different types of encoders can be used, although more commonly bidirectional recurrent neural networks, such as LSTMs, are used. In cases where recurrent neural networks are used in the encoder, a word embedding is used to provide a distributed representation of words.</p>
<p>Alexander Rush, et al. uses a simple bag-of-words encoder that discards word order and convolutional encoders that explicitly try to capture n-grams.</p>
<blockquote><p>Our most basic model simply uses the bag-of-words of the input sentence embedded down to size H, while ignoring properties of the original order or relationships between neighboring words. […] To address some of the modelling issues with bag-of-words we also consider using a deep convolutional encoder for the input sentence.</p></blockquote>
<p>— <a href="https://arxiv.org/abs/1509.00685">A Neural Attention Model for Abstractive Sentence Summarization</a>, 2015.</p>
<p>Konstantin Lopyrev uses a deep stack of 4 LSTM recurrent neural networks as the encoder.</p>
<blockquote><p>The encoder is fed as input the text of a news article one word of a time. Each word is first passed through an embedding layer that transforms the word into a distributed representation. That distributed representation is then combined using a multi-layer neural network</p></blockquote>
<p>— <a href="https://arxiv.org/abs/1512.01712">Generating News Headlines with Recurrent Neural Networks</a>, 2015.</p>
<p>Abigail See, et al. use a single-layer bidirectional LSTM as the encoder.</p>
<blockquote><p>The tokens of the article w(i) are fed one-by-one into the encoder (a single-layer bidirectional LSTM), producing a sequence of encoder hidden states h(i).</p></blockquote>
<p>— <a href="https://arxiv.org/abs/1704.04368">Get To The Point: Summarization with Pointer-Generator Networks</a>, 2017.</p>
<p>Ramesh Nallapati, et al. use bidirectional GRU recurrent neural networks in their encoders and incorporate additional information about each word in the input sequence.</p>
<blockquote><p>The encoder consists of a bidirectional GRU-RNN…</p></blockquote>
<p>— <a href="https://arxiv.org/abs/1602.06023">Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond</a>, 2016.</p>
<h2>Text Summarization Decoders</h2>
<p>The decoder must generate each word in the output sequence given two sources of information:</p>
<ol>
<li><strong>Context Vector</strong>: The encoded representation of the source document provided by the encoder.</li>
<li><strong>Generated Sequence</strong>: The word or sequence of words already generated as a summary.</li>
</ol>
<p>The context vector may be a fixed-length encoding as in the simple Encoder-Decoder architecture, or may be a more expressive form filtered via an attention mechanism.</p>
<p>The generated sequence is provided with little preparation, such as distributed representation of each generated word via a word embedding.</p>
<blockquote><p>On each step t, the decoder (a single-layer unidirectional LSTM) receives the word embedding of the previous word (while training, this is the previous word of the reference summary; at test time it is the previous word emitted by the decoder)</p></blockquote>
<p>— <a href="https://arxiv.org/abs/1704.04368">Get To The Point: Summarization with Pointer-Generator Networks</a>, 2017.</p>
<p>Alexander Rush, et al. show this cleanly in a diagram where <em>x</em> is the source document, <em>enc</em> is the encoder providing internal representation of the source document, and <em>yc</em> is the sequence of previously generated words.</p>
<div class="wp-caption aligncenter" id="attachment_4482" style="max-width: 674px"><img alt="Example of inputs to the decoder for text summarization" class="size-full wp-image-4482" height="520" sizes="(max-width: 664px) 100vw, 664px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Example-of-inputs-to-the-decoder-for-text-summarization.png" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Example-of-inputs-to-the-decoder-for-text-summarization.png 664w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Example-of-inputs-to-the-decoder-for-text-summarization-300x235.png 300w" width="664"/><p class="wp-caption-text">Example of inputs to the decoder for text summarization.<br/>Taken from “A Neural Attention Model for Abstractive Sentence Summarization”, 2015.</p></div>
<p>Generating words one at a time requires that the model be run until some maximum number of summary words are generated or a special end-of-sequence token is reached.</p>
<p>The process must be started by providing the model with a special start-of-sequence token in order to generate the first word.</p>
<blockquote><p>The decoder takes as input the hidden layers generated after feeding in the last word of the input text. First, an end-of-sequence symbol is fed in as input, again using an embedding layer to transform the symbol into a distributed representation. […]. After generating each word that same word is fed in as input when generating the next word.</p></blockquote>
<p>— <a href="https://arxiv.org/abs/1512.01712">Generating News Headlines with Recurrent Neural Networks</a>, 2015.</p>
<p>Ramesh Nallapati, et al. generate the output sequence using a GRU recurrent neural network.</p>
<blockquote><p>… the decoder consists of a uni-directional GRU-RNN with the same hidden-state size as that of the encoder</p></blockquote>
<h2>Reading Source Text</h2>
<p>There is flexibility in the application of this architecture depending on the specific text summarization problem being addressed.</p>
<p>Most studies focus on one or just a few source sentences in the encoder, but this does not have to be the case.</p>
<p>For example, the encoder could be configured to read and encode the source document in different sized chunks:</p>
<ul>
<li>Sentence.</li>
<li>Paragraph.</li>
<li>Page.</li>
<li>Document.</li>
</ul>
<p>Equally, the decoder can be configured to summarize each chunk or aggregate the encoded chunks and output a broader summary.</p>
<p>Some work has been done along this path, where Alexander Rush, et al. use a hierarchical encoder model with attention at both the word and the sentence level.</p>
<blockquote><p>This model aims to capture this notion of two levels of importance using two bi-directional RNNs on the source side, one at the word level and the other at the sentence level. The attention mechanism operates at both levels simultaneously</p></blockquote>
<p>— <a href="https://arxiv.org/abs/1509.00685">A Neural Attention Model for Abstractive Sentence Summarization</a>, 2015.</p>
<h2>Implementation Models</h2>
<p>In this section, we will look at how to implement the Encoder-Decoder architecture for text summarization in the Keras deep learning library.</p>
<h3>General Model</h3>
<p>A simple realization of the model involves an Encoder with an Embedding input followed by an LSTM hidden layer that produces a fixed-length representation of the source document.</p>
<p>The Decoder reads the representation and an Embedding of the last generated word and uses these inputs to generate each word in the output summary.</p>
<div class="wp-caption aligncenter" id="attachment_4483" style="max-width: 244px"><img alt="General Text Summarization Model in Keras" class="size-full wp-image-4483" height="477" sizes="(max-width: 234px) 100vw, 234px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/General-Text-Summarization-Model-in-Keras.png" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/General-Text-Summarization-Model-in-Keras.png 234w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/General-Text-Summarization-Model-in-Keras-147x300.png 147w" width="234"/><p class="wp-caption-text">General Text Summarization Model in Keras</p></div>
<p>There is a problem.</p>
<p>Keras does not allow recursive loops where the output of the model is fed as input to the model automatically.</p>
<p>This means the model as described above cannot be directly implemented in Keras (but perhaps could in a more flexible platform like TensorFlow).</p>
<p>Instead, we will look at three variations of the model that we can implement in Keras.</p>
<h3>Alternate 1: One-Shot Model</h3>
<p>The first alternative model is to generate the entire output sequence in a one-shot manner.</p>
<p>That is, the decoder uses the context vector alone to generate the output sequence.</p>
<div class="wp-caption aligncenter" id="attachment_4484" style="max-width: 211px"><img alt="Alternate 1 - One-Shot Text Summarization Model" class="size-full wp-image-4484" height="497" sizes="(max-width: 201px) 100vw, 201px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Alternate-1-One-Shot-Text-Summarization-Model.png" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Alternate-1-One-Shot-Text-Summarization-Model.png 201w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Alternate-1-One-Shot-Text-Summarization-Model-121x300.png 121w" width="201"/><p class="wp-caption-text">Alternate 1 – One-Shot Text Summarization Model</p></div>
<p>Here is some sample code for this approach in Keras using the functional API.</p><!-- Crayon Syntax Highlighter v_2.7.2_beta -->
<div class="crayon-syntax crayon-theme-classic crayon-font-monaco crayon-os-mac print-yes notranslate" data-settings=" minimize scroll-mouseover" id="crayon-5a6590f3d8ef4687651924" style=" margin-top: 12px; margin-bottom: 12px; font-size: 12px !important; line-height: 15px !important;">
<div class="crayon-toolbar" data-settings=" mouseover overlay hide delay" style="font-size: 12px !important;height: 18px !important; line-height: 18px !important;"><span class="crayon-title"></span>
<div class="crayon-tools" style="font-size: 12px !important;height: 18px !important; line-height: 18px !important;"><div class="crayon-button crayon-nums-button" title="Toggle Line Numbers"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-plain-button" title="Toggle Plain Code"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-wrap-button" title="Toggle Line Wrap"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-expand-button" title="Expand Code"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-copy-button" title="Copy"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-popup-button" title="Open Code In New Window"><div class="crayon-button-icon"></div></div></div></div>
<div class="crayon-info" style="min-height: 16.8px !important; line-height: 16.8px !important;"></div>
<div class="crayon-plain-wrap"><textarea class="crayon-plain print-no" data-settings="dblclick" readonly="" style="-moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4; font-size: 12px !important; line-height: 15px !important;" wrap="soft">
vocab_size = ...
src_txt_length = ...
sum_txt_length = ...
# encoder input model
inputs = Input(shape=(src_txt_length,))
encoder1 = Embedding(vocab_size, 128)(inputs)
encoder2 = LSTM(128)(encoder1)
encoder3 = RepeatVector(sum_txt_length)(encoder2)
# decoder output model
decoder1 = LSTM(128, return_sequences=True)(encoder3)
outputs = TimeDistributed(Dense(vocab_size, activation='softmax'))(decoder1)
# tie it together
model = Model(inputs=inputs, outputs=outputs)
model.compile(loss='categorical_crossentropy', optimizer='adam')</textarea></div>
<div class="crayon-main" style="">
<table class="crayon-table">
<tr class="crayon-row">
<td class="crayon-nums " data-settings="show">
<div class="crayon-nums-content" style="font-size: 12px !important; line-height: 15px !important;"><div class="crayon-num" data-line="crayon-5a6590f3d8ef4687651924-1">1</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8ef4687651924-2">2</div><div class="crayon-num" data-line="crayon-5a6590f3d8ef4687651924-3">3</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8ef4687651924-4">4</div><div class="crayon-num" data-line="crayon-5a6590f3d8ef4687651924-5">5</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8ef4687651924-6">6</div><div class="crayon-num" data-line="crayon-5a6590f3d8ef4687651924-7">7</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8ef4687651924-8">8</div><div class="crayon-num" data-line="crayon-5a6590f3d8ef4687651924-9">9</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8ef4687651924-10">10</div><div class="crayon-num" data-line="crayon-5a6590f3d8ef4687651924-11">11</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8ef4687651924-12">12</div><div class="crayon-num" data-line="crayon-5a6590f3d8ef4687651924-13">13</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8ef4687651924-14">14</div></div>
</td>
<td class="crayon-code"><div class="crayon-pre" style="font-size: 12px !important; line-height: 15px !important; -moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4;"><div class="crayon-line" id="crayon-5a6590f3d8ef4687651924-1"><span class="crayon-v">vocab_size</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-sy">.</span><span class="crayon-sy">.</span><span class="crayon-sy">.</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8ef4687651924-2"><span class="crayon-v">src_txt_length</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-sy">.</span><span class="crayon-sy">.</span><span class="crayon-sy">.</span></div><div class="crayon-line" id="crayon-5a6590f3d8ef4687651924-3"><span class="crayon-v">sum_txt_length</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-sy">.</span><span class="crayon-sy">.</span><span class="crayon-sy">.</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8ef4687651924-4"><span class="crayon-p"># encoder input model</span></div><div class="crayon-line" id="crayon-5a6590f3d8ef4687651924-5"><span class="crayon-v">inputs</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Input</span><span class="crayon-sy">(</span><span class="crayon-v">shape</span><span class="crayon-o">=</span><span class="crayon-sy">(</span><span class="crayon-v">src_txt_length</span><span class="crayon-sy">,</span><span class="crayon-sy">)</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8ef4687651924-6"><span class="crayon-v">encoder1</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Embedding</span><span class="crayon-sy">(</span><span class="crayon-v">vocab_size</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-cn">128</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">inputs</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a6590f3d8ef4687651924-7"><span class="crayon-v">encoder2</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">LSTM</span><span class="crayon-sy">(</span><span class="crayon-cn">128</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">encoder1</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8ef4687651924-8"><span class="crayon-v">encoder3</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">RepeatVector</span><span class="crayon-sy">(</span><span class="crayon-v">sum_txt_length</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">encoder2</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a6590f3d8ef4687651924-9"><span class="crayon-p"># decoder output model</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8ef4687651924-10"><span class="crayon-v">decoder1</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">LSTM</span><span class="crayon-sy">(</span><span class="crayon-cn">128</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">return_sequences</span><span class="crayon-o">=</span><span class="crayon-t">True</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">encoder3</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a6590f3d8ef4687651924-11"><span class="crayon-v">outputs</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">TimeDistributed</span><span class="crayon-sy">(</span><span class="crayon-e">Dense</span><span class="crayon-sy">(</span><span class="crayon-v">vocab_size</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">activation</span><span class="crayon-o">=</span><span class="crayon-s">'softmax'</span><span class="crayon-sy">)</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">decoder1</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8ef4687651924-12"><span class="crayon-p"># tie it together</span></div><div class="crayon-line" id="crayon-5a6590f3d8ef4687651924-13"><span class="crayon-v">model</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Model</span><span class="crayon-sy">(</span><span class="crayon-v">inputs</span><span class="crayon-o">=</span><span class="crayon-v">inputs</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">outputs</span><span class="crayon-o">=</span><span class="crayon-v">outputs</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8ef4687651924-14"><span class="crayon-v">model</span><span class="crayon-sy">.</span><span class="crayon-e">compile</span><span class="crayon-sy">(</span><span class="crayon-v">loss</span><span class="crayon-o">=</span><span class="crayon-s">'categorical_crossentropy'</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">optimizer</span><span class="crayon-o">=</span><span class="crayon-s">'adam'</span><span class="crayon-sy">)</span></div></div></td>
</tr>
</table>
</div>
</div>
<!-- [Format Time: 0.0022 seconds] -->
<p>This model puts a heavy burden on the decoder.</p>
<p>It is likely that the decoder will not have sufficient context for generating a coherent output sequence as it must choose the words and their order.</p>
<h3>Alternate 2: Recursive Model A</h3>
<p>A second alternative model is to develop a model that generates a single word forecast and call it recursively.</p>
<p>That is, the decoder uses the context vector and the distributed representation of all words generated so far as input in order to generate the next word.</p>
<p>A language model can be used to interpret the sequence of words generated so far to provide a second context vector to combine with the representation of the source document in order to generate the next word in the sequence.</p>
<p>The summary is built up by recursively calling the model with the previously generated word appended (or, more specifically, the expected previous word during training).</p>
<p>The context vectors could be concentrated or added together to provide a broader context for the decoder to interpret and output the next word.</p>
<div class="wp-caption aligncenter" id="attachment_4485" style="max-width: 456px"><img alt="Alternate 2 - Recursive Text Summarization Model A" class="size-full wp-image-4485" height="487" sizes="(max-width: 446px) 100vw, 446px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Alternate-2-Recursive-Text-Summarization-Model-A.png" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Alternate-2-Recursive-Text-Summarization-Model-A.png 446w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Alternate-2-Recursive-Text-Summarization-Model-A-275x300.png 275w" width="446"/><p class="wp-caption-text">Alternate 2 – Recursive Text Summarization Model A</p></div>
<p>Here is some sample code for this approach in Keras using the functional API.</p><!-- Crayon Syntax Highlighter v_2.7.2_beta -->
<div class="crayon-syntax crayon-theme-classic crayon-font-monaco crayon-os-mac print-yes notranslate" data-settings=" minimize scroll-mouseover" id="crayon-5a6590f3d8f03133952599" style=" margin-top: 12px; margin-bottom: 12px; font-size: 12px !important; line-height: 15px !important;">
<div class="crayon-toolbar" data-settings=" mouseover overlay hide delay" style="font-size: 12px !important;height: 18px !important; line-height: 18px !important;"><span class="crayon-title"></span>
<div class="crayon-tools" style="font-size: 12px !important;height: 18px !important; line-height: 18px !important;"><div class="crayon-button crayon-nums-button" title="Toggle Line Numbers"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-plain-button" title="Toggle Plain Code"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-wrap-button" title="Toggle Line Wrap"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-expand-button" title="Expand Code"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-copy-button" title="Copy"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-popup-button" title="Open Code In New Window"><div class="crayon-button-icon"></div></div></div></div>
<div class="crayon-info" style="min-height: 16.8px !important; line-height: 16.8px !important;"></div>
<div class="crayon-plain-wrap"><textarea class="crayon-plain print-no" data-settings="dblclick" readonly="" style="-moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4; font-size: 12px !important; line-height: 15px !important;" wrap="soft">
vocab_size = ...
src_txt_length = ...
sum_txt_length = ...
# source text input model
inputs1 = Input(shape=(src_txt_length,))
am1 = Embedding(vocab_size, 128)(inputs1)
am2 = LSTM(128)(am1)
# summary input model
inputs2 = Input(shape=(sum_txt_length,))
sm1 = = Embedding(vocab_size, 128)(inputs2)
sm2 = LSTM(128)(sm1)
# decoder output model
decoder1 = concatenate([am2, sm2])
outputs = Dense(vocab_size, activation='softmax')(decoder1)
# tie it together [article, summary] [word]
model = Model(inputs=[inputs1, inputs2], outputs=outputs)
model.compile(loss='categorical_crossentropy', optimizer='adam')</textarea></div>
<div class="crayon-main" style="">
<table class="crayon-table">
<tr class="crayon-row">
<td class="crayon-nums " data-settings="show">
<div class="crayon-nums-content" style="font-size: 12px !important; line-height: 15px !important;"><div class="crayon-num" data-line="crayon-5a6590f3d8f03133952599-1">1</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f03133952599-2">2</div><div class="crayon-num" data-line="crayon-5a6590f3d8f03133952599-3">3</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f03133952599-4">4</div><div class="crayon-num" data-line="crayon-5a6590f3d8f03133952599-5">5</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f03133952599-6">6</div><div class="crayon-num" data-line="crayon-5a6590f3d8f03133952599-7">7</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f03133952599-8">8</div><div class="crayon-num" data-line="crayon-5a6590f3d8f03133952599-9">9</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f03133952599-10">10</div><div class="crayon-num" data-line="crayon-5a6590f3d8f03133952599-11">11</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f03133952599-12">12</div><div class="crayon-num" data-line="crayon-5a6590f3d8f03133952599-13">13</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f03133952599-14">14</div><div class="crayon-num" data-line="crayon-5a6590f3d8f03133952599-15">15</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f03133952599-16">16</div><div class="crayon-num" data-line="crayon-5a6590f3d8f03133952599-17">17</div></div>
</td>
<td class="crayon-code"><div class="crayon-pre" style="font-size: 12px !important; line-height: 15px !important; -moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4;"><div class="crayon-line" id="crayon-5a6590f3d8f03133952599-1"><span class="crayon-v">vocab_size</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-sy">.</span><span class="crayon-sy">.</span><span class="crayon-sy">.</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f03133952599-2"><span class="crayon-v">src_txt_length</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-sy">.</span><span class="crayon-sy">.</span><span class="crayon-sy">.</span></div><div class="crayon-line" id="crayon-5a6590f3d8f03133952599-3"><span class="crayon-v">sum_txt_length</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-sy">.</span><span class="crayon-sy">.</span><span class="crayon-sy">.</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f03133952599-4"><span class="crayon-p"># source text input model</span></div><div class="crayon-line" id="crayon-5a6590f3d8f03133952599-5"><span class="crayon-v">inputs1</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Input</span><span class="crayon-sy">(</span><span class="crayon-v">shape</span><span class="crayon-o">=</span><span class="crayon-sy">(</span><span class="crayon-v">src_txt_length</span><span class="crayon-sy">,</span><span class="crayon-sy">)</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f03133952599-6"><span class="crayon-v">am1</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Embedding</span><span class="crayon-sy">(</span><span class="crayon-v">vocab_size</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-cn">128</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">inputs1</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a6590f3d8f03133952599-7"><span class="crayon-v">am2</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">LSTM</span><span class="crayon-sy">(</span><span class="crayon-cn">128</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">am1</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f03133952599-8"><span class="crayon-p"># summary input model</span></div><div class="crayon-line" id="crayon-5a6590f3d8f03133952599-9"><span class="crayon-v">inputs2</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Input</span><span class="crayon-sy">(</span><span class="crayon-v">shape</span><span class="crayon-o">=</span><span class="crayon-sy">(</span><span class="crayon-v">sum_txt_length</span><span class="crayon-sy">,</span><span class="crayon-sy">)</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f03133952599-10"><span class="crayon-v">sm1</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Embedding</span><span class="crayon-sy">(</span><span class="crayon-v">vocab_size</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-cn">128</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">inputs2</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a6590f3d8f03133952599-11"><span class="crayon-v">sm2</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">LSTM</span><span class="crayon-sy">(</span><span class="crayon-cn">128</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">sm1</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f03133952599-12"><span class="crayon-p"># decoder output model</span></div><div class="crayon-line" id="crayon-5a6590f3d8f03133952599-13"><span class="crayon-v">decoder1</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">concatenate</span><span class="crayon-sy">(</span><span class="crayon-sy">[</span><span class="crayon-v">am2</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">sm2</span><span class="crayon-sy">]</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f03133952599-14"><span class="crayon-v">outputs</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Dense</span><span class="crayon-sy">(</span><span class="crayon-v">vocab_size</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">activation</span><span class="crayon-o">=</span><span class="crayon-s">'softmax'</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">decoder1</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a6590f3d8f03133952599-15"><span class="crayon-p"># tie it together [article, summary] [word]</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f03133952599-16"><span class="crayon-v">model</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Model</span><span class="crayon-sy">(</span><span class="crayon-v">inputs</span><span class="crayon-o">=</span><span class="crayon-sy">[</span><span class="crayon-v">inputs1</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">inputs2</span><span class="crayon-sy">]</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">outputs</span><span class="crayon-o">=</span><span class="crayon-v">outputs</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a6590f3d8f03133952599-17"><span class="crayon-v">model</span><span class="crayon-sy">.</span><span class="crayon-e">compile</span><span class="crayon-sy">(</span><span class="crayon-v">loss</span><span class="crayon-o">=</span><span class="crayon-s">'categorical_crossentropy'</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">optimizer</span><span class="crayon-o">=</span><span class="crayon-s">'adam'</span><span class="crayon-sy">)</span></div></div></td>
</tr>
</table>
</div>
</div>
<!-- [Format Time: 0.0017 seconds] -->
<p>This is better as the decoder is given an opportunity to use the previously generated words and the source document as a context for generating the next word.</p>
<p>It does put a burden on the merge operation and decoder to interpret where it is up to in generating the output sequence.</p>
<h3>Alternate 3: Recursive Model B</h3>
<p>In this third alternative, the Encoder generates a context vector representation of the source document.</p>
<p>This document is fed to the decoder at each step of the generated output sequence. This allows the decoder to build up the same internal state as was used to generate the words in the output sequence so that it is primed to generate the next word in the sequence.</p>
<p>This process is then repeated by calling the model again and again for each word in the output sequence until a maximum length or end-of-sequence token is generated.</p>
<div class="wp-caption aligncenter" id="attachment_4486" style="max-width: 467px"><img alt="Alternate 3 - Recursive Text Summarization Model B" class="size-full wp-image-4486" height="445" sizes="(max-width: 457px) 100vw, 457px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Alternate-3-Recursive-Text-Summarization-Model-B.png" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Alternate-3-Recursive-Text-Summarization-Model-B.png 457w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/09/Alternate-3-Recursive-Text-Summarization-Model-B-300x292.png 300w" width="457"/><p class="wp-caption-text">Alternate 3 – Recursive Text Summarization Model B</p></div>
<p>Here is some sample code for this approach in Keras using the functional API.</p><!-- Crayon Syntax Highlighter v_2.7.2_beta -->
<div class="crayon-syntax crayon-theme-classic crayon-font-monaco crayon-os-mac print-yes notranslate" data-settings=" minimize scroll-mouseover" id="crayon-5a6590f3d8f07216797185" style=" margin-top: 12px; margin-bottom: 12px; font-size: 12px !important; line-height: 15px !important;">
<div class="crayon-toolbar" data-settings=" mouseover overlay hide delay" style="font-size: 12px !important;height: 18px !important; line-height: 18px !important;"><span class="crayon-title"></span>
<div class="crayon-tools" style="font-size: 12px !important;height: 18px !important; line-height: 18px !important;"><div class="crayon-button crayon-nums-button" title="Toggle Line Numbers"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-plain-button" title="Toggle Plain Code"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-wrap-button" title="Toggle Line Wrap"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-expand-button" title="Expand Code"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-copy-button" title="Copy"><div class="crayon-button-icon"></div></div><div class="crayon-button crayon-popup-button" title="Open Code In New Window"><div class="crayon-button-icon"></div></div></div></div>
<div class="crayon-info" style="min-height: 16.8px !important; line-height: 16.8px !important;"></div>
<div class="crayon-plain-wrap"><textarea class="crayon-plain print-no" data-settings="dblclick" readonly="" style="-moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4; font-size: 12px !important; line-height: 15px !important;" wrap="soft">
vocab_size = ...
src_txt_length = ...
sum_txt_length = ...
# article input model
inputs1 = Input(shape=(src_txt_length,))
article1 = Embedding(vocab_size, 128)(inputs1)
article2 = LSTM(128)(article1)
article3 = RepeatVector(sum_txt_length)(article2)
# summary input model
inputs2 = Input(shape=(sum_txt_length,))
summ1 = Embedding(vocab_size, 128)(inputs2)
# decoder model
decoder1 = concatenate([article3, summ1])
decoder2 = LSTM(128)(decoder1)
outputs = Dense(vocab_size, activation='softmax')(decoder2)
# tie it together [article, summary] [word]
model = Model(inputs=[inputs1, inputs2], outputs=outputs)
model.compile(loss='categorical_crossentropy', optimizer='adam')</textarea></div>
<div class="crayon-main" style="">
<table class="crayon-table">
<tr class="crayon-row">
<td class="crayon-nums " data-settings="show">
<div class="crayon-nums-content" style="font-size: 12px !important; line-height: 15px !important;"><div class="crayon-num" data-line="crayon-5a6590f3d8f07216797185-1">1</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f07216797185-2">2</div><div class="crayon-num" data-line="crayon-5a6590f3d8f07216797185-3">3</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f07216797185-4">4</div><div class="crayon-num" data-line="crayon-5a6590f3d8f07216797185-5">5</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f07216797185-6">6</div><div class="crayon-num" data-line="crayon-5a6590f3d8f07216797185-7">7</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f07216797185-8">8</div><div class="crayon-num" data-line="crayon-5a6590f3d8f07216797185-9">9</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f07216797185-10">10</div><div class="crayon-num" data-line="crayon-5a6590f3d8f07216797185-11">11</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f07216797185-12">12</div><div class="crayon-num" data-line="crayon-5a6590f3d8f07216797185-13">13</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f07216797185-14">14</div><div class="crayon-num" data-line="crayon-5a6590f3d8f07216797185-15">15</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f07216797185-16">16</div><div class="crayon-num" data-line="crayon-5a6590f3d8f07216797185-17">17</div><div class="crayon-num crayon-striped-num" data-line="crayon-5a6590f3d8f07216797185-18">18</div></div>
</td>
<td class="crayon-code"><div class="crayon-pre" style="font-size: 12px !important; line-height: 15px !important; -moz-tab-size:4; -o-tab-size:4; -webkit-tab-size:4; tab-size:4;"><div class="crayon-line" id="crayon-5a6590f3d8f07216797185-1"><span class="crayon-v">vocab_size</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-sy">.</span><span class="crayon-sy">.</span><span class="crayon-sy">.</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f07216797185-2"><span class="crayon-v">src_txt_length</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-sy">.</span><span class="crayon-sy">.</span><span class="crayon-sy">.</span></div><div class="crayon-line" id="crayon-5a6590f3d8f07216797185-3"><span class="crayon-v">sum_txt_length</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-sy">.</span><span class="crayon-sy">.</span><span class="crayon-sy">.</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f07216797185-4"><span class="crayon-p"># article input model</span></div><div class="crayon-line" id="crayon-5a6590f3d8f07216797185-5"><span class="crayon-v">inputs1</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Input</span><span class="crayon-sy">(</span><span class="crayon-v">shape</span><span class="crayon-o">=</span><span class="crayon-sy">(</span><span class="crayon-v">src_txt_length</span><span class="crayon-sy">,</span><span class="crayon-sy">)</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f07216797185-6"><span class="crayon-v">article1</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Embedding</span><span class="crayon-sy">(</span><span class="crayon-v">vocab_size</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-cn">128</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">inputs1</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a6590f3d8f07216797185-7"><span class="crayon-v">article2</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">LSTM</span><span class="crayon-sy">(</span><span class="crayon-cn">128</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">article1</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f07216797185-8"><span class="crayon-v">article3</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">RepeatVector</span><span class="crayon-sy">(</span><span class="crayon-v">sum_txt_length</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">article2</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a6590f3d8f07216797185-9"><span class="crayon-p"># summary input model</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f07216797185-10"><span class="crayon-v">inputs2</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Input</span><span class="crayon-sy">(</span><span class="crayon-v">shape</span><span class="crayon-o">=</span><span class="crayon-sy">(</span><span class="crayon-v">sum_txt_length</span><span class="crayon-sy">,</span><span class="crayon-sy">)</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a6590f3d8f07216797185-11"><span class="crayon-v">summ1</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Embedding</span><span class="crayon-sy">(</span><span class="crayon-v">vocab_size</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-cn">128</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">inputs2</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f07216797185-12"><span class="crayon-p"># decoder model</span></div><div class="crayon-line" id="crayon-5a6590f3d8f07216797185-13"><span class="crayon-v">decoder1</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">concatenate</span><span class="crayon-sy">(</span><span class="crayon-sy">[</span><span class="crayon-v">article3</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">summ1</span><span class="crayon-sy">]</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f07216797185-14"><span class="crayon-v">decoder2</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">LSTM</span><span class="crayon-sy">(</span><span class="crayon-cn">128</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">decoder1</span><span class="crayon-sy">)</span></div><div class="crayon-line" id="crayon-5a6590f3d8f07216797185-15"><span class="crayon-v">outputs</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Dense</span><span class="crayon-sy">(</span><span class="crayon-v">vocab_size</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">activation</span><span class="crayon-o">=</span><span class="crayon-s">'softmax'</span><span class="crayon-sy">)</span><span class="crayon-sy">(</span><span class="crayon-v">decoder2</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f07216797185-16"><span class="crayon-p"># tie it together [article, summary] [word]</span></div><div class="crayon-line" id="crayon-5a6590f3d8f07216797185-17"><span class="crayon-v">model</span><span class="crayon-h"> </span><span class="crayon-o">=</span><span class="crayon-h"> </span><span class="crayon-e">Model</span><span class="crayon-sy">(</span><span class="crayon-v">inputs</span><span class="crayon-o">=</span><span class="crayon-sy">[</span><span class="crayon-v">inputs1</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">inputs2</span><span class="crayon-sy">]</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">outputs</span><span class="crayon-o">=</span><span class="crayon-v">outputs</span><span class="crayon-sy">)</span></div><div class="crayon-line crayon-striped-line" id="crayon-5a6590f3d8f07216797185-18"><span class="crayon-v">model</span><span class="crayon-sy">.</span><span class="crayon-e">compile</span><span class="crayon-sy">(</span><span class="crayon-v">loss</span><span class="crayon-o">=</span><span class="crayon-s">'categorical_crossentropy'</span><span class="crayon-sy">,</span><span class="crayon-h"> </span><span class="crayon-v">optimizer</span><span class="crayon-o">=</span><span class="crayon-s">'adam'</span><span class="crayon-sy">)</span></div></div></td>
</tr>
</table>
</div>
</div>
<!-- [Format Time: 0.0016 seconds] -->
<p>Do you have any other alternate implementation ideas?<br/>
Let me know in the comments below.</p>
<h2>Further Reading</h2>
<p>This section provides more resources on the topic if you are looking go deeper.</p>
<h3>Papers</h3>
<ul>
<li><a href="https://arxiv.org/abs/1509.00685">A Neural Attention Model for Abstractive Sentence Summarization</a>, 2015.</li>
<li><a href="https://arxiv.org/abs/1512.01712">Generating News Headlines with Recurrent Neural Networks</a>, 2015.</li>
<li><a href="https://arxiv.org/abs/1602.06023">Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond</a>, 2016.</li>
<li><a href="https://arxiv.org/abs/1704.04368">Get To The Point: Summarization with Pointer-Generator Networks</a>, 2017.</li>
</ul>
<h3>Related</h3>
<ul>
<li><a href="https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/">Encoder-Decoder Long Short-Term Memory Networks</a></li>
<li><a href="https://machinelearningmastery.com/attention-long-short-term-memory-recurrent-neural-networks/">Attention in Long Short-Term Memory Recurrent Neural Networks</a></li>
</ul>
<h2>Summary</h2>
<p>In this tutorial, you discovered how to implement the Encoder-Decoder architecture for text summarization in the Keras deep learning library.</p>
<p>Specifically, you learned:</p>
<ul>
<li>How text summarization can be addressed using the Encoder-Decoder recurrent neural network architecture.</li>
<li>How different encoders and decoders can be implemented for the problem.</li>
<li>Three models that you can use to implement the architecture for text summarization in Keras.</li>
</ul>
<p>Do you have any questions?<br/>
Ask your questions in the comments below and I will do my best to answer.</p>
<div class="awac-wrapper"><div class="awac widget text-42"> <div class="textwidget"><p></p><center><br/>
<div class="woo-sc-hr"></div>
<h2>Develop Deep Learning models for Text Data Today!</h2>
<p><a href="/deep-learning-for-nlp/"><img align="left" alt="Deep Learning for Natural Language Processing" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/DLFNLP-Cover-220.png" style="border: 0;"/></a></p>
<h4>Develop Your Own Text models in Minutes</h4>
<p>…with just a few lines of python code</p>
<p>Discover how in my new Ebook:<br/>
<a href="/deep-learning-for-nlp/">Deep Learning for Natural Language Processing</a></p>
<p>It provides <strong>self-study tutorials</strong> on topics like:<br/>
<em>Bag-of-Words, Word Embedding, Language Models, Caption Generation, Text Translation</em> and much more…</p>
<h4>Finally Bring Deep Learning to your Natural Language Processing Projects</h4>
<p>Skip the Academics. Just Results.</p>
<p><a href="/deep-learning-for-nlp/">Click to learn more</a>.<br/>
</p><div class="woo-sc-hr"></div><br/>
</center>
</div>
</div></div><div class="apss-social-share apss-theme-4 clearfix">
<div class="apss-twitter apss-single-icon">
<a href="javascript:void(0);" onclick="apss_open_in_popup_window(event, 'https://twitter.com/intent/tweet?text=Encoder-Decoder%20Models%20for%20Text%20Summarization%20in%20Keras&amp;url=https%3A%2F%2Fmachinelearningmastery.com%2Fencoder-decoder-models-text-summarization-keras%2F&amp;');" rel="nofollow" target="" title="Share on Twitter">
<div class="apss-icon-block clearfix">
<i class="fa fa-twitter"></i>
<span class="apss-social-text">Share on Twitter</span><span class="apss-share">Tweet</span>
</div>
</a>
</div>
<div class="apss-facebook apss-single-icon">
<a href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/" onclick="apss_open_in_popup_window(event, 'https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/');" rel="nofollow" target="" title="Share on Facebook">
<div class="apss-icon-block clearfix">
<i class="fa fa-facebook"></i>
<span class="apss-social-text">Share on Facebook</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-linkedin apss-single-icon">
<a href="http://www.linkedin.com/shareArticle?mini=true&amp;title=Encoder-Decoder%20Models%20for%20Text%20Summarization%20in%20Keras&amp;url=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/&amp;summary=Text+summarization+is+a+problem+in+natural+language+processing+of+creating+a+short%2C+accurate%2C+and+fl..." onclick="apss_open_in_popup_window(event, 'http://www.linkedin.com/shareArticle?mini=true&amp;title=Encoder-Decoder%20Models%20for%20Text%20Summarization%20in%20Keras&amp;url=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/&amp;summary=Text+summarization+is+a+problem+in+natural+language+processing+of+creating+a+short%2C+accurate%2C+and+fl...');" rel="nofollow" target="" title="Share on LinkedIn">
<div class="apss-icon-block clearfix"><i class="fa fa-linkedin"></i>
<span class="apss-social-text">Share on LinkedIn</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-google-plus apss-single-icon">
<a href="https://plus.google.com/share?url=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/" onclick="apss_open_in_popup_window(event, 'https://plus.google.com/share?url=https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/');" rel="nofollow" target="" title="Share on Google Plus">
<div class="apss-icon-block clearfix">
<i class="fa fa-google-plus"></i>
<span class="apss-social-text">Share on Google Plus</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
</div> </section><!-- /.entry -->
<div class="fix"></div>
<aside id="post-author">
<div class="profile-image"><img alt="" class="avatar avatar-80 photo" height="80" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=160&amp;d=mm&amp;r=g 2x" width="80"/></div>
<div class="profile-content">
<h4>About Jason Brownlee</h4>
		Dr. Jason Brownlee is a husband, proud father, academic researcher, author, professional developer and a machine learning practitioner. He is dedicated to helping developers get started and get good at applied machine learning.
<a href="/about">Learn more</a>.				<div class="profile-link">
<a href="https://machinelearningmastery.com/author/jasonb/">
				View all posts by Jason Brownlee <span class="meta-nav">→</span> </a>
</div><!--#profile-link-->
</div>
<div class="fix"></div>
</aside>
<div class="post-utility"></div>
</article><!-- /.post -->
<div class="post-entries">
<div class="nav-prev fl"><a href="https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/" rel="prev"><i class="fa fa-angle-left"></i> What is Teacher Forcing for Recurrent Neural Networks?</a></div>
<div class="nav-next fr"><a href="https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/" rel="next">Difference Between Classification and Regression in Machine Learning <i class="fa fa-angle-right"></i></a></div>
<div class="fix"></div>
</div>
<div id="comments"> <h3 id="comments-title">17 Responses to <em>Encoder-Decoder Models for Text Summarization in Keras</em></h3>
<ol class="commentlist">
<li class="comment even thread-even depth-1" id="comment-422595">
<div class="comment-container" id="li-comment-422595">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/82a6da393d6dce1a2a3b3f7939cf13da?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/82a6da393d6dce1a2a3b3f7939cf13da?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Oswaldo Ludwig</span>
<span class="date">December 9, 2017 at 3:53 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-422595" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Regarding the Recursive Model A, here is a similar approach proposed 5 months ago (with shared embedding): <a href="https://github.com/oswaldoludwig/Seq2seq-Chatbot-for-Keras" rel="nofollow">https://github.com/oswaldoludwig/Seq2seq-Chatbot-for-Keras</a></p>
<p>The advantage of this model can be seen in Section 3.1 of this paper: <a href="https://www.researchgate.net/publication/321347271_End-to-end_Adversarial_Learning_for_Generative_Conversational_Agents" rel="nofollow">https://www.researchgate.net/publication/321347271_End-to-end_Adversarial_Learning_for_Generative_Conversational_Agents</a></p>
<div class="reply">
<a aria-label="Reply to Oswaldo Ludwig" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=422595#respond" onclick='return addComment.moveForm( "comment-422595", "422595", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-422625">
<div class="comment-container" id="li-comment-422625">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">December 10, 2017 at 5:17 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-422625" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Thanks for the links.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=422625#respond" onclick='return addComment.moveForm( "comment-422625", "422625", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment even depth-3" id="comment-422634">
<div class="comment-container" id="li-comment-422634">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/82a6da393d6dce1a2a3b3f7939cf13da?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/82a6da393d6dce1a2a3b3f7939cf13da?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Oswaldo Ludwig</span>
<span class="date">December 10, 2017 at 5:37 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-422634" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>You’re welcome!</p>
<div class="reply">
<a aria-label="Reply to Oswaldo Ludwig" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=422634#respond" onclick='return addComment.moveForm( "comment-422634", "422634", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-422598">
<div class="comment-container" id="li-comment-422598">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/82a6da393d6dce1a2a3b3f7939cf13da?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/82a6da393d6dce1a2a3b3f7939cf13da?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Oswaldo Ludwig</span>
<span class="date">December 9, 2017 at 4:31 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-422598" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>For the Recursive Model A you can kindly cite the Zenodo document: <a href="https://zenodo.org/record/825303#.Wit0jc_TXqA" rel="nofollow">https://zenodo.org/record/825303#.Wit0jc_TXqA</a></p>
<p>or the ArXiv paper: <a href="https://arxiv.org/abs/1711.10122" rel="nofollow">https://arxiv.org/abs/1711.10122</a></p>
<p>Thanks in advance,</p>
<p>Oswaldo Ludwig</p>
<div class="reply">
<a aria-label="Reply to Oswaldo Ludwig" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=422598#respond" onclick='return addComment.moveForm( "comment-422598", "422598", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-422626">
<div class="comment-container" id="li-comment-422626">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">December 10, 2017 at 5:18 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-422626" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Nice!</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=422626#respond" onclick='return addComment.moveForm( "comment-422626", "422626", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-even depth-1" id="comment-422686">
<div class="comment-container" id="li-comment-422686">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/7fc04f718ccda8281da64705dc552388?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/7fc04f718ccda8281da64705dc552388?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">viky</span>
<span class="date">December 10, 2017 at 10:22 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-422686" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Sir, could you explain it with an example.??</p>
<div class="reply">
<a aria-label="Reply to viky" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=422686#respond" onclick='return addComment.moveForm( "comment-422686", "422686", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-422713">
<div class="comment-container" id="li-comment-422713">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">December 11, 2017 at 5:26 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-422713" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Explain what?</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=422713#respond" onclick='return addComment.moveForm( "comment-422713", "422713", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-423813">
<div class="comment-container" id="li-comment-423813">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/4aefa6173df962ad926e8f5397784003?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/4aefa6173df962ad926e8f5397784003?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">RJPG</span>
<span class="date">December 19, 2017 at 6:11 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-423813" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>It would be nice if you provide some example of using autoencoders in simple classification problems. Using encoders/decoders pretrain (with inputs = outputs “unsupervised pretrain”) to have a high abstraction level of information in the middle  then split in half this network and use the encoder to feed a dense NN with softmax (for ex) and execute supervised “post train”. Do you think it is possible with keras ?</p>
<div class="reply">
<a aria-label="Reply to RJPG" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=423813#respond" onclick='return addComment.moveForm( "comment-423813", "423813", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-423922">
<div class="comment-container" id="li-comment-423922">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">December 19, 2017 at 3:55 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-423922" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Thanks for the suggestion.</p>
<p>Generally, deep MLPs outperform autoencoders for classification tasks.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=423922#respond" onclick='return addComment.moveForm( "comment-423922", "423922", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-even depth-1" id="comment-423814">
<div class="comment-container" id="li-comment-423814">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/4aefa6173df962ad926e8f5397784003?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/4aefa6173df962ad926e8f5397784003?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">RJPG</span>
<span class="date">December 19, 2017 at 6:15 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-423814" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>something like this in keras would be super : <a href="https://www.mathworks.com/help/nnet/examples/training-a-deep-neural-network-for-digit-classification.html" rel="nofollow">https://www.mathworks.com/help/nnet/examples/training-a-deep-neural-network-for-digit-classification.html</a></p>
<div class="reply">
<a aria-label="Reply to RJPG" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=423814#respond" onclick='return addComment.moveForm( "comment-423814", "423814", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-423923">
<div class="comment-container" id="li-comment-423923">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">December 19, 2017 at 3:56 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-423923" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Here’s an example of a CNN on that problem:<br/>
<a href="http://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/" rel="nofollow">http://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/</a></p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=423923#respond" onclick='return addComment.moveForm( "comment-423923", "423923", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-423964">
<div class="comment-container" id="li-comment-423964">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/103b1e20e43ed1b4c79c727ae03b582e?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/103b1e20e43ed1b4c79c727ae03b582e?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Anita</span>
<span class="date">December 19, 2017 at 7:58 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-423964" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Please provide the code links for Encoder-Decoder Models for Text Summarization in Keras</p>
<div class="reply">
<a aria-label="Reply to Anita" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=423964#respond" onclick='return addComment.moveForm( "comment-423964", "423964", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-424047">
<div class="comment-container" id="li-comment-424047">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">December 20, 2017 at 5:42 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-424047" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Thanks for the suggestion.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=424047#respond" onclick='return addComment.moveForm( "comment-424047", "424047", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-even depth-1" id="comment-425701">
<div class="comment-container" id="li-comment-425701">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1a0553a6e8a69766f19b9ca2e1f9e655?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1a0553a6e8a69766f19b9ca2e1f9e655?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Andy K</span>
<span class="date">January 5, 2018 at 12:23 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-425701" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>How well does this work for the following cases?</p>
<p>1) Messy data. e.g. Say I want a summary of a chat conversation I missed.<br/>
2) Long content. Can it summarize a book?</p>
<p>Is this actually used in industry or just academic?</p>
<div class="reply">
<a aria-label="Reply to Andy K" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=425701#respond" onclick='return addComment.moveForm( "comment-425701", "425701", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-425745">
<div class="comment-container" id="li-comment-425745">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">January 6, 2018 at 5:51 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-425745" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Great question, but too hard to answer. I’d recommend either diving into some papers to see examples or run some experiments on your data.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=425745#respond" onclick='return addComment.moveForm( "comment-425745", "425745", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-426861">
<div class="comment-container" id="li-comment-426861">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/516ef6e02fba586569ab4b2b1b62bf5f?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/516ef6e02fba586569ab4b2b1b62bf5f?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Daniel</span>
<span class="date">January 19, 2018 at 2:31 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-426861" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Hi Jason,</p>
<p>thank you for the article.</p>
<p>I tried combining the first approach with the dataset from your article about preparation of news articles for text summarization (<a href="https://machinelearningmastery.com/prepare-news-articles-text-summarization/" rel="nofollow">https://machinelearningmastery.com/prepare-news-articles-text-summarization/</a>). </p>
<p>Unfortunately, I cannot get the Encoder-Decoder architecture to work, maybe you can provide some help.</p>
<p>After the code from the preparation article I added the following code:</p>
<p><code></code><code><br/>
X, y = [' '.join(t['story']) for t in stories], [' '.join(t['highlights']) for t in stories]</code></p>
<p>from keras.preprocessing.text import Tokenizer<br/>
from keras.preprocessing.sequence import pad_sequences</p>
<p>MAX_SEQUENCE_LENGTH = 1000</p>
<p>tokenizer = Tokenizer()<br/>
total = X + y<br/>
tokenizer.fit_on_texts(total)<br/>
sequences_X = tokenizer.texts_to_sequences(X)<br/>
sequences_y = tokenizer.texts_to_sequences(y)</p>
<p>word_index = tokenizer.word_index</p>
<p>data = pad_sequences(sequences_X, maxlen=MAX_SEQUENCE_LENGTH)<br/>
labels = pad_sequences(sequences_y, maxlen=100) # test with maxlen=100</p>
<p># train/test split</p>
<p>TEST_SIZE = 5<br/>
X_train, y_train, X_test, y_test = data[:-TEST_SIZE], labels[:-TEST_SIZE], data[-TEST_SIZE:], labels[-TEST_SIZE:]</p>
<p># create model</p>
<p># encoder input model<br/>
inputs = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')</p>
<p>encoder1 = Embedding(len(word_index) + 1, 128, input_length=MAX_SEQUENCE_LENGTH)(inputs)<br/>
encoder2 = LSTM(128)(encoder1)<br/>
encoder3 = RepeatVector(2)(encoder2)</p>
<p># decoder output model<br/>
decoder1 = LSTM(128, return_sequences=True)(encoder3)<br/>
outputs = TimeDistributed(Dense(len(word_index) + 1, activation='softmax'))(decoder1)</p>
<p>model = Model(inputs=inputs, outputs=outputs)<br/>
model.compile(loss='categorical_crossentropy', optimizer='adam')</p>
<p>batch_size = 32<br/>
epochs = 4</p>
<p>model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=1)</p>
<p><code></code></p>
<p>The error I get is: Error when checking target: expected time_distributed_2 to have 3 dimensions, but got array with shape (3000, 100)</p>
<p>Thank you in advance.</p>
<div class="reply">
<a aria-label="Reply to Daniel" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=426861#respond" onclick='return addComment.moveForm( "comment-426861", "426861", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor even depth-2" id="comment-426890">
<div class="comment-container" id="li-comment-426890">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">January 19, 2018 at 6:35 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/#comment-426890" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Sorry, I cannot debug your code for you.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/?replytocom=426890#respond" onclick='return addComment.moveForm( "comment-426890", "426890", "respond", "4481" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ol>
</div> <div class="comment-respond" id="respond">
<h3 class="comment-reply-title" id="reply-title">Leave a Reply <small><a href="/encoder-decoder-models-text-summarization-keras/#respond" id="cancel-comment-reply-link" rel="nofollow" style="display:none;">Click here to cancel reply.</a></small></h3> <form action="https://machinelearningmastery.com/wp-comments-post.php?wpe-comment-post=mlmastery" class="comment-form" id="commentform" method="post">
<p class="comment-form-comment"><label class="hide" for="comment">Comment</label> <textarea aria-required="true" cols="50" id="comment" maxlength="65525" name="comment" required="required" rows="10" tabindex="4"></textarea></p><p class="comment-form-author"><input aria-required="true" class="txt" id="author" name="author" size="30" tabindex="1" type="text" value=""/><label for="author">Name <span class="required">(required)</span></label> </p>
<p class="comment-form-email"><input aria-required="true" class="txt" id="email" name="email" size="30" tabindex="2" type="text" value=""/><label for="email">Email (will not be published) <span class="required">(required)</span></label> </p>
<p class="comment-form-url"><input class="txt" id="url" name="url" size="30" tabindex="3" type="text" value=""/><label for="url">Website</label></p>
<p class="form-submit"><input class="submit" id="submit" name="submit" type="submit" value="Submit Comment"/> <input id="comment_post_ID" name="comment_post_ID" type="hidden" value="4481"/>
<input id="comment_parent" name="comment_parent" type="hidden" value="0"/>
</p><p style="display: none;"><input id="akismet_comment_nonce" name="akismet_comment_nonce" type="hidden" value="801f91fc35"/></p><p style="display: none;"><input id="ak_js" name="ak_js" type="hidden" value="148"/></p> </form>
</div><!-- #respond -->
</section><!-- /#main -->
<aside id="sidebar">
<div class="widget widget_woo_blogauthorinfo" id="woo_blogauthorinfo-2"><h3>Welcome to Machine Learning Mastery</h3><span class="left"><img alt="" class="avatar avatar-100 photo" height="100" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=100&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=200&amp;d=mm&amp;r=g 2x" width="100"/></span>
<p>Hi, I'm Dr. Jason Brownlee.
<br/>
My goal is to make practitioners like YOU awesome at applied machine learning.</p>
<p><a href="/about">Read More</a></p>
<div class="fix"></div>
</div><div class="widget widget_text" id="text-43"> <div class="textwidget"><p></p><center>
<h3>Deep Learning for Text Data</h3>
<p>Cut through the math and research papers.<br/>
Discover Word Embeddings, Text Translation and more.</p>
<p><a href="/deep-learning-for-nlp/">Get Started With Deep Learning for NLP Today!</a><br/>
<a href="/deep-learning-for-nlp/"><img src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/DLFNLP-Cover-220.png"/></a><br/>
</p></center>
</div>
</div>
<div class="widget widget_woo_tabs" id="woo_tabs-2"> <div id="tabs">
<ul class="wooTabs">
<li class="popular"><a href="#tab-pop">Popular</a></li> </ul>
<div class="clear"></div>
<div class="boxes box inside">
<ul class="list" id="tab-pop">
<li>
<a href="https://machinelearningmastery.com/machine-learning-in-python-step-by-step/" title="Your First Machine Learning Project in Python Step-By-Step"><img alt="Your First Machine Learning Project in Python Step-By-Step" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/Your-First-Machine-Learning-Project-in-Python-Step-By-Step-150x150.jpg" title="Your First Machine Learning Project in Python Step-By-Step" width="45"/></a> <a href="https://machinelearningmastery.com/machine-learning-in-python-step-by-step/" title="Your First Machine Learning Project in Python Step-By-Step">Your First Machine Learning Project in Python Step-By-Step</a>
<span class="meta">June 10, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/" title="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras"><img alt="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/07/Time-Series-Prediction-with-LSTM-Recurrent-Neural-Networks-in-Python-with-Keras-150x150.jpg" title="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras" width="45"/></a> <a href="https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/" title="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras">Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras</a>
<span class="meta">July 21, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/" title="Multivariate Time Series Forecasting with LSTMs in Keras"><img alt="Line Plots of Air Pollution Time Series" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/06/Line-Plots-of-Air-Pollution-Time-Series-150x150.png" title="Multivariate Time Series Forecasting with LSTMs in Keras" width="45"/></a> <a href="https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/" title="Multivariate Time Series Forecasting with LSTMs in Keras">Multivariate Time Series Forecasting with LSTMs in Keras</a>
<span class="meta">August 14, 2017</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/" title="Develop Your First Neural Network in Python With Keras Step-By-Step"><img alt="Tour of Deep Learning Algorithms" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/04/Tour-of-Deep-Learning-Algorithms-150x150.jpg" title="Develop Your First Neural Network in Python With Keras Step-By-Step" width="45"/></a> <a href="https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/" title="Develop Your First Neural Network in Python With Keras Step-By-Step">Develop Your First Neural Network in Python With Keras Step-By-Step</a>
<span class="meta">May 24, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/setup-python-environment-machine-learning-deep-learning-anaconda/" title="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda"><img alt="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/03/How-to-Setup-a-Python-Environment-for-Machine-Learning-and-Deep-Learning-with-Anaconda-150x150.png" title="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda" width="45"/></a> <a href="https://machinelearningmastery.com/setup-python-environment-machine-learning-deep-learning-anaconda/" title="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda">How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda</a>
<span class="meta">March 13, 2017</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/" title="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras"><img alt="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/07/Sequence-Classification-with-LSTM-Recurrent-Neural-Networks-in-Python-with-Keras-150x150.jpg" title="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras" width="45"/></a> <a href="https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/" title="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras">Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras</a>
<span class="meta">July 26, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/" title="Time Series Forecasting with the Long Short-Term Memory Network in Python"><img alt="Time Series Forecasting with the Long Short-Term Memory Network in Python" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/04/Time-Series-Forecasting-with-the-Long-Short-Term-Memory-Network-in-Python-150x150.jpg" title="Time Series Forecasting with the Long Short-Term Memory Network in Python" width="45"/></a> <a href="https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/" title="Time Series Forecasting with the Long Short-Term Memory Network in Python">Time Series Forecasting with the Long Short-Term Memory Network in Python</a>
<span class="meta">April 7, 2017</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/" title="Multi-Class Classification Tutorial with the Keras Deep Learning Library"><img alt="Multi-Class Classification Tutorial with the Keras Deep Learning Library" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/Multi-Class-Classification-Tutorial-with-the-Keras-Deep-Learning-Library-150x150.jpg" title="Multi-Class Classification Tutorial with the Keras Deep Learning Library" width="45"/></a> <a href="https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/" title="Multi-Class Classification Tutorial with the Keras Deep Learning Library">Multi-Class Classification Tutorial with the Keras Deep Learning Library</a>
<span class="meta">June 2, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/" title="Regression Tutorial with the Keras Deep Learning Library in Python"><img alt="Regression Tutorial with Keras Deep Learning Library in Python" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/Regression-Tutorial-with-Keras-Deep-Learning-Library-in-Python-150x150.jpg" title="Regression Tutorial with the Keras Deep Learning Library in Python" width="45"/></a> <a href="https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/" title="Regression Tutorial with the Keras Deep Learning Library in Python">Regression Tutorial with the Keras Deep Learning Library in Python</a>
<span class="meta">June 9, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/" title="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras"><img alt="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/08/How-to-Grid-Search-Hyperparameters-for-Deep-Learning-Models-in-Python-With-Keras-150x150.jpg" title="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras" width="45"/></a> <a href="https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/" title="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras">How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras</a>
<span class="meta">August 9, 2016</span>
<div class="fix"></div>
</li>
</ul>
</div><!-- /.boxes -->
</div><!-- /wooTabs -->
</div> </aside><!-- /#sidebar -->
</div><!-- /#main-sidebar-container -->
</div><!-- /#content -->
<footer class="col-full" id="footer">
<div class="col-left" id="copyright">
<p>© 2018 Machine Learning Mastery. All Rights Reserved. </p> </div>
<div class="col-right" id="credit">
<p></p><p>
<a href="/privacy/">Privacy</a> | 
<a href="/contact/">Contact</a> |
<a href="/about/">About</a>
</p> </div>
</footer>
</div><!-- /#inner-wrapper -->
</div><!-- /#wrapper -->
<div class="fix"></div><!--/.fix-->
<!-- Drip -->
<script type="text/javascript">
  var _dcq = _dcq || [];
  var _dcs = _dcs || {}; 
  _dcs.account = '9556588';
  
  (function() {
    var dc = document.createElement('script');
    dc.type = 'text/javascript'; dc.async = true; 
    dc.src = '//tag.getdrip.com/9556588.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(dc, s);
  })();
</script><!-- Woo Tabs Widget -->
<script type="text/javascript">
jQuery(document).ready(function(){
	// UL = .wooTabs
	// Tab contents = .inside

	var tag_cloud_class = '#tagcloud';

	//Fix for tag clouds - unexpected height before .hide()
	var tag_cloud_height = jQuery( '#tagcloud').height();

	jQuery( '.inside ul li:last-child').css( 'border-bottom','0px' ); // remove last border-bottom from list in tab content
	jQuery( '.wooTabs').each(function(){
		jQuery(this).children( 'li').children( 'a:first').addClass( 'selected' ); // Add .selected class to first tab on load
	});
	jQuery( '.inside > *').hide();
	jQuery( '.inside > *:first-child').show();

	jQuery( '.wooTabs li a').click(function(evt){ // Init Click funtion on Tabs

		var clicked_tab_ref = jQuery(this).attr( 'href' ); // Strore Href value

		jQuery(this).parent().parent().children( 'li').children( 'a').removeClass( 'selected' ); //Remove selected from all tabs
		jQuery(this).addClass( 'selected' );
		jQuery(this).parent().parent().parent().children( '.inside').children( '*').hide();

		jQuery( '.inside ' + clicked_tab_ref).fadeIn(500);

		 evt.preventDefault();

	})
})
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/comment-reply.min.js?ver=4.9.2" type="text/javascript"></script>
<script type="text/javascript">
/* <![CDATA[ */
var wpcf7 = {"apiSettings":{"root":"https:\/\/machinelearningmastery.com\/wp-json\/contact-form-7\/v1","namespace":"contact-form-7\/v1"},"recaptcha":{"messages":{"empty":"Please verify that you are not a robot."}},"cached":"1"};
/* ]]> */
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/contact-form-7/includes/js/scripts.js?ver=4.9.2" type="text/javascript"></script>
<script type="text/javascript">
/* <![CDATA[ */
var frontend_ajax_object = {"ajax_url":"https:\/\/machinelearningmastery.com\/wp-admin\/admin-ajax.php","ajax_nonce":"555b70787c"};
/* ]]> */
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/seo-optimized-share-buttons/js/frontend.js?ver=4.2.2.0.iis7_supports_permalinks" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/wp-embed.min.js?ver=4.9.2" type="text/javascript"></script>
<script async="async" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/akismet/_inc/form.js?ver=4.0.2" type="text/javascript"></script>
</body>
</html>