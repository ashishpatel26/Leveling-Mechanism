<html lang="en-US" prefix="og: http://ogp.me/ns#">
<head>
<meta charset="utf-8"/>
<title>Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation - Machine Learning Mastery</title>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<link href="https://machinelearningmastery.com/xmlrpc.php" rel="pingback"/>
<!--  Mobile viewport scale -->
<meta content="initial-scale=1.0, maximum-scale=1.0, user-scalable=yes" name="viewport"/>
<!-- This site is optimized with the Yoast SEO plugin v6.1.1 - https://yoa.st/1yg?utm_content=6.1.1 -->
<link href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" rel="canonical"/>
<link href="https://plus.google.com/u/0/b/117073416089354242117/+MachinelearningmasteryHome/" rel="publisher"/>
<meta content="en_US" property="og:locale"/>
<meta content="article" property="og:type"/>
<meta content="Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation - Machine Learning Mastery" property="og:title"/>
<meta content="The encoder-decoder architecture for recurrent neural networks is the standard neural machine translation method that rivals and in some cases outperforms classical statistical machine translation methods. This architecture is very new, having only been pioneered in 2014, although, has been adopted as the core technology inside Google’s translate service. In this post, you will discover …" property="og:description"/>
<meta content="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" property="og:url"/>
<meta content="Machine Learning Mastery" property="og:site_name"/>
<meta content="https://www.facebook.com/Machine-Learning-Mastery-1429846323896563/" property="article:publisher"/>
<meta content="Natural Language Processing" property="article:section"/>
<meta content="2018-01-01T05:00:52+11:00" property="article:published_time"/>
<meta content="2017-11-21T11:08:54+11:00" property="article:modified_time"/>
<meta content="2017-11-21T11:08:54+11:00" property="og:updated_time"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/Encoder-Decoder-Recurrent-Neural-Network-Models-for-Neural-Machine-Translation.jpg" property="og:image"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/Encoder-Decoder-Recurrent-Neural-Network-Models-for-Neural-Machine-Translation.jpg" property="og:image:secure_url"/>
<meta content="640" property="og:image:width"/>
<meta content="360" property="og:image:height"/>
<script type="application/ld+json">{"@context":"http:\/\/schema.org","@type":"WebSite","@id":"#website","url":"https:\/\/machinelearningmastery.com\/","name":"Machine Learning Mastery","potentialAction":{"@type":"SearchAction","target":"https:\/\/machinelearningmastery.com\/?s={search_term_string}","query-input":"required name=search_term_string"}}</script>
<script type="application/ld+json">{"@context":"http:\/\/schema.org","@type":"Organization","url":"https:\/\/machinelearningmastery.com\/encoder-decoder-recurrent-neural-network-models-neural-machine-translation\/","sameAs":["https:\/\/www.facebook.com\/Machine-Learning-Mastery-1429846323896563\/","https:\/\/www.linkedin.com\/in\/jasonbrownlee","https:\/\/plus.google.com\/u\/0\/b\/117073416089354242117\/+MachinelearningmasteryHome\/","https:\/\/twitter.com\/TeachTheMachine"],"@id":"#organization","name":"Machine Learning Mastery","logo":"https:\/\/machinelearningmastery.com\/wp-content\/uploads\/2016\/09\/cropped-icon.png"}</script>
<!-- / Yoast SEO plugin. -->
<link href="//cdnjs.cloudflare.com" rel="dns-prefetch"/>
<link href="//fonts.googleapis.com" rel="dns-prefetch"/>
<link href="//s.w.org" rel="dns-prefetch"/>
<link href="https://feeds.feedburner.com/MachineLearningMastery" rel="alternate" title="Machine Learning Mastery » Feed" type="application/rss+xml"/>
<link href="https://machinelearningmastery.com/comments/feed/" rel="alternate" title="Machine Learning Mastery » Comments Feed" type="application/rss+xml"/>
<link href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/feed/" rel="alternate" title="Machine Learning Mastery » Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation Comments Feed" type="application/rss+xml"/>
<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.3\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/2.3\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/machinelearningmastery.com\/wp-includes\/js\/wp-emoji-release.min.js?ver=4.9.2"}};
			!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline="top",l.font="600 32px Arial",a){case"flag":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case"emoji":return b=d([55358,56794,8205,9794,65039],[55358,56794,8203,9794,65039]),!b}return!1}function f(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var g,h,i,j,k=b.createElement("canvas"),l=k.getContext&&k.getContext("2d");for(j=Array("flag","emoji"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],"flag"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",h,!1),a.addEventListener("load",h,!1)):(a.attachEvent("onload",h),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/css/min/crayon.min.css?ver=_2.7.2_beta" id="crayon-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/contact-form-7/includes/css/styles.css?ver=4.9.2" id="contact-form-7-css" media="all" rel="stylesheet" type="text/css"/>
<link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.4.0/css/font-awesome.min.css?ver=4.2.2.0.iis7_supports_permalinks" id="apss-font-awesome-css" media="all" rel="stylesheet" type="text/css"/>
<link href="//fonts.googleapis.com/css?family=Open+Sans&amp;ver=4.9.2" id="apss-font-opensans-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/seo-optimized-share-buttons/css/frontend.css?ver=4.2.2.0.iis7_supports_permalinks" id="apss-frontend-css-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/integrations/testimonials/css/testimonials.css?ver=4.9.2" id="woo-testimonials-css-css" media="all" rel="stylesheet" type="text/css"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/style.css?ver=5.9.21" id="theme-stylesheet-css" media="all" rel="stylesheet" type="text/css"/>
<!--[if lt IE 9]>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/css/non-responsive.css" rel="stylesheet" type="text/css" />
<style type="text/css">.col-full, #wrapper { width: 960px; max-width: 960px; } #inner-wrapper { padding: 0; } body.full-width #header, #nav-container, body.full-width #content, body.full-width #footer-widgets, body.full-width #footer { padding-left: 0; padding-right: 0; } body.fixed-mobile #top, body.fixed-mobile #header-container, body.fixed-mobile #footer-container, body.fixed-mobile #nav-container, body.fixed-mobile #footer-widgets-container { min-width: 960px; padding: 0 1em; } body.full-width #content { width: auto; padding: 0 1em;}</style>
<![endif]-->
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/jquery/jquery.js?ver=1.12.4" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.4.1" type="text/javascript"></script>
<script type="text/javascript">
/* <![CDATA[ */
var CrayonSyntaxSettings = {"version":"_2.7.2_beta","is_admin":"0","ajaxurl":"https:\/\/machinelearningmastery.com\/wp-admin\/admin-ajax.php","prefix":"crayon-","setting":"crayon-setting","selected":"crayon-setting-selected","changed":"crayon-setting-changed","special":"crayon-setting-special","orig_value":"data-orig-value","debug":""};
var CrayonSyntaxStrings = {"copy":"Press %s to Copy, %s to Paste","minimize":"Click To Expand Code"};
/* ]]> */
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/crayon-syntax-highlighter/js/min/crayon.min.js?ver=_2.7.2_beta" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/third-party.min.js?ver=4.9.2" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/modernizr.min.js?ver=2.6.2" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/includes/js/general.min.js?ver=4.9.2" type="text/javascript"></script>
<link href="https://machinelearningmastery.com/wp-json/" rel="https://api.w.org/"/>
<link href="https://machinelearningmastery.com/xmlrpc.php?rsd" rel="EditURI" title="RSD" type="application/rsd+xml"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/wlwmanifest.xml" rel="wlwmanifest" type="application/wlwmanifest+xml"/>
<link href="https://machinelearningmastery.com/?p=4531" rel="shortlink"/>
<link href="https://machinelearningmastery.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fmachinelearningmastery.com%2Fencoder-decoder-recurrent-neural-network-models-neural-machine-translation%2F" rel="alternate" type="application/json+oembed"/>
<link href="https://machinelearningmastery.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fmachinelearningmastery.com%2Fencoder-decoder-recurrent-neural-network-models-neural-machine-translation%2F&amp;format=xml" rel="alternate" type="text/xml+oembed"/>
<!-- Start Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44039733-3', 'auto');
  ga('send', 'pageview');

</script>
<!-- End Google Analytics -->
<!-- Facebook Pixel Code -->
<script>
!function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function(){n.callMethod?
n.callMethod.apply(n,arguments):n.queue.push(arguments)};if(!f._fbq)f._fbq=n;
n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;
t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,
document,'script','https://connect.facebook.net/en_US/fbevents.js');

fbq('init', '296263687421164');
fbq('track', "PageView");</script>
<noscript><img height="1" src="https://www.facebook.com/tr?id=296263687421164&amp;ev=PageView&amp;noscript=1" style="display:none" width="1"/></noscript>
<!-- End Facebook Pixel Code -->
<!-- Custom CSS Styling -->
<style type="text/css">
#logo .site-title, #logo .site-description { display:none; }
body {background-repeat:no-repeat;background-position:top left;background-attachment:scroll;border-top:0px solid #000000;}
#header {background-repeat:no-repeat;background-position:left top;margin-top:0px;margin-bottom:0px;padding-top:10px;padding-bottom:10px;border:0px solid ;}
#logo .site-title a {font:bold 40px/1em Helvetica Neue, Helvetica, sans-serif;color:#222222;}
#logo .site-description {font:300 13px/1em Helvetica Neue, Helvetica, sans-serif;color:#999999;}
body, p { font:300 14px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#555555; }
h1 { font:bold 28px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h2 { font:bold 24px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h3 { font:bold 20px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h4 { font:bold 16px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h5 { font:bold 14px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }h6 { font:bold 12px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }
.page-title, .post .title, .page .title {font:bold 28px/1.1em "Helvetica Neue", Helvetica, sans-serif;color:#222222;}
.post .title a:link, .post .title a:visited, .page .title a:link, .page .title a:visited {color:#222222}
.post-meta { font:300 12px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#999999; }
.entry, .entry p{ font:300 15px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:#555555; }
.post-more {font:300 13px/1.5em "Helvetica Neue", Helvetica, sans-serif;color:;border-top:0px solid #e6e6e6;border-bottom:0px solid #e6e6e6;}
#post-author, #connect {border-top:1px solid #e6e6e6;border-bottom:1px solid #e6e6e6;border-left:1px solid #e6e6e6;border-right:1px solid #e6e6e6;border-radius:5px;-moz-border-radius:5px;-webkit-border-radius:5px;background-color:#fafafa}
.nav-entries a, .woo-pagination { font:300 13px/1em "Helvetica Neue", Helvetica, sans-serif;color:#888; }
.woo-pagination a, .woo-pagination a:hover {color:#888!important}
.widget h3 {font:bold 14px/1.2em &quot;Helvetica Neue&quot;, Helvetica, sans-serif;color:#555555;border-bottom:1px solid #e6e6e6;}
.widget_recent_comments li, #twitter li { border-color: #e6e6e6;}
.widget p, .widget .textwidget { font:300 13px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#555555; }
.widget {font:300 13px/1.5em &quot;Helvetica Neue&quot;, Helvetica, sans-serif;color:#555555;border-radius:0px;-moz-border-radius:0px;-webkit-border-radius:0px;}
#tabs .inside li a, .widget_woodojo_tabs .tabbable .tab-pane li a { font:bold 12px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#555555; }
#tabs .inside li span.meta, .widget_woodojo_tabs .tabbable .tab-pane li span.meta { font:300 11px/1.5em Helvetica Neue, Helvetica, sans-serif;color:#999999; }
#tabs ul.wooTabs li a, .widget_woodojo_tabs .tabbable .nav-tabs li a { font:300 11px/2em Helvetica Neue, Helvetica, sans-serif;color:#999999; }
@media only screen and (min-width:768px) {
ul.nav li a, #navigation ul.rss a, #navigation ul.cart a.cart-contents, #navigation .cart-contents #navigation ul.rss, #navigation ul.nav-search, #navigation ul.nav-search a { font:300 14px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#666666; } #navigation ul.rss li a:before, #navigation ul.nav-search a.search-contents:before { color:#666666;}
#navigation ul.nav li ul, #navigation ul.cart > li > ul > div  { border: 0px solid #dbdbdb; }
#navigation ul.nav > li:hover > ul  { left: 0; }
#navigation ul.nav > li  { border-right: 0px solid #dbdbdb; }#navigation ul.nav > li:hover > ul  { left: 0; }
#navigation { box-shadow: none; -moz-box-shadow: none; -webkit-box-shadow: none; }#navigation ul li:first-child, #navigation ul li:first-child a { border-radius:0px 0 0 0px; -moz-border-radius:0px 0 0 0px; -webkit-border-radius:0px 0 0 0px; }
#navigation {border-top:0px solid #dbdbdb;border-bottom:0px solid #dbdbdb;border-left:0px solid #dbdbdb;border-right:0px solid #dbdbdb;border-radius:0px; -moz-border-radius:0px; -webkit-border-radius:0px;}
#top ul.nav li a { font:300 12px/1.6em Helvetica Neue, Helvetica, sans-serif;color:#ddd; }
}
#footer, #footer p { font:300 13px/1.4em Helvetica Neue, Helvetica, sans-serif;color:#999999; }
#footer {border-top:1px solid #dbdbdb;border-bottom:0px solid ;border-left:0px solid ;border-right:0px solid ;border-radius:0px; -moz-border-radius:0px; -webkit-border-radius:0px;}
.magazine #loopedSlider .content h2.title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-magazine .slide-title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.magazine #loopedSlider .content .excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-magazine .slide-content p, .wooslider-theme-magazine .slide-excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.magazine .block .post .title a {font:bold 18px/1.2em Helvetica Neue, Helvetica, sans-serif;color:#222222; }
#loopedSlider.business-slider .content h2 { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
#loopedSlider.business-slider .content h2.title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-business .has-featured-image .slide-title { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
.wooslider-theme-business .has-featured-image .slide-title a { font:bold 24px/1em Arial, sans-serif;color:#ffffff; }
#wrapper #loopedSlider.business-slider .content p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-business .has-featured-image .slide-content p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.wooslider-theme-business .has-featured-image .slide-excerpt p { font:300 13px/1.5em Arial, sans-serif;color:#cccccc; }
.archive_header { font:bold 18px/1em Arial, sans-serif;color:#222222; }
.archive_header {border-bottom:1px solid #e6e6e6;}
.archive_header .catrss { display:none; }
</style>
<!-- Woo Shortcodes CSS -->
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/functions/css/shortcodes.css" rel="stylesheet" type="text/css"/>
<!-- Custom Stylesheet -->
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/themes/canvas-new/custom.css" rel="stylesheet" type="text/css"/>
<!-- Theme version -->
<meta content="Canvas 5.9.21" name="generator"/>
<meta content="WooFramework 6.2.9" name="generator"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-32x32.png" rel="icon" sizes="32x32"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-192x192.png" rel="icon" sizes="192x192"/>
<link href="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-180x180.png" rel="apple-touch-icon-precomposed"/>
<meta content="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/09/cropped-icon-270x270.png" name="msapplication-TileImage"/>
</head>
<body class="post-template-default single single-post postid-4531 single-format-standard safari alt-style-default two-col-left width-960 two-col-left-960">
<div id="wrapper">
<div id="inner-wrapper">
<h3 class="nav-toggle icon"><a href="#navigation">Navigation</a></h3>
<header class="col-full" id="header">
<div id="logo">
<a href="https://machinelearningmastery.com/" title="Making developers awesome at machine learning"><img alt="Machine Learning Mastery" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/MachineLearningMastery.png"/></a>
<span class="site-title"><a href="https://machinelearningmastery.com/">Machine Learning Mastery</a></span>
<span class="site-description">Making developers awesome at machine learning</span>
</div>
<div class="header-widget">
<div class="widget widget_text" id="text-3"> <div class="textwidget"><br/>
<div style="font-size:12pt;">
<a href="/start-here"><strong>Start Here</strong></a>
     
<a href="/blog">Blog</a>
     
<a href="/products">Books</a>
     
<a href="/about">About</a>
     
<a href="/contact">Contact</a>
</div></div>
</div><div class="widget widget_search" id="search-3"><div class="search_main">
<form action="https://machinelearningmastery.com/" class="searchform" method="get">
<input class="field s" name="s" onblur="if (this.value == '') {this.value = 'Search...';}" onfocus="if (this.value == 'Search...') {this.value = '';}" type="text" value="Search..."/>
<button class="fa fa-search submit" name="submit" type="submit" value="Search"></button>
</form>
<div class="fix"></div>
</div></div><div class="widget widget_text" id="text-44"> <div class="textwidget"><p>Need help with Deep Learning for Text? <a href="https://machinelearningmastery.lpages.co/dlfnlp-mini-course/">Take the FREE Mini-Course</a></p>
</div>
</div> </div>
</header>
<nav class="col-full" id="navigation" role="navigation">
<section class="menus">
<a class="nav-home" href="https://machinelearningmastery.com"><span>Home</span></a>
<h3>Empty Menu</h3> <div class="side-nav">
</div><!-- /#side-nav -->
</section><!-- /.menus -->
<a class="nav-close" href="#top"><span>Return to Content</span></a>
</nav>
<!-- #content Starts -->
<div class="col-full" id="content">
<div id="main-sidebar-container">
<!-- #main Starts -->
<section id="main">
<article class="post-4531 post type-post status-publish format-standard has-post-thumbnail hentry category-natural-language-processing">
<header>
<h1 class="title entry-title">Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation</h1> </header>
<div class="post-meta"><span class="small">By</span> <span class="author vcard"><span class="fn"><a href="https://machinelearningmastery.com/author/jasonb/" rel="author" title="Posts by Jason Brownlee">Jason Brownlee</a></span></span> <span class="small">on</span> <abbr class="date time published updated" title="2018-01-01T05:00:52+1100">January 1, 2018</abbr> <span class="small">in</span> <span class="categories"><a href="https://machinelearningmastery.com/category/natural-language-processing/" title="View all items in Natural Language Processing">Natural Language Processing</a></span> </div>
<section class="entry">
<div class="apss-social-share apss-theme-4 clearfix">
<div class="apss-twitter apss-single-icon">
<a href="javascript:void(0);" onclick="apss_open_in_popup_window(event, 'https://twitter.com/intent/tweet?text=Encoder-Decoder%20Recurrent%20Neural%20Network%20Models%20for%20Neural%20Machine%20Translation&amp;url=https%3A%2F%2Fmachinelearningmastery.com%2Fencoder-decoder-recurrent-neural-network-models-neural-machine-translation%2F&amp;');" rel="nofollow" target="" title="Share on Twitter">
<div class="apss-icon-block clearfix">
<i class="fa fa-twitter"></i>
<span class="apss-social-text">Share on Twitter</span><span class="apss-share">Tweet</span>
</div>
</a>
</div>
<div class="apss-facebook apss-single-icon">
<a href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="apss_open_in_popup_window(event, 'https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/');" rel="nofollow" target="" title="Share on Facebook">
<div class="apss-icon-block clearfix">
<i class="fa fa-facebook"></i>
<span class="apss-social-text">Share on Facebook</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-linkedin apss-single-icon">
<a href="http://www.linkedin.com/shareArticle?mini=true&amp;title=Encoder-Decoder%20Recurrent%20Neural%20Network%20Models%20for%20Neural%20Machine%20Translation&amp;url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/&amp;summary=The+encoder-decoder+architecture+for+recurrent+neural+networks+is+the+standard+neural+machine+transl..." onclick="apss_open_in_popup_window(event, 'http://www.linkedin.com/shareArticle?mini=true&amp;title=Encoder-Decoder%20Recurrent%20Neural%20Network%20Models%20for%20Neural%20Machine%20Translation&amp;url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/&amp;summary=The+encoder-decoder+architecture+for+recurrent+neural+networks+is+the+standard+neural+machine+transl...');" rel="nofollow" target="" title="Share on LinkedIn">
<div class="apss-icon-block clearfix"><i class="fa fa-linkedin"></i>
<span class="apss-social-text">Share on LinkedIn</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-google-plus apss-single-icon">
<a href="https://plus.google.com/share?url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="apss_open_in_popup_window(event, 'https://plus.google.com/share?url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/');" rel="nofollow" target="" title="Share on Google Plus">
<div class="apss-icon-block clearfix">
<i class="fa fa-google-plus"></i>
<span class="apss-social-text">Share on Google Plus</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
</div><p>The encoder-decoder architecture for recurrent neural networks is the standard neural machine translation method that rivals and in some cases outperforms classical statistical machine translation methods.</p>
<p>This architecture is very new, having only been pioneered in 2014, although, has been adopted as the core technology inside <a href="https://translate.google.com/">Google’s translate service</a>.</p>
<p>In this post, you will discover the two seminal examples of the encoder-decoder model for neural machine translation.</p>
<p>After reading this post, you will know:</p>
<ul>
<li>The encoder-decoder recurrent neural network architecture is the core technology inside Google’s translate service.</li>
<li>The so-called “<em>Sutskever model</em>” for direct end-to-end machine translation.</li>
<li>The so-called “<em>Cho model</em>” that extends the architecture with GRU units and an attention mechanism.</li>
</ul>
<p>Let’s get started.</p>
<div class="wp-caption aligncenter" id="attachment_4535" style="max-width: 650px"><img alt="Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation" class="size-full wp-image-4535" height="360" sizes="(max-width: 640px) 100vw, 640px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/Encoder-Decoder-Recurrent-Neural-Network-Models-for-Neural-Machine-Translation.jpg" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/Encoder-Decoder-Recurrent-Neural-Network-Models-for-Neural-Machine-Translation.jpg 640w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/01/Encoder-Decoder-Recurrent-Neural-Network-Models-for-Neural-Machine-Translation-300x169.jpg 300w" width="640"/><p class="wp-caption-text">Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation<br/>Photo by <a href="https://www.flickr.com/photos/fabiuxfabiux/34223907581/">Fabio Pani</a>, some rights reserved.</p></div>
<h2>Encoder-Decoder Architecture for NMT</h2>
<p>The Encoder-Decoder architecture with recurrent neural networks has become an effective and standard approach for both neural machine translation (NMT) and sequence-to-sequence (seq2seq) prediction in general.</p>
<p>The key benefits of the approach are the ability to train a single end-to-end model directly on source and target sentences and the ability to handle variable length input and output sequences of text.</p>
<p>As evidence of the success of the method, the architecture is the core of the <a href="https://translate.google.com/">Google translation service</a>.</p>
<blockquote><p>Our model follows the common sequence-to-sequence learning framework with attention. It has three components: an encoder network, a decoder network, and an attention network.</p></blockquote>
<p>— <a href="https://arxiv.org/abs/1609.08144">Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</a>, 2016</p>
<p>In this post, we will take a closer look at two different research projects that developed the same Encoder-Decoder architecture at the same time in 2014 and achieved results that put the spotlight on the approach. They are:</p>
<ul>
<li>Sutskever NMT Model</li>
<li>Cho NMT Model</li>
</ul>
<p>For more on the architecture, see the post:</p>
<ul>
<li><a href="https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/">Encoder-Decoder Long Short-Term Memory Networks</a></li>
</ul>
<!-- Start shortcoder --><p></p><div class="woo-sc-hr"></div>
<center>
<h3>Need help with Deep Learning for Text Data?</h3>
<p>Take my free 7-day email crash course now (with sample code).</p>
<p>Click to sign-up and also get a free PDF Ebook version of the course.</p>
<p><a href="https://machinelearningmastery.lpages.co/leadbox/144855173f72a2%3A164f8be4f346dc/5655638436741120/" rel="noopener" style="background: #ffce0a; color: #ffffff; text-decoration: none; font-family: Helvetica, Arial, sans-serif; font-weight: bold; font-size: 16px; line-height: 20px; padding: 10px; display: inline-block; max-width: 300px; border-radius: 5px; text-shadow: rgba(0, 0, 0, 0.25) 0px -1px 1px; box-shadow: rgba(255, 255, 255, 0.5) 0px 1px 3px inset, rgba(0, 0, 0, 0.5) 0px 1px 3px;" target="_blank">Start Your FREE Crash-Course Now</a><script data-config="%7B%7D" data-leadbox="144855173f72a2:164f8be4f346dc" data-url="https://machinelearningmastery.lpages.co/leadbox/144855173f72a2%3A164f8be4f346dc/5655638436741120/" src="https://machinelearningmastery.lpages.co/leadbox-1509466860.js" type="text/javascript"></script></p>
</center>
<p></p><div class="woo-sc-hr"></div><!-- End shortcoder v4.1.5-->
<h2>Sutskever NMT Model</h2>
<p>In this section, we will look at the neural machine translation model developed by <a href="http://www.cs.toronto.edu/~ilya/">Ilya Sutskever</a>, et al. as described in their 2014 paper “<a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a>“. We will refer to it as the “<em>Sutskever NMT Model</em>“, for lack of a better name.</p>
<p>This is an important paper as it was one of the first to introduce the Encoder-Decoder model for machine translation and more generally sequence-to-sequence learning.</p>
<p>It is an important model in the field of machine translation as it was one of the first neural machine translation systems to outperform a baseline statistical machine learning model on a large translation task.</p>
<h3>Problem</h3>
<p>The model was applied to English to French translation, specifically the <a href="http://www.statmt.org/wmt14/translation-task.html">WMT 2014 translation task</a>.</p>
<p>The translation task was processed one sentence at a time, and an end-of-sequence (&lt;EOS&gt;) token was added to the end of output sequences during training to signify the end of the translated sequence. This allowed the model to be capable of predicting variable length output sequences.</p>
<blockquote><p>Note that we require that each sentence ends with a special end-of-sentence symbol “&lt;EOS&gt;”, which enables the model to define a distribution over sequences of all possible lengths.</p></blockquote>
<p>The model was trained on a subset of the 12 Million sentences in the dataset, comprised of 348 Million French words and 304 Million English words. This set was chosen because it was pre-tokenized.</p>
<p>The source vocabulary was reduced to the 160,000 most frequent source English words and 80,000 of the most frequent target French words. All out-of-vocabulary words were replaced with the “UNK” token.</p>
<h3>Model</h3>
<p>An Encoder-Decoder architecture was developed where an input sequence was read in entirety and encoded to a fixed-length internal representation.</p>
<p>A decoder network then used this internal representation to output words until the end of sequence token was reached. LSTM networks were used for both the encoder and decoder.</p>
<blockquote><p>The idea is to use one LSTM to read the input sequence, one timestep at a time, to obtain large fixed-dimensional vector representation, and then to use another LSTM to extract the output sequence from that vector</p></blockquote>
<p>The final model was an ensemble of 5 deep learning models. A left-to-right beam search was used during the inference of the translations.</p>
<div class="wp-caption aligncenter" id="attachment_4532" style="max-width: 1590px"><img alt="Depiction of Sutskever Encoder-Decoder Model for Text Translation" class="size-full wp-image-4532" height="356" sizes="(max-width: 1580px) 100vw, 1580px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-Sutskever-Encoder-Decoder-Model-for-Text-Translation.png" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-Sutskever-Encoder-Decoder-Model-for-Text-Translation.png 1580w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-Sutskever-Encoder-Decoder-Model-for-Text-Translation-300x68.png 300w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-Sutskever-Encoder-Decoder-Model-for-Text-Translation-768x173.png 768w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-Sutskever-Encoder-Decoder-Model-for-Text-Translation-1024x231.png 1024w" width="1580"/><p class="wp-caption-text">Depiction of Sutskever Encoder-Decoder Model for Text Translation<br/>Taken from “Sequence to Sequence Learning with Neural Networks,” 2014.</p></div>
<h3>Model Configuration</h3>
<ul>
<li>Input sequences were reversed.</li>
<li>A 1000-dimensional word embedding layer was used to represent the input words.</li>
<li>Softmax was used on the output layer.</li>
<li>The input and output models had 4 layers with 1,000 units per layer.</li>
<li>The model was fit for 7.5 epochs where some learning rate decay was performed.</li>
<li>A batch-size of 128 sequences was used during training.</li>
<li>Gradient clipping was used during training to mitigate the chance of gradient explosions.</li>
<li>Batches were comprised of sentences with roughly the same length to speed-up computation.</li>
</ul>
<p>The model was fit on an 8-GPU machine where each layer was run on a different GPU. Training took 10 days.</p>
<blockquote><p>The resulting implementation achieved a speed of 6,300 (both English and French) words per second with a minibatch size of 128. Training took about ten days with this implementation.</p></blockquote>
<h3>Result</h3>
<p>The system achieved a BLEU score of 34.81, which is a good score compared to the baseline score developed with a statistical machine translation system of 33.30. Importantly, this is the first example of a neural machine translation system that outperformed a phrase-based statistical machine translation baseline on a large scale problem.</p>
<blockquote><p>… we obtained a BLEU score of 34.81 […] This is by far the best result achieved by direct translation with large neural networks. For comparison, the BLEU score of an SMT baseline on this dataset is 33.30</p></blockquote>
<p>The final model was used t ore-score the list of <a href="http://www-lium.univ-lemans.fr/~schwenk/cslm_joint_paper/">best translations</a> and improved the score to 36.5 which brings it close to the best result at the time of 37.0.</p>
<p>You can see a video of the talk associated with the paper <a href="https://www.youtube.com/watch?v=-uyXE7dY5H0">here</a>:</p>
<p><iframe allowfullscreen="" frameborder="0" gesture="media" height="281" src="https://www.youtube.com/embed/-uyXE7dY5H0?feature=oembed" width="500"></iframe></p>
<h2>Cho NMT Model</h2>
<p>In this section, we will look at the neural machine translation system described by <a href="http://www.kyunghyuncho.me/">Kyunghyun Cho</a>, et al. in their 2014 paper titled “<a href="https://arxiv.org/abs/1406.1078">Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation</a>.” We will refer to it as the “<em>Cho NMT Model</em>” model for lack of a better name.</p>
<p>Importantly, the Cho Model is used only to score candidate translations and is not used directly for translation like the Sutskever model above. Although extensions to the work to better diagnose and improve the model do use it directly and alone for translation.</p>
<h3>Problem</h3>
<p>As above, the problem is the English to French translation task from the WMT 2014 workshop.</p>
<p>The source and target vocabulary were limited to the most frequent 15,000 French and English words which covers 93% of the dataset, and out of vocabulary words were replaced with “UNK”.</p>
<h3>Model</h3>
<p>The model uses the same two-model approach, here giving it the explicit name of the encoder-decoder architecture.</p>
<blockquote><p>… called RNN Encoder–Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols.</p></blockquote>
<div class="wp-caption aligncenter" id="attachment_4533" style="max-width: 650px"><img alt="Depiction of the Encoder-Decoder architecture" class="size-full wp-image-4533" height="654" sizes="(max-width: 640px) 100vw, 640px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-the-Encoder-Decoder-architecture.png" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-the-Encoder-Decoder-architecture.png 640w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Depiction-of-the-Encoder-Decoder-architecture-294x300.png 294w" width="640"/><p class="wp-caption-text">Depiction of the Encoder-Decoder architecture.<br/>Taken from “Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation.”</p></div>
<p>The implementation does not use LSTM units; instead, a simpler recurrent neural network unit is developed called the gated recurrent unit or GRU.</p>
<blockquote><p>… we also propose a new type of hidden unit that has been motivated by the LSTM unit but is much simpler to compute and implement.</p></blockquote>
<h3>Model Configuration</h3>
<ul>
<li>A 100-dimensional word embedding was used to represent the input words.</li>
<li>The encoder and decoder were configured with 1 layer of 1000 GRU units.</li>
<li>500 Maxout units pooling 2 inputs were used after the decoder.</li>
<li>A batch size of 64 sentences was used during training.</li>
</ul>
<p>The model was trained for approximately 2 days.</p>
<h3>Extensions</h3>
<p>In the paper “<a href="https://arxiv.org/abs/1409.1259">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</a>,” Cho, et al. investigate the limitations of their model. They discover that performance degrades quickly with the increase in the length of input sentences and with the number of words outside of the vocabulary.</p>
<blockquote><p>Our analysis revealed that the performance of the neural machine translation suffers significantly from the length of sentences.</p></blockquote>
<p>They provide a useful graph of the performance of the model as the length of the sentence is increased that captures the graceful loss in skill with increased difficulty.</p>
<div class="wp-caption aligncenter" id="attachment_4534" style="max-width: 496px"><img alt="Loss in model skill with increased sentence length" class="size-full wp-image-4534" height="346" sizes="(max-width: 486px) 100vw, 486px" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Loss-in-model-skill-with-increased-sentence-length.png" srcset="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Loss-in-model-skill-with-increased-sentence-length.png 486w, https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/Loss-in-model-skill-with-increased-sentence-length-300x214.png 300w" width="486"/><p class="wp-caption-text">Loss in model skill with increased sentence length.<br/>Taken from “On the Properties of Neural Machine Translation: Encoder-Decoder Approaches.”</p></div>
<p>To address the problem of unknown words, they suggest dramatically increasing the vocabulary of known words during training.</p>
<p>They address the problem of sentence length in a follow-up paper titled “<a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a>” in which they propose the use of an attention mechanism. Instead of encoding the input sentence to a fixed length vector, a fuller representation of the encoded input is kept and the model learns to use to pay attention to different parts of the input for each word output by the decoder.</p>
<blockquote><p>Each time the proposed model generates a word in a translation, it (soft-)searches for a set of positions in a source sentence where the most relevant information is concentrated. The model then predicts a target word based on the context vectors associated with these source positions and all the previous generated target words.</p></blockquote>
<p>A wealth of technical details are provided in the paper; for example:</p>
<ul>
<li>A similarly configured model is used, although with bidirectional layers.</li>
<li>The data is prepared such that 30,000 of the most common words are kept in the vocabulary.</li>
<li>The model is first trained with sentences with a length up to 20 words, then with sentences with a length up to 50 words.</li>
<li>A batch size of 80 sentences is used and the model was fit for 4-6 epochs.</li>
<li>A beam search was used during the inference to find the most likely sequence of words for each translation.</li>
</ul>
<p>This time the model takes approximately 5 days to train. The code for this follow-up work is also <a href="https://github.com/lisa-groundhog/GroundHog">made available</a>.</p>
<p>As with the Sutskever, the model achieved results within the reach of classical phrase-based statistical approaches.</p>
<blockquote><p>Perhaps more importantly, the proposed approach achieved a translation performance comparable to the existing phrase-based statistical machine translation. It is a striking result, considering that the proposed architecture, or the whole family of neural machine translation, has only been proposed as recently as this year. We believe the architecture proposed here is a promising step toward better machine translation and a better understanding of natural languages in general.</p></blockquote>
<p>Kyunghyun Cho is also the author of a 2015 series of posts on the Nvidia developer blog on the topic of the encoder-decoder architecture for neural machine translation titled “<em>Introduction to Neural Machine Translation with GPUs.</em>” The series provides a good introduction to the topic and the model; see <a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/">part 1</a>, <a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/">part 2</a>, and <a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/">part 3</a>.</p>
<h2>Further Reading</h2>
<p>This section provides more resources on the topic if you are looking to go deeper.</p>
<ul>
<li><a href="https://arxiv.org/abs/1609.08144">Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</a>, 2016.</li>
<li><a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a>, 2014.</li>
<li><a href="https://www.youtube.com/watch?v=-uyXE7dY5H0">Presentation for Sequence to Sequence Learning with Neural Networks</a>, 2016.</li>
<li><a href="http://www.cs.toronto.edu/~ilya/">Ilya Sutskever Homepage</a></li>
<li><a href="https://arxiv.org/abs/1406.1078">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</a>, 2014.</li>
<li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a>, 2014.</li>
<li><a href="https://arxiv.org/abs/1409.1259">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</a>, 2014.</li>
<li><a href="http://www.kyunghyuncho.me/">Kyunghyun Cho Homepage</a></li>
<li>Introduction to Neural Machine Translation with GPUs (<a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/">part1</a>, <a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-2/">part2</a>, <a href="https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-gpus-part-3/">part3</a>), 2015.</li>
</ul>
<h2>Summary</h2>
<p>In this post, you discovered two examples of the encoder-decoder model for neural machine translation.</p>
<p>Specifically, you learned:</p>
<ul>
<li>The encoder-decoder recurrent neural network architecture is the core technology inside Google’s translate service.</li>
<li>The so-called “Sutskever model” for direct end-to-end machine translation.</li>
<li>The so-called “Cho model” that extends the architecture with GRU units and an attention mechanism.</li>
</ul>
<p>Do you have any questions?<br/>
Ask your questions in the comments below and I will do my best to answer.</p>
<div class="awac-wrapper"><div class="awac widget text-42"> <div class="textwidget"><p></p><center><br/>
<div class="woo-sc-hr"></div>
<h2>Develop Deep Learning models for Text Data Today!</h2>
<p><a href="/deep-learning-for-nlp/"><img align="left" alt="Deep Learning for Natural Language Processing" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/DLFNLP-Cover-220.png" style="border: 0;"/></a></p>
<h4>Develop Your Own Text models in Minutes</h4>
<p>…with just a few lines of python code</p>
<p>Discover how in my new Ebook:<br/>
<a href="/deep-learning-for-nlp/">Deep Learning for Natural Language Processing</a></p>
<p>It provides <strong>self-study tutorials</strong> on topics like:<br/>
<em>Bag-of-Words, Word Embedding, Language Models, Caption Generation, Text Translation</em> and much more…</p>
<h4>Finally Bring Deep Learning to your Natural Language Processing Projects</h4>
<p>Skip the Academics. Just Results.</p>
<p><a href="/deep-learning-for-nlp/">Click to learn more</a>.<br/>
</p><div class="woo-sc-hr"></div><br/>
</center>
</div>
</div></div><div class="apss-social-share apss-theme-4 clearfix">
<div class="apss-twitter apss-single-icon">
<a href="javascript:void(0);" onclick="apss_open_in_popup_window(event, 'https://twitter.com/intent/tweet?text=Encoder-Decoder%20Recurrent%20Neural%20Network%20Models%20for%20Neural%20Machine%20Translation&amp;url=https%3A%2F%2Fmachinelearningmastery.com%2Fencoder-decoder-recurrent-neural-network-models-neural-machine-translation%2F&amp;');" rel="nofollow" target="" title="Share on Twitter">
<div class="apss-icon-block clearfix">
<i class="fa fa-twitter"></i>
<span class="apss-social-text">Share on Twitter</span><span class="apss-share">Tweet</span>
</div>
</a>
</div>
<div class="apss-facebook apss-single-icon">
<a href="https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="apss_open_in_popup_window(event, 'https://www.facebook.com/sharer/sharer.php?u=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/');" rel="nofollow" target="" title="Share on Facebook">
<div class="apss-icon-block clearfix">
<i class="fa fa-facebook"></i>
<span class="apss-social-text">Share on Facebook</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-linkedin apss-single-icon">
<a href="http://www.linkedin.com/shareArticle?mini=true&amp;title=Encoder-Decoder%20Recurrent%20Neural%20Network%20Models%20for%20Neural%20Machine%20Translation&amp;url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/&amp;summary=The+encoder-decoder+architecture+for+recurrent+neural+networks+is+the+standard+neural+machine+transl..." onclick="apss_open_in_popup_window(event, 'http://www.linkedin.com/shareArticle?mini=true&amp;title=Encoder-Decoder%20Recurrent%20Neural%20Network%20Models%20for%20Neural%20Machine%20Translation&amp;url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/&amp;summary=The+encoder-decoder+architecture+for+recurrent+neural+networks+is+the+standard+neural+machine+transl...');" rel="nofollow" target="" title="Share on LinkedIn">
<div class="apss-icon-block clearfix"><i class="fa fa-linkedin"></i>
<span class="apss-social-text">Share on LinkedIn</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
<div class="apss-google-plus apss-single-icon">
<a href="https://plus.google.com/share?url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/" onclick="apss_open_in_popup_window(event, 'https://plus.google.com/share?url=https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/');" rel="nofollow" target="" title="Share on Google Plus">
<div class="apss-icon-block clearfix">
<i class="fa fa-google-plus"></i>
<span class="apss-social-text">Share on Google Plus</span>
<span class="apss-share">Share</span>
</div>
</a>
</div>
</div> </section><!-- /.entry -->
<div class="fix"></div>
<aside id="post-author">
<div class="profile-image"><img alt="" class="avatar avatar-80 photo" height="80" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=160&amp;d=mm&amp;r=g 2x" width="80"/></div>
<div class="profile-content">
<h4>About Jason Brownlee</h4>
		Dr. Jason Brownlee is a husband, proud father, academic researcher, author, professional developer and a machine learning practitioner. He is dedicated to helping developers get started and get good at applied machine learning.
<a href="/about">Learn more</a>.				<div class="profile-link">
<a href="https://machinelearningmastery.com/author/jasonb/">
				View all posts by Jason Brownlee <span class="meta-nav">→</span> </a>
</div><!--#profile-link-->
</div>
<div class="fix"></div>
</aside>
<div class="post-utility"></div>
</article><!-- /.post -->
<div class="post-entries">
<div class="nav-prev fl"><a href="https://machinelearningmastery.com/introduction-neural-machine-translation/" rel="prev"><i class="fa fa-angle-left"></i> A Gentle Introduction to Neural Machine Translation</a></div>
<div class="nav-next fr"><a href="https://machinelearningmastery.com/configure-encoder-decoder-model-neural-machine-translation/" rel="next">How to Configure an Encoder-Decoder Model for Neural Machine Translation <i class="fa fa-angle-right"></i></a></div>
<div class="fix"></div>
</div>
<div id="comments"> <h3 id="comments-title">6 Responses to <em>Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation</em></h3>
<ol class="commentlist">
<li class="comment even thread-even depth-1" id="comment-425707">
<div class="comment-container" id="li-comment-425707">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/bcae215578dd8bcced346e7010d68b60?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/bcae215578dd8bcced346e7010d68b60?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">vineet</span>
<span class="date">January 5, 2018 at 1:18 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-425707" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>The post was inspiring! Thank you  jason.</p>
<div class="reply">
<a aria-label="Reply to vineet" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/?replytocom=425707#respond" onclick='return addComment.moveForm( "comment-425707", "425707", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-425747">
<div class="comment-container" id="li-comment-425747">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">January 6, 2018 at 5:51 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-425747" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Thanks, I’m glad to hear that.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/?replytocom=425747#respond" onclick='return addComment.moveForm( "comment-425747", "425747", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment even thread-odd thread-alt depth-1" id="comment-425818">
<div class="comment-container" id="li-comment-425818">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/189ab65cabe6527b354b14e855473c27?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/189ab65cabe6527b354b14e855473c27?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">Roa</span>
<span class="date">January 7, 2018 at 9:45 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-425818" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>It’s an exciting, perfect.</p>
<div class="reply">
<a aria-label="Reply to Roa" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/?replytocom=425818#respond" onclick='return addComment.moveForm( "comment-425818", "425818", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-425846">
<div class="comment-container" id="li-comment-425846">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">January 8, 2018 at 5:39 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-425846" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Thanks.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/?replytocom=425846#respond" onclick='return addComment.moveForm( "comment-425846", "425846", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
<li class="comment even thread-even depth-1" id="comment-425992">
<div class="comment-container" id="li-comment-425992">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/ce623be2f3ffcc799bec04740be2856c?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/ce623be2f3ffcc799bec04740be2856c?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name">BA</span>
<span class="date">January 9, 2018 at 9:08 pm</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-425992" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>Can this technique be used for transliteration (of proper names)? Or would transliteration be simpler? If so, what is a good sequence-to-sequence model for transliteration English to a Arabic and Visa-versa</p>
<div class="reply">
<a aria-label="Reply to BA" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/?replytocom=425992#respond" onclick='return addComment.moveForm( "comment-425992", "425992", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
<ul class="children">
<li class="comment byuser comment-author-jasonb bypostauthor odd alt depth-2" id="comment-426059">
<div class="comment-container" id="li-comment-426059">
<div class="avatar"><img alt="" class="avatar avatar-40 photo" height="40" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=40&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=80&amp;d=mm&amp;r=g 2x" width="40"/></div>
<div class="comment-head">
<span class="name"><a class="url" href="http://MachineLearningMastery.com" rel="external nofollow">Jason Brownlee</a></span>
<span class="date">January 10, 2018 at 5:25 am</span>
<span class="perma"><a href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#comment-426059" title="Direct link to this comment">#</a></span>
<span class="edit"></span>
</div><!-- /.comment-head -->
<div class="comment-entry">
<p>I believe so.</p>
<div class="reply">
<a aria-label="Reply to Jason Brownlee" class="comment-reply-link" href="https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/?replytocom=426059#respond" onclick='return addComment.moveForm( "comment-426059", "426059", "respond", "4531" )' rel="nofollow">Reply</a> </div><!-- /.reply -->
</div><!-- /comment-entry -->
</div><!-- /.comment-container -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ol>
</div> <div class="comment-respond" id="respond">
<h3 class="comment-reply-title" id="reply-title">Leave a Reply <small><a href="/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/#respond" id="cancel-comment-reply-link" rel="nofollow" style="display:none;">Click here to cancel reply.</a></small></h3> <form action="https://machinelearningmastery.com/wp-comments-post.php?wpe-comment-post=mlmastery" class="comment-form" id="commentform" method="post">
<p class="comment-form-comment"><label class="hide" for="comment">Comment</label> <textarea aria-required="true" cols="50" id="comment" maxlength="65525" name="comment" required="required" rows="10" tabindex="4"></textarea></p><p class="comment-form-author"><input aria-required="true" class="txt" id="author" name="author" size="30" tabindex="1" type="text" value=""/><label for="author">Name <span class="required">(required)</span></label> </p>
<p class="comment-form-email"><input aria-required="true" class="txt" id="email" name="email" size="30" tabindex="2" type="text" value=""/><label for="email">Email (will not be published) <span class="required">(required)</span></label> </p>
<p class="comment-form-url"><input class="txt" id="url" name="url" size="30" tabindex="3" type="text" value=""/><label for="url">Website</label></p>
<p class="form-submit"><input class="submit" id="submit" name="submit" type="submit" value="Submit Comment"/> <input id="comment_post_ID" name="comment_post_ID" type="hidden" value="4531"/>
<input id="comment_parent" name="comment_parent" type="hidden" value="0"/>
</p><p style="display: none;"><input id="akismet_comment_nonce" name="akismet_comment_nonce" type="hidden" value="ff87551612"/></p><p style="display: none;"><input id="ak_js" name="ak_js" type="hidden" value="163"/></p> </form>
</div><!-- #respond -->
</section><!-- /#main -->
<aside id="sidebar">
<div class="widget widget_woo_blogauthorinfo" id="woo_blogauthorinfo-2"><h3>Welcome to Machine Learning Mastery</h3><span class="left"><img alt="" class="avatar avatar-100 photo" height="100" src="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=100&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/1d75d46040c28497f0dee5d8e100db37?s=200&amp;d=mm&amp;r=g 2x" width="100"/></span>
<p>Hi, I'm Dr. Jason Brownlee.
<br/>
My goal is to make practitioners like YOU awesome at applied machine learning.</p>
<p><a href="/about">Read More</a></p>
<div class="fix"></div>
</div><div class="widget widget_text" id="text-43"> <div class="textwidget"><p></p><center>
<h3>Deep Learning for Text Data</h3>
<p>Cut through the math and research papers.<br/>
Discover Word Embeddings, Text Translation and more.</p>
<p><a href="/deep-learning-for-nlp/">Get Started With Deep Learning for NLP Today!</a><br/>
<a href="/deep-learning-for-nlp/"><img src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/DLFNLP-Cover-220.png"/></a><br/>
</p></center>
</div>
</div>
<div class="widget widget_woo_tabs" id="woo_tabs-2"> <div id="tabs">
<ul class="wooTabs">
<li class="popular"><a href="#tab-pop">Popular</a></li> </ul>
<div class="clear"></div>
<div class="boxes box inside">
<ul class="list" id="tab-pop">
<li>
<a href="https://machinelearningmastery.com/machine-learning-in-python-step-by-step/" title="Your First Machine Learning Project in Python Step-By-Step"><img alt="Your First Machine Learning Project in Python Step-By-Step" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/Your-First-Machine-Learning-Project-in-Python-Step-By-Step-150x150.jpg" title="Your First Machine Learning Project in Python Step-By-Step" width="45"/></a> <a href="https://machinelearningmastery.com/machine-learning-in-python-step-by-step/" title="Your First Machine Learning Project in Python Step-By-Step">Your First Machine Learning Project in Python Step-By-Step</a>
<span class="meta">June 10, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/" title="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras"><img alt="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/07/Time-Series-Prediction-with-LSTM-Recurrent-Neural-Networks-in-Python-with-Keras-150x150.jpg" title="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras" width="45"/></a> <a href="https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/" title="Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras">Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras</a>
<span class="meta">July 21, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/" title="Multivariate Time Series Forecasting with LSTMs in Keras"><img alt="Line Plots of Air Pollution Time Series" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/06/Line-Plots-of-Air-Pollution-Time-Series-150x150.png" title="Multivariate Time Series Forecasting with LSTMs in Keras" width="45"/></a> <a href="https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/" title="Multivariate Time Series Forecasting with LSTMs in Keras">Multivariate Time Series Forecasting with LSTMs in Keras</a>
<span class="meta">August 14, 2017</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/" title="Develop Your First Neural Network in Python With Keras Step-By-Step"><img alt="Tour of Deep Learning Algorithms" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/04/Tour-of-Deep-Learning-Algorithms-150x150.jpg" title="Develop Your First Neural Network in Python With Keras Step-By-Step" width="45"/></a> <a href="https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/" title="Develop Your First Neural Network in Python With Keras Step-By-Step">Develop Your First Neural Network in Python With Keras Step-By-Step</a>
<span class="meta">May 24, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/setup-python-environment-machine-learning-deep-learning-anaconda/" title="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda"><img alt="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/03/How-to-Setup-a-Python-Environment-for-Machine-Learning-and-Deep-Learning-with-Anaconda-150x150.png" title="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda" width="45"/></a> <a href="https://machinelearningmastery.com/setup-python-environment-machine-learning-deep-learning-anaconda/" title="How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda">How to Setup a Python Environment for Machine Learning and Deep Learning with Anaconda</a>
<span class="meta">March 13, 2017</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/" title="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras"><img alt="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/07/Sequence-Classification-with-LSTM-Recurrent-Neural-Networks-in-Python-with-Keras-150x150.jpg" title="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras" width="45"/></a> <a href="https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/" title="Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras">Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras</a>
<span class="meta">July 26, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/" title="Time Series Forecasting with the Long Short-Term Memory Network in Python"><img alt="Time Series Forecasting with the Long Short-Term Memory Network in Python" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2017/04/Time-Series-Forecasting-with-the-Long-Short-Term-Memory-Network-in-Python-150x150.jpg" title="Time Series Forecasting with the Long Short-Term Memory Network in Python" width="45"/></a> <a href="https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/" title="Time Series Forecasting with the Long Short-Term Memory Network in Python">Time Series Forecasting with the Long Short-Term Memory Network in Python</a>
<span class="meta">April 7, 2017</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/" title="Multi-Class Classification Tutorial with the Keras Deep Learning Library"><img alt="Multi-Class Classification Tutorial with the Keras Deep Learning Library" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/Multi-Class-Classification-Tutorial-with-the-Keras-Deep-Learning-Library-150x150.jpg" title="Multi-Class Classification Tutorial with the Keras Deep Learning Library" width="45"/></a> <a href="https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/" title="Multi-Class Classification Tutorial with the Keras Deep Learning Library">Multi-Class Classification Tutorial with the Keras Deep Learning Library</a>
<span class="meta">June 2, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/" title="Regression Tutorial with the Keras Deep Learning Library in Python"><img alt="Regression Tutorial with Keras Deep Learning Library in Python" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/Regression-Tutorial-with-Keras-Deep-Learning-Library-in-Python-150x150.jpg" title="Regression Tutorial with the Keras Deep Learning Library in Python" width="45"/></a> <a href="https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/" title="Regression Tutorial with the Keras Deep Learning Library in Python">Regression Tutorial with the Keras Deep Learning Library in Python</a>
<span class="meta">June 9, 2016</span>
<div class="fix"></div>
</li>
<li>
<a href="https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/" title="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras"><img alt="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras" class="thumbnail wp-post-image" height="45" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/08/How-to-Grid-Search-Hyperparameters-for-Deep-Learning-Models-in-Python-With-Keras-150x150.jpg" title="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras" width="45"/></a> <a href="https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/" title="How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras">How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras</a>
<span class="meta">August 9, 2016</span>
<div class="fix"></div>
</li>
</ul>
</div><!-- /.boxes -->
</div><!-- /wooTabs -->
</div> </aside><!-- /#sidebar -->
</div><!-- /#main-sidebar-container -->
</div><!-- /#content -->
<footer class="col-full" id="footer">
<div class="col-left" id="copyright">
<p>© 2018 Machine Learning Mastery. All Rights Reserved. </p> </div>
<div class="col-right" id="credit">
<p></p><p>
<a href="/privacy/">Privacy</a> | 
<a href="/contact/">Contact</a> |
<a href="/about/">About</a>
</p> </div>
</footer>
</div><!-- /#inner-wrapper -->
</div><!-- /#wrapper -->
<div class="fix"></div><!--/.fix-->
<!-- Drip -->
<script type="text/javascript">
  var _dcq = _dcq || [];
  var _dcs = _dcs || {}; 
  _dcs.account = '9556588';
  
  (function() {
    var dc = document.createElement('script');
    dc.type = 'text/javascript'; dc.async = true; 
    dc.src = '//tag.getdrip.com/9556588.js';
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(dc, s);
  })();
</script><!-- Woo Tabs Widget -->
<script type="text/javascript">
jQuery(document).ready(function(){
	// UL = .wooTabs
	// Tab contents = .inside

	var tag_cloud_class = '#tagcloud';

	//Fix for tag clouds - unexpected height before .hide()
	var tag_cloud_height = jQuery( '#tagcloud').height();

	jQuery( '.inside ul li:last-child').css( 'border-bottom','0px' ); // remove last border-bottom from list in tab content
	jQuery( '.wooTabs').each(function(){
		jQuery(this).children( 'li').children( 'a:first').addClass( 'selected' ); // Add .selected class to first tab on load
	});
	jQuery( '.inside > *').hide();
	jQuery( '.inside > *:first-child').show();

	jQuery( '.wooTabs li a').click(function(evt){ // Init Click funtion on Tabs

		var clicked_tab_ref = jQuery(this).attr( 'href' ); // Strore Href value

		jQuery(this).parent().parent().children( 'li').children( 'a').removeClass( 'selected' ); //Remove selected from all tabs
		jQuery(this).addClass( 'selected' );
		jQuery(this).parent().parent().parent().children( '.inside').children( '*').hide();

		jQuery( '.inside ' + clicked_tab_ref).fadeIn(500);

		 evt.preventDefault();

	})
})
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/comment-reply.min.js?ver=4.9.2" type="text/javascript"></script>
<script type="text/javascript">
/* <![CDATA[ */
var wpcf7 = {"apiSettings":{"root":"https:\/\/machinelearningmastery.com\/wp-json\/contact-form-7\/v1","namespace":"contact-form-7\/v1"},"recaptcha":{"messages":{"empty":"Please verify that you are not a robot."}},"cached":"1"};
/* ]]> */
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/contact-form-7/includes/js/scripts.js?ver=4.9.2" type="text/javascript"></script>
<script type="text/javascript">
/* <![CDATA[ */
var frontend_ajax_object = {"ajax_url":"https:\/\/machinelearningmastery.com\/wp-admin\/admin-ajax.php","ajax_nonce":"555b70787c"};
/* ]]> */
</script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/seo-optimized-share-buttons/js/frontend.js?ver=4.2.2.0.iis7_supports_permalinks" type="text/javascript"></script>
<script src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-includes/js/wp-embed.min.js?ver=4.9.2" type="text/javascript"></script>
<script async="async" src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/plugins/akismet/_inc/form.js?ver=4.0.2" type="text/javascript"></script>
</body>
</html>